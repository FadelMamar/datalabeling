{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image tiling for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanings of arguments\n",
    "- ```-ratioheight``` : proportion of tile  w.r.t height of image. Example 0.5 means dividing the image in two bands w.r.t height.\n",
    "- ```-ratiowidth``` : proportion of tile w.r.t to width of image. Example 1.0 means the width of the tile is the same as the image.\n",
    "- ```-overlapfactor``` : percentage of overlap. It should be less than 1.\n",
    "- ```-rmheight``` : percentage of height to remove or crop at bottom and top\n",
    "- ```-rmwidth``` : percentage of width to remove or crop on each side of the image\n",
    "- ```-pattern``` : \"**/*.JPG\" will get all .JPG images in directory and subdirectories. On windows it will get both .JPG and .jpg. On unix it will only get .JPG images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New script for tiling data\n",
    "# images_to_tile = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images\"\n",
    "# destination_directory = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images-tiled\"\n",
    "!python ../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Dry season\\Kapiri\\Camp 6-8\\Rep 2\" 0 0 0 -overlapfactor 0.1  -ratiowidth 0.33334 -ratioheight 0.5 -rmheight 0.21 -rmwidth 0.1 -dest \"D:\\PhD\\Data per camp\\Dry season\\Kapiri\\Camp 6-8\\Rep 2 - tiled\" -pattern \"**/*.JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-annotating data for Labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from datalabeling.annotator import Annotator\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a JSON file to be uuploaded to Label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "alias = \"last\" # the aliases are found in mlflow tracker UI\n",
    "name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "handler = Annotator(mlflow_model_alias=alias,\n",
    "                    mlflow_model_name=name,\n",
    "                    is_yolo_obb= name.strip() == \"obb-detector\",\n",
    "                    # dotenv_path=\"../.env\"\n",
    "                    )\n",
    "path_img_dir=r\"D:\\PhD\\Data per camp\\Dry season\\Kapiri\\Camp 6-8\\Rep 2 - tiled\"\n",
    "root=\"D:\\\\\"\n",
    "save_json_path = os.path.join(Path(path_img_dir).parent,\n",
    "                              f\"{Path(path_img_dir).name}_preannotation_label-studio.json\")\n",
    "\n",
    "# build and saves json\n",
    "directory_preds = handler.build_upload_json(path_img_dir=path_img_dir,\n",
    "                                            root=root,\n",
    "                                            save_json_path=save_json_path,\n",
    "                                            pattern=\"**/*.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-annotating an existing project using Label studio API\n",
    "It seems that it will not work well (i.e. filtering) with older projects created prior to Label studio software update.\n",
    "It is the **recommended way of pre-annotating data in Labelstudio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "alias = \"last\"\n",
    "name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "handler = Annotator(mlflow_model_alias=alias,\n",
    "                    mlflow_model_name=name,\n",
    "                    confidence_threshold=0.1,\n",
    "                    is_yolo_obb=name.strip() == \"obb-detector\",\n",
    "                    dotenv_path=\"../.env\")\n",
    "project_id = ... # insert correct project_id by loooking at the url\n",
    "handler.upload_predictions(project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up inference on intel, make changes inn ultralytics/nn/autobackend.py:\n",
    "```\n",
    "- device_name = \"AUTO:NPU,GPU,CPU\" # CPU, GPU, NPU, AUTO,\"AUTO:GPU,NPU\"\n",
    "- inference_mode = \"LATENCY\" # OpenVINO inference modes are 'LATENCY', 'THROUGHPUT' (not recommended), or 'CUMULATIVE_THROUGHPUT'\n",
    "- LOGGER.info(f\"Using OpenVINO {inference_mode} mode for inference...\")\n",
    "- ov_compiled_model = core.compile_model(\n",
    "                ov_model,\n",
    "                device_name=device_name,  # AUTO selects best available device, do not modify\n",
    "                config={\"PERFORMANCE_HINT\": inference_mode,\n",
    "                        \"CACHE_DIR\": os.environ[\"OPENVINO_CACHE_MODEL\"]}, # make sure to set environment variable\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/17/2024 21:53:35 - INFO - datalabeling.annotator.models -   Computing device: NPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model for OpenVINO inference...\n",
      "Available openvino devices are: ['CPU', 'GPU', 'NPU']. Using device=AUTO:NPU,GPU,CPU.\n",
      "Using OpenVINO LATENCY mode for inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:   0%|          | 0/10 [00:00<?, ?it/s]11/17/2024 21:53:39 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\003a34ee6b7841e6851b8fe511ebe102_0.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  10%|█         | 1/10 [00:01<00:12,  1.39s/it]11/17/2024 21:53:40 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  10%|█         | 1/10 [00:01<00:12,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_0.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  20%|██        | 2/10 [00:02<00:10,  1.30s/it]11/17/2024 21:53:41 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  20%|██        | 2/10 [00:02<00:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_1.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  30%|███       | 3/10 [00:03<00:08,  1.26s/it]11/17/2024 21:53:43 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  30%|███       | 3/10 [00:03<00:08,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_4.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  40%|████      | 4/10 [00:04<00:07,  1.22s/it]11/17/2024 21:53:44 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  40%|████      | 4/10 [00:05<00:07,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\00a033fefe644429a1e0fcffe88f8b39_0.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  50%|█████     | 5/10 [00:06<00:06,  1.22s/it]11/17/2024 21:53:45 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  50%|█████     | 5/10 [00:06<00:06,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\01f1653a94f14044bf11d78c5b4221d1_4.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  60%|██████    | 6/10 [00:07<00:04,  1.23s/it]11/17/2024 21:53:46 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  60%|██████    | 6/10 [00:07<00:04,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_0.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  70%|███████   | 7/10 [00:08<00:03,  1.23s/it]11/17/2024 21:53:48 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  70%|███████   | 7/10 [00:08<00:03,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_1.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  80%|████████  | 8/10 [00:09<00:02,  1.23s/it]11/17/2024 21:53:49 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  80%|████████  | 8/10 [00:09<00:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_3.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  90%|█████████ | 9/10 [00:11<00:01,  1.22s/it]11/17/2024 21:53:50 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  90%|█████████ | 9/10 [00:11<00:01,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0331412671394b5a948c75a13a709340_4.JPG\n",
      "Performing prediction on 4 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions: 100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# using path_to_weights\n",
    "# go to ultralytics.nn.autobackend to modify ov_compiled device to \"AUTO:NPU,GPU,CPU\"\n",
    "\n",
    "use_sliding_window=True\n",
    "\n",
    "handler = Annotator(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                    is_yolo_obb=True,\n",
    "                    tilesize=1280,\n",
    "                    overlapratio=0.1,\n",
    "                    use_sliding_window=use_sliding_window,\n",
    "                    confidence_threshold=0.5,\n",
    "                    device=\"NPU\", # \"cpu\", \"cuda\"\n",
    "                    tag_to_append=f\"-sahi:{use_sliding_window}\",\n",
    "                    dotenv_path=\"../.env\")\n",
    "\n",
    "project_id = 3 # insert correct project_id by loooking at the url\n",
    "top_n=10\n",
    "handler.upload_predictions(project_id=project_id,top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/17/2024 21:54:23 - INFO - datalabeling.annotator.models -   Computing device: NPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model for OpenVINO inference...\n",
      "Available openvino devices are: ['CPU', 'GPU', 'NPU']. Using device=AUTO:NPU,GPU,CPU.\n",
      "Using OpenVINO LATENCY mode for inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:   0%|          | 0/10 [00:00<?, ?it/s]11/17/2024 21:54:28 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\003a34ee6b7841e6851b8fe511ebe102_0.JPG\n",
      "\n",
      "0: 1280x1280 349.8ms\n",
      "Speed: 11.3ms preprocess, 349.8ms inference, 12.8ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  10%|█         | 1/10 [00:00<00:04,  2.05it/s]11/17/2024 21:54:28 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_0.JPG\n",
      "\n",
      "0: 1280x1280 160.4ms\n",
      "Speed: 15.6ms preprocess, 160.4ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  20%|██        | 2/10 [00:00<00:03,  2.58it/s]11/17/2024 21:54:28 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_1.JPG\n",
      "\n",
      "0: 1280x1280 163.4ms\n",
      "Speed: 14.2ms preprocess, 163.4ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  30%|███       | 3/10 [00:01<00:02,  2.87it/s]11/17/2024 21:54:29 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0078d29a8d0b489caa3425969c7477ac_4.JPG\n",
      "\n",
      "0: 1280x1280 166.2ms\n",
      "Speed: 10.8ms preprocess, 166.2ms inference, 2.7ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  40%|████      | 4/10 [00:01<00:02,  2.98it/s]11/17/2024 21:54:29 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\00a033fefe644429a1e0fcffe88f8b39_0.JPG\n",
      "\n",
      "0: 1280x1280 167.1ms\n",
      "Speed: 13.5ms preprocess, 167.1ms inference, 1.9ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  50%|█████     | 5/10 [00:01<00:01,  3.07it/s]11/17/2024 21:54:29 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\01f1653a94f14044bf11d78c5b4221d1_4.JPG\n",
      "\n",
      "0: 1280x1280 161.0ms\n",
      "Speed: 13.1ms preprocess, 161.0ms inference, 8.2ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  60%|██████    | 6/10 [00:02<00:01,  3.13it/s]11/17/2024 21:54:30 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_0.JPG\n",
      "\n",
      "0: 1280x1280 166.0ms\n",
      "Speed: 11.9ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  70%|███████   | 7/10 [00:02<00:00,  3.15it/s]11/17/2024 21:54:30 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_1.JPG\n",
      "\n",
      "0: 1280x1280 178.9ms\n",
      "Speed: 11.6ms preprocess, 178.9ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  80%|████████  | 8/10 [00:02<00:00,  3.12it/s]11/17/2024 21:54:30 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0236bf6690654f9ab0e1ebae673ab6eb_3.JPG\n",
      "\n",
      "0: 1280x1280 (no detections), 165.0ms\n",
      "Speed: 15.2ms preprocess, 165.0ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  90%|█████████ | 9/10 [00:03<00:00,  3.11it/s]11/17/2024 21:54:31 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\0331412671394b5a948c75a13a709340_4.JPG\n",
      "\n",
      "0: 1280x1280 161.8ms\n",
      "Speed: 13.7ms preprocess, 161.8ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions: 100%|██████████| 10/10 [00:03<00:00,  3.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# using path_to_weights\n",
    "# go to ultralytics.nn.autobackend to modify ov_compiled device to \"AUTO:NPU,GPU,CPU\"\n",
    "\n",
    "use_sliding_window=False\n",
    "\n",
    "handler = Annotator(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                    is_yolo_obb=True,\n",
    "                    tilesize=1280,\n",
    "                    overlapratio=0.1,\n",
    "                    use_sliding_window=use_sliding_window,\n",
    "                    confidence_threshold=0.5,\n",
    "                    device=\"NPU\", # \"cpu\", \"cuda\"\n",
    "                    tag_to_append=f\"-sahi:{use_sliding_window}\",\n",
    "                    dotenv_path=\"../.env\")\n",
    "\n",
    "project_id = 3 # insert correct project_id by loooking at the url\n",
    "top_n=10\n",
    "handler.upload_predictions(project_id=project_id,top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_ml.utils import get_local_path\n",
    "from urllib.parse import unquote, quote\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/17/2024 20:18:35 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\savmap_dataset_v2\\images_splits\\003a34ee6b7841e6851b8fe511ebe102_0.JPG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:\\\\savmap_dataset_v2\\\\images_splits\\\\003a34ee6b7841e6851b8fe511ebe102_0.JPG'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = unquote(\"/data/local-files/?d=savmap_dataset_v2%5Cimages_splits%5C003a34ee6b7841e6851b8fe511ebe102_0.JPG\")\n",
    "get_local_path(path,download_resources=False)#,os.path.exists(get_local_path(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from sahi.predict import get_sliced_prediction\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "from datalabeling.annotator import Detector\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load env variable, loads model cache location!!\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = r\"D:\\savmap_dataset_v2\\images_splits\\00a033fefe644429a1e0fcffe88f8b39_1.JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up inference on intel, make changes inn ultralytics/nn/autobackend.py:\n",
    "```\n",
    "- device_name = \"AUTO:NPU,GPU,CPU\" # CPU, GPU, NPU, AUTO,\"AUTO:GPU,NPU\"\n",
    "- inference_mode = \"LATENCY\" # OpenVINO inference modes are 'LATENCY', 'THROUGHPUT' (not recommended), or 'CUMULATIVE_THROUGHPUT'\n",
    "- LOGGER.info(f\"Using OpenVINO {inference_mode} mode for inference...\")\n",
    "- ov_compiled_model = core.compile_model(\n",
    "                ov_model,\n",
    "                device_name=device_name,  # AUTO selects best available device, do not modify\n",
    "                config={\"PERFORMANCE_HINT\": inference_mode,\n",
    "                        \"CACHE_DIR\": os.environ[\"OPENVINO_CACHE_MODEL\"]}, # make sure to set environment variable\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/17/2024 21:28:50 - INFO - datalabeling.annotator.models -   Computing device: CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model for OpenVINO inference...\n",
      "Available openvino devices are: ['CPU', 'GPU', 'NPU']. Using device=AUTO:NPU,GPU,CPU.\n",
      "Using OpenVINO LATENCY mode for inference...\n"
     ]
    }
   ],
   "source": [
    "# Define detector\n",
    "# to speed up inference on intel, make\n",
    "model = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                confidence_threshold=0.1,\n",
    "                overlap_ratio=0.1,\n",
    "                tilesize=1280,\n",
    "                device='CPU',\n",
    "                use_sliding_window=False,\n",
    "                is_yolo_obb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 253.8ms\n",
      "Speed: 14.0ms preprocess, 253.8ms inference, 4.0ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "[{'image_id': None, 'bbox': [1929.349365234375, 389.6276550292969, 81.92626953125, 70.74468994140625], 'score': 0.3759765625, 'category_id': 0, 'category_name': 'wildlife', 'segmentation': [], 'iscrowd': 0, 'area': None}]\n",
      "Device took 0.31 seconds.\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(IMAGE_PATH)\n",
    "\n",
    "while True:\n",
    "    start_time = time.perf_counter()\n",
    "    print(model.predict(image,return_coco=True,nms_iou=0.5))\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Device took {end_time-start_time:.2f} seconds.\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with openvino\n",
    "import openvino as ov\n",
    "import openvino.properties.hint as hints\n",
    "import torch\n",
    "import torchvision.transforms as F\n",
    "from ultralytics.utils import DEFAULT_CFG\n",
    "from ultralytics.cfg import get_cfg\n",
    "from ultralytics.data.converter import coco80_to_coco91_class\n",
    "\n",
    "# load validator\n",
    "args = get_cfg(cfg=DEFAULT_CFG)\n",
    "det_model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\")\n",
    "det_validator = det_model.task_map[det_model.task][\"validator\"](args=args)\n",
    "det_validator.is_coco = True\n",
    "det_validator.class_map = coco80_to_coco91_class()\n",
    "det_validator.names = det_model.model.names\n",
    "det_validator.metrics.names = det_validator.names\n",
    "det_validator.nc = det_model.model.model[-1].nc\n",
    "det_validator.stride = 32\n",
    "args = get_cfg(cfg=DEFAULT_CFG)\n",
    "det_model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\")\n",
    "\n",
    "core = ov.Core()\n",
    "det_model_path = r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\\best.xml\"\n",
    "det_ov_model = core.read_model(det_model_path)\n",
    "\n",
    "device = \"AUTO:NPU,GPU\" # CPU, NPU, GPU \"AUTO:NPU,GPU,CPU\" \n",
    "\n",
    "# reshaping\n",
    "input_layer = det_ov_model.input(0)\n",
    "output_layer = det_ov_model.output(0)\n",
    "new_shape = ov.PartialShape([2, 3, 1280, 1280])\n",
    "det_ov_model.reshape({input_layer.any_name: new_shape})\n",
    "\n",
    "ov_config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT,\n",
    "             \"CACHE_DIR\": '../models/model_cache'}\n",
    "\n",
    "if (\"GPU\" in core.available_devices) and device==\"GPU\":\n",
    "    ov_config[\"GPU_DISABLE_WINOGRAD_CONVOLUTION\"] = \"YES\"\n",
    "det_compiled_model = core.compile_model(det_ov_model, device, ov_config)\n",
    "\n",
    "def infer(image):\n",
    "    image = det_validator.preprocess({\"img\":image,\"batch_idx\":torch.Tensor([0]),\n",
    "                                      \"cls\":torch.Tensor([0]),\n",
    "                                      \"bboxes\":torch.Tensor([0.,0.,0.,0.])})[\"img\"]\n",
    "    results = det_compiled_model(image)\n",
    "    preds = torch.from_numpy(results[det_compiled_model.output(0)])\n",
    "    return det_validator.postprocess(preds) #torch.from_numpy(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_img = np.random.random(size=(2,3,1280,1280))\n",
    "preds = det_compiled_model(dummy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([array([[[     7.4219,      14.062,      20.094, ...,        1202,        1235,        1263],\n",
       "        [     7.6016,      5.3047,      5.6641, ...,        1272,        1271,        1275],\n",
       "        [     13.695,      19.766,       26.25, ...,      174.75,      178.38,      200.38],\n",
       "        [     14.992,      13.727,      13.766, ...,         186,       187.5,      201.12],\n",
       "        [ 0.00034332,  0.00015843,  0.00010151, ...,           0,           0,           0],\n",
       "        [  -0.066345,   -0.036407,   -0.020706, ...,     -0.6333,    -0.64941,    -0.68408]],\n",
       "\n",
       "       [[     8.1875,      14.195,      21.688, ...,        1202,        1235,        1263],\n",
       "        [     5.7344,      5.4609,      5.7891, ...,        1272,        1271,        1275],\n",
       "        [     14.961,      21.109,      28.531, ...,      176.25,         179,      200.75],\n",
       "        [     13.141,      13.938,      15.023, ...,      186.75,      188.25,      201.12],\n",
       "        [ 0.00013232,  9.9957e-05,           0, ...,           0,           0,           0],\n",
       "        [    -0.0625,   -0.042542,    -0.02684, ...,    -0.63477,    -0.64893,    -0.68359]]], dtype=float32)])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(IMAGE_PATH)\n",
    "image = F.PILToTensor()(image)[None,:,:1280,:1280]\n",
    "# _ = infer(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with pt\n",
    "model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\",task='obb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 894.2ms\n",
      "Speed: 0.0ms preprocess, 894.2ms inference, 0.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'wildlife'}\n",
       " obb: ultralytics.engine.results.OBB object\n",
       " orig_img: array([[[130, 111,  79],\n",
       "         [129, 110,  78],\n",
       "         [128, 109,  77],\n",
       "         ...,\n",
       "         [157, 139, 103],\n",
       "         [168, 150, 114],\n",
       "         [173, 155, 119]],\n",
       " \n",
       "        [[130, 111,  79],\n",
       "         [128, 109,  77],\n",
       "         [127, 108,  76],\n",
       "         ...,\n",
       "         [152, 134,  98],\n",
       "         [158, 140, 104],\n",
       "         [165, 147, 111]],\n",
       " \n",
       "        [[129, 110,  78],\n",
       "         [127, 108,  76],\n",
       "         [125, 106,  74],\n",
       "         ...,\n",
       "         [147, 129,  93],\n",
       "         [151, 133,  97],\n",
       "         [163, 145, 109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[147, 131,  95],\n",
       "         [141, 125,  89],\n",
       "         [136, 120,  84],\n",
       "         ...,\n",
       "         [139, 121,  85],\n",
       "         [144, 125,  92],\n",
       "         [146, 127,  94]],\n",
       " \n",
       "        [[147, 129,  91],\n",
       "         [142, 124,  86],\n",
       "         [138, 120,  82],\n",
       "         ...,\n",
       "         [130, 112,  76],\n",
       "         [139, 120,  87],\n",
       "         [145, 126,  93]],\n",
       " \n",
       "        [[148, 130,  92],\n",
       "         [144, 126,  88],\n",
       "         [140, 122,  84],\n",
       "         ...,\n",
       "         [120, 102,  66],\n",
       "         [127, 111,  77],\n",
       "         [132, 116,  82]]], dtype=uint8)\n",
       " orig_shape: (1280, 1280)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\obb\\\\predict'\n",
       " speed: {'preprocess': 0.0, 'inference': 894.1519260406494, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with openvino\n",
    "model_vino = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",task='obb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 189.7ms\n",
      "Speed: 0.0ms preprocess, 189.7ms inference, 17.0ms postprocess per image at shape (1, 3, 1280, 1280)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'wildlife'}\n",
       " obb: ultralytics.engine.results.OBB object\n",
       " orig_img: array([[[130, 111,  79],\n",
       "         [129, 110,  78],\n",
       "         [128, 109,  77],\n",
       "         ...,\n",
       "         [157, 139, 103],\n",
       "         [168, 150, 114],\n",
       "         [173, 155, 119]],\n",
       " \n",
       "        [[130, 111,  79],\n",
       "         [128, 109,  77],\n",
       "         [127, 108,  76],\n",
       "         ...,\n",
       "         [152, 134,  98],\n",
       "         [158, 140, 104],\n",
       "         [165, 147, 111]],\n",
       " \n",
       "        [[129, 110,  78],\n",
       "         [127, 108,  76],\n",
       "         [125, 106,  74],\n",
       "         ...,\n",
       "         [147, 129,  93],\n",
       "         [151, 133,  97],\n",
       "         [163, 145, 109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[147, 131,  95],\n",
       "         [141, 125,  89],\n",
       "         [136, 120,  84],\n",
       "         ...,\n",
       "         [139, 121,  85],\n",
       "         [144, 125,  92],\n",
       "         [146, 127,  94]],\n",
       " \n",
       "        [[147, 129,  91],\n",
       "         [142, 124,  86],\n",
       "         [138, 120,  82],\n",
       "         ...,\n",
       "         [130, 112,  76],\n",
       "         [139, 120,  87],\n",
       "         [145, 126,  93]],\n",
       " \n",
       "        [[148, 130,  92],\n",
       "         [144, 126,  88],\n",
       "         [140, 122,  84],\n",
       "         ...,\n",
       "         [120, 102,  66],\n",
       "         [127, 111,  77],\n",
       "         [132, 116,  82]]], dtype=uint8)\n",
       " orig_shape: (1280, 1280)\n",
       " path: 'image0.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\obb\\\\predict'\n",
       " speed: {'preprocess': 0.0, 'inference': 189.741849899292, 'postprocess': 16.979455947875977}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vino(image/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CPU', 'GPU', 'NPU']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core.available_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2024 13:35:56 - INFO - datalabeling.annotator.models -   Computing device: cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO CUMULATIVE_THROUGHPUT mode for batch=16 inference...\n"
     ]
    }
   ],
   "source": [
    "sahi_model_obb = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                    confidence_threshold=0.6,\n",
    "                    overlap_ratio=0.1,\n",
    "                    tilesize=640,\n",
    "                    is_yolo_obb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 3000)\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"D:\\savmap_dataset_v2\\images\\0d1ba3c424ad4414ac37dbd0c93460ea.JPG\"\n",
    "image = Image.open(image_path)\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 42 slices.\n"
     ]
    }
   ],
   "source": [
    "result = sahi_model_obb.predict(image,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sahi.prediction.PredictionResult at 0x26dab692300>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.export_visuals('../.tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"D:\\PhD\\Data per camp\\Dry season\\Kapiri\\Camp 6-8\\Rep 1 - tiled\\DJI_20231003081043_0016_1.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(tile)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO data_config.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "from arguments import Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label mapping\n",
    "args = Arguments()\n",
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\label_mapping.json\",'r') as file:\n",
    "    label_map = json.load(file)\n",
    "names = [p['name'] for p in label_map if p['name'] not in args.discard_labels ]\n",
    "label_map = dict(zip(range(len(names)),names))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_config.update({'names':label_map,'nc':len(label_map)})\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\",'w') as file:\n",
    "    yaml.dump(yolo_config,file,default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\Extra training data\\WAID\\data_config.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = yolo_config['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "\n",
    "path_dataset = os.path.join(yolo_config['path'],yolo_config[split][0])\n",
    "path_dataset = path_dataset.replace('images','labels')\n",
    "\n",
    "path_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "\n",
    "for txtfile in Path(path_dataset).glob(\"*.txt\"):\n",
    "\n",
    "    df = pd.read_csv(txtfile,sep=\" \",names = ['class','x','y','w','h'] )\n",
    "    df['class'] = df['class'].astype(int)    \n",
    "    df['image'] = txtfile.stem\n",
    "    labels.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(labels,axis=0)\n",
    "df['class'] = df['class'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_class = dict()\n",
    "for cls in df['class'].unique():\n",
    "    num_imge = df.loc[df['class'] == cls,'image'].unique().shape[0]\n",
    "    images_per_class[cls] = num_imge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Split:\", split)\n",
    "print(images_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Split:',split)\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts().plot(kind='bar',figsize=(10,5),logy=True,title=f\"{split} label distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing metrics on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "path = r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\base_models_weights\\yolov8-wildai-obb.pt\"\n",
    "# path = r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\base_models_weights\\yolov5su.pt\"\n",
    "model = YOLO(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\images\\01f1653a94f14044bf11d78c5b4221d1.JPG: 480x640 1815.5ms\n",
      "Speed: 17.0ms preprocess, 1815.5ms inference, 9.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\images\\01f1653a94f14044bf11d78c5b4221d1.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.OBB object with attributes:\n",
       " \n",
       " cls: tensor([0., 0., 0., 0.])\n",
       " conf: tensor([0.6630, 0.3514, 0.2796, 0.2695])\n",
       " data: tensor([[6.8862e+02, 1.2766e+03, 8.7202e+01, 8.0733e+01, 1.4624e-01, 6.6303e-01, 0.0000e+00],\n",
       "         [2.7321e+02, 2.2809e+03, 7.7099e+01, 6.9344e+01, 1.9605e+00, 3.5140e-01, 0.0000e+00],\n",
       "         [6.2843e+02, 1.4832e+03, 7.9159e+01, 5.8002e+01, 4.8534e-01, 2.7962e-01, 0.0000e+00],\n",
       "         [3.5846e+02, 1.2539e+03, 7.7243e+01, 6.7475e+01, 5.9167e-01, 2.6951e-01, 0.0000e+00]])\n",
       " id: None\n",
       " is_track: False\n",
       " orig_shape: (3000, 4000)\n",
       " shape: torch.Size([4, 7])\n",
       " xywhr: tensor([[6.8862e+02, 1.2766e+03, 8.7202e+01, 8.0733e+01, 1.4624e-01],\n",
       "         [2.7321e+02, 2.2809e+03, 7.7099e+01, 6.9344e+01, 1.9605e+00],\n",
       "         [6.2843e+02, 1.4832e+03, 7.9159e+01, 5.8002e+01, 4.8534e-01],\n",
       "         [3.5846e+02, 1.2539e+03, 7.7243e+01, 6.7475e+01, 5.9167e-01]])\n",
       " xyxy: tensor([[ 639.5987, 1230.2849,  737.6347, 1322.8635],\n",
       "         [ 226.4875, 2232.0591,  319.9226, 2329.7217],\n",
       "         [ 579.8905, 1439.1091,  676.9661, 1527.3413],\n",
       "         [ 307.5852, 1204.3851,  409.3313, 1303.4718]])\n",
       " xyxyxyxy: tensor([[[ 725.8702, 1322.8635],\n",
       "          [ 737.6347, 1242.9922],\n",
       "          [ 651.3632, 1230.2849],\n",
       "          [ 639.5987, 1310.1562]],\n",
       " \n",
       "         [[ 226.4875, 2303.3784],\n",
       "          [ 290.6331, 2329.7217],\n",
       "          [ 319.9226, 2258.4023],\n",
       "          [ 255.7770, 2232.0591]],\n",
       " \n",
       "         [[ 649.9075, 1527.3413],\n",
       "          [ 676.9661, 1476.0374],\n",
       "          [ 606.9491, 1439.1091],\n",
       "          [ 579.8905, 1490.4131]],\n",
       " \n",
       "         [[ 371.6975, 1303.4718],\n",
       "          [ 409.3313, 1247.4669],\n",
       "          [ 345.2190, 1204.3851],\n",
       "          [ 307.5852, 1260.3900]]])\n",
       " xyxyxyxyn: tensor([[[0.1815, 0.4410],\n",
       "          [0.1844, 0.4143],\n",
       "          [0.1628, 0.4101],\n",
       "          [0.1599, 0.4367]],\n",
       " \n",
       "         [[0.0566, 0.7678],\n",
       "          [0.0727, 0.7766],\n",
       "          [0.0800, 0.7528],\n",
       "          [0.0639, 0.7440]],\n",
       " \n",
       "         [[0.1625, 0.5091],\n",
       "          [0.1692, 0.4920],\n",
       "          [0.1517, 0.4797],\n",
       "          [0.1450, 0.4968]],\n",
       " \n",
       "         [[0.0929, 0.4345],\n",
       "          [0.1023, 0.4158],\n",
       "          [0.0863, 0.4015],\n",
       "          [0.0769, 0.4201]]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[result.obb for result in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 639.5987, 1230.2849,  737.6347, 1322.8635],\n",
       "        [ 226.4875, 2232.0591,  319.9226, 2329.7217],\n",
       "        [ 579.8905, 1439.1091,  676.9661, 1527.3413],\n",
       "        [ 307.5852, 1204.3851,  409.3313, 1303.4718]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].obb.xyxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].obb.cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6630, 0.3514, 0.2796, 0.2695])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0].obb.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize validation settings\n",
    "validation_results = model.val(data=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\data_config.yaml\",\n",
    "                                imgsz=640,\n",
    "                                batch=8,\n",
    "                                conf=0.25,\n",
    "                                iou=0.5,\n",
    "                                device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "from datalabeling.annotator import Detector\n",
    "\n",
    "handler = Detector(path_to_weights=path,confidence_threshold=0.3)\n",
    "predictions = handler.predict_directory(r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
