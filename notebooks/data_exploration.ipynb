{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload pre-annotated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalabeling.annotator import Annotator\n",
    "# import pprint\n",
    "# import os\n",
    "# from dotenv import load_dotenv \n",
    "# from label_studio_ml.utils import get_local_path\n",
    "# from label_studio_sdk import Client\n",
    "# from PIL import Image\n",
    "# from time import time\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "handler = Annotator(path_to_weights=...,\n",
    "                    mlflow_model_version='5',\n",
    "                    dotenv_path='../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:   0%|          | 0/2 [00:00<?, ?it/s]07/31/2024 15:15:31 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 42 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions:  50%|█████     | 1/2 [00:17<00:17, 17.61s/it]07/31/2024 15:15:48 - WARNING - label_studio_tools.core.utils.io -   Using `localhost` (http://localhost:8080) in LABEL_STUDIO_URL, `localhost` is not accessible inside of docker containers. You can check your IP with utilities like `ifconfig` and set it as LABEL_STUDIO_URL.\n",
      "Uploading predictions:  50%|█████     | 1/2 [00:17<00:17, 17.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 42 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading predictions: 100%|██████████| 2/2 [00:34<00:00, 17.32s/it]\n"
     ]
    }
   ],
   "source": [
    "handler.upload_predictions(project_id=3,top_n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Savmap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = \"/Users/sfadel/Desktop/savmap\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "path_to_images = root #os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in range(len(polygons)):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    try:\n",
    "        width, height = Image.open(image_path).size\n",
    "    except:\n",
    "        continue\n",
    "    polygons['x_min'].iat[i] = int(x_min)\n",
    "    polygons['x_max'].iat[i] = int(x_max)\n",
    "    polygons['y_min'].iat[i] = int(y_min)\n",
    "    polygons['y_max'].iat[i] = int(y_max)\n",
    "    polygons['x'].iat[i] = round(0.5*(x_max+x_min))\n",
    "    polygons['y'].iat[i] = round(0.5*(y_max+y_min))\n",
    "    polygons['width'] = width\n",
    "    polygons['height'] = height\n",
    "\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGEUUID</th>\n",
       "      <th>TAGUUID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>bbox_w</th>\n",
       "      <th>bbox_h</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f77f4af5a1344b9086b307d2b4ba61ff</td>\n",
       "      <td>a9b3a2325dbe4a208bc3ae37eeb8e1e1</td>\n",
       "      <td>POLYGON ((1197 568, 1186 568, 1179 582, 1190 5...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33c79ba79aca4b06ae30a109e5cd868f</td>\n",
       "      <td>4999d35b3b8b407f8cbf48d95e689899</td>\n",
       "      <td>POLYGON ((2689 778, 2674 747, 2697 741, 2711 7...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IMAGEUUID                           TAGUUID  \\\n",
       "0  f77f4af5a1344b9086b307d2b4ba61ff  a9b3a2325dbe4a208bc3ae37eeb8e1e1   \n",
       "1  33c79ba79aca4b06ae30a109e5cd868f  4999d35b3b8b407f8cbf48d95e689899   \n",
       "\n",
       "                                            geometry x_min y_min x_max y_max  \\\n",
       "0  POLYGON ((1197 568, 1186 568, 1179 582, 1190 5...  None  None  None  None   \n",
       "1  POLYGON ((2689 778, 2674 747, 2697 741, 2711 7...  None  None  None  None   \n",
       "\n",
       "   width  height     x     y bbox_w bbox_h  class  \n",
       "0   4608    3456  None  None    NaN    NaN      0  \n",
       "1   4608    3456  None  None    NaN    NaN      0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2acac7c355f4454a96a6b60b813a1a1a.JPG</td>\n",
       "      <td>0</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>3298</td>\n",
       "      <td>2028</td>\n",
       "      <td>3345</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                filename  class  width  height  xmin  ymin  \\\n",
       "52  2acac7c355f4454a96a6b60b813a1a1a.JPG      0   4608    3456  3298  2028   \n",
       "\n",
       "    xmax  ymax  \n",
       "52  3345  2066  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select labels\n",
    "data = polygons.loc[:,['x_min','x_max','y_min','y_max','IMAGEUUID','width','height','class']].copy()\n",
    "data.rename(columns={'IMAGEUUID':'filename',\n",
    "                     'x_max':'xmax',\n",
    "                     'x_min':'xmin',\n",
    "                     'y_min':'ymin',\n",
    "                     'y_max':'ymax'},inplace=True)\n",
    "data['filename'] = data['filename'].apply(lambda x: f\"{x}.JPG\")\n",
    "data = data.dropna()\n",
    "data = data[['filename','class','width', 'height','xmin','ymin','xmax','ymax']]\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSV to COCO\n",
    "save_json_path = ... #'cocoformat.json'\n",
    "\n",
    "images = []\n",
    "categories = []\n",
    "annotations = []\n",
    "\n",
    "category = {}\n",
    "category[\"supercategory\"] = 'None'\n",
    "category[\"id\"] = 0\n",
    "category[\"category_name\"] = 'wildlife'\n",
    "categories.append(category)\n",
    "\n",
    "data['fileid'] = data['filename'].astype('category').cat.codes\n",
    "data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n",
    "# data['categoryid'] = data['categoryid']+1\n",
    "data['annid'] = data.index\n",
    "\n",
    "def image(row):\n",
    "    image = {}\n",
    "    image[\"height\"] = row.height\n",
    "    image[\"width\"] = row.width\n",
    "    image[\"id\"] = row.fileid\n",
    "    image[\"file_name\"] = row.filename\n",
    "    return image\n",
    "\n",
    "# def category(row):\n",
    "#     category = {}\n",
    "#     category[\"supercategory\"] = 'None'\n",
    "#     category[\"id\"] = row.categoryid\n",
    "#     category[\"category_name\"] = row[2]\n",
    "#     return category\n",
    "\n",
    "def annotation(row):\n",
    "    annotation = {}\n",
    "    area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
    "    annotation[\"segmentation\"] = []\n",
    "    annotation[\"iscrowd\"] = 0\n",
    "    annotation[\"area\"] = area\n",
    "    annotation[\"image_id\"] = row.fileid\n",
    "    annotation[\"score\"] = 1.0\n",
    "\n",
    "    annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
    "\n",
    "    annotation[\"category_id\"] = row.categoryid\n",
    "    annotation[\"id\"] = row.annid\n",
    "    return annotation\n",
    "\n",
    "for row in data.itertuples():\n",
    "    annotations.append(annotation(row))\n",
    "\n",
    "imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "for row in imagedf.itertuples():\n",
    "    images.append(image(row))\n",
    "\n",
    "# catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "# for row in catdf.itertuples():\n",
    "#     categories.append(category(row))\n",
    "\n",
    "data_coco = {}\n",
    "data_coco[\"images\"] = images\n",
    "data_coco[\"categories\"] = categories\n",
    "data_coco[\"annotations\"] = annotations\n",
    "# json.dump(data_coco, open(save_json_path, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = {annot['file_name']:[] for annot in data_coco['images']}\n",
    "for annot,image_data in zip(data_coco['annotations'],data_coco['images']):\n",
    "    annot.update(image_data)\n",
    "    # pprint.pp(annot)\n",
    "    annot['category_name'] = category['category_name']\n",
    "    groundtruth[annot['file_name']].append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 10/10 [00:00<00:00, 21.78it/s]  \n"
     ]
    }
   ],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "handler = Annotator(mlflow_model_alias='pt',\n",
    "                    mlflow_model_version=\"groundtruth\")\n",
    "directory_preds = handler.build_upload_json(path_img_dir='/Users/sfadel/Desktop/savmap',\n",
    "                                            root='/Users/sfadel',\n",
    "                                            bulk_predictions=groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to save data\n",
    "# with open('/Users/sfadel/Desktop/savmap/savmap_annotations_2014_labelstudio.json','w') as file:\n",
    "#     json.dump(directory_preds,file,indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image tiling for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanings of arguments\n",
    "- ```-ratioheight``` : proportion of tile  w.r.t height of image. Example 0.5 means dividing the image in two bands w.r.t height.\n",
    "- ```-ratiowidth``` : proportion of tile w.r.t to width of image. Example 1.0 means the width of the tile is the same as the image.\n",
    "- ```-overlapfactor``` : percentage of overlap. It should be less than 1.\n",
    "- ```-rmheight``` : percentage of height to remove or crop at bottom and top\n",
    "- ```-rmwidth``` : percentage of width to remove or crop on each side of the image\n",
    "- ```-pattern``` : \"**/*.JPG\" will get all .JPG images in directory and subdirectories. On windows it will get both .JPG and .jpg. On unix it will only get .JPG images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New script for tiling data\n",
    "# images_to_tile = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images\"\n",
    "# destination_directory = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images-tiled\"\n",
    "!python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Dry season\\Leopard rock\\Camp 22 + 37-40\\Rep 2\" 0 0 0 -overlapfactor 0.1  -ratiowidth 0.33334 -ratioheight 0.5 -rmheight 0.21 -rmwidth 0.08 -dest \"D:\\PhD\\Data per camp\\Dry season\\Leopard rock\\Camp 22 + 37-40\\Rep 2 - tiled\" -pattern \"**/*.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-annotating data for labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import Annotator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "handler = Annotator(mlflow_model_alias='cycle1')\n",
    "path_img_dir=r\"D:\\PhD\\Data per camp\\Dry season\\Leopard rock\\Camp 22 37-40\\Rep 2 - tiled\"\n",
    "root=\"D:\\\\\"\n",
    "save_json_path = os.path.join(Path(path_img_dir).parent,\n",
    "                              f\"{Path(path_img_dir).name}_preannotation_label-studio.json\")\n",
    "directory_preds = handler.build_upload_json(path_img_dir=path_img_dir,\n",
    "                                            root=root,\n",
    "                                            save_json_path=save_json_path,\n",
    "                                            pattern=\"**/*.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preprocessing import Annotator\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# from dotenv import load_dotenv \n",
    "# from label_studio_ml.utils import get_local_path\n",
    "# from label_studio_sdk import Client\n",
    "# from PIL import Image\n",
    "# from tqdm import tqdm\n",
    "\n",
    "\n",
    "# def upload_predictions(project_id:int,\n",
    "#                        annotator:Annotator,\n",
    "#                        dotenv_path:str):\n",
    "\n",
    "#     # Load environment variables\n",
    "#     load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "#     # Connect to the Label Studio API and check the connection\n",
    "#     LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "#     API_KEY = os.getenv(\"LABELSTUDIO-API-KEY\")      \n",
    "#     ls = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "\n",
    "#     # Select project\n",
    "#     project = ls.get_project(id=project_id)\n",
    "\n",
    "#     # Upload predictions for each task\n",
    "#     tasks = project.get_tasks()\n",
    "#     for task in tqdm(tasks,desc=\"Uploading predictions\"):\n",
    "#         task_id = task['id']\n",
    "#         img_url = task['data']['image']\n",
    "#         img_path = get_local_path(img_url)\n",
    "#         img = Image.open(img_path)\n",
    "#         prediction = annotator.predict(img)\n",
    "#         img_width, img_height = img.size\n",
    "#         formatted_pred = [annotator.format_prediction(pred,\n",
    "#                                                     img_height=img_height,\n",
    "#                                                     img_width=img_width) for pred in prediction]\n",
    "#         conf_scores = [pred['score'] for pred in prediction]\n",
    "#         max_score = 0.0\n",
    "#         if len(conf_scores)>0:\n",
    "#             max_score = max(conf_scores)\n",
    "#         project.create_prediction(task_id=task_id,\n",
    "#                             score=max_score,\n",
    "#                             result=formatted_pred,\n",
    "#                             model_version=annotator.modelversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_predictions(project_id=37,\n",
    "#                    annotator=Annotator(mlflow_model_alias='cycle1'),\n",
    "#                    dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.models.yolov8 import Yolov8DetectionModel\n",
    "from ultralytics import YOLO\n",
    "from sahi.predict import get_sliced_prediction\n",
    "import torch\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import json\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "from label_studio_ml.utils import get_local_path\n",
    "from label_studio_sdk import Client\n",
    "# from preprocessing import Annotator\n",
    "from copy import deepcopy\n",
    "\n",
    "class Annotator(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                dotenv_path:str='../.env',\n",
    "                path_to_weights:str=None,\n",
    "                mlflow_model_alias:str=\"cycle1\",\n",
    "                mlflow_model_name:str=\"detector\",\n",
    "                mlflow_model_version:str=None,\n",
    "                confidence_threshold:float=0.1):\n",
    "        \n",
    "        ## Load env variables\n",
    "        load_dotenv(dotenv_path=dotenv_path)\n",
    "        LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "        API_KEY = os.getenv(\"LABELSTUDIO-API-KEY\")      \n",
    "        self.labelstudio_client = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "\n",
    "        ## Load model from path\n",
    "        self.tilesize=640\n",
    "        self.overlapratio=0.1\n",
    "        self.sahi_prostprocess='NMS'\n",
    "        self.path_to_weights = path_to_weights\n",
    "        if self.path_to_weights is None:\n",
    "            ## Load  from mlflow\n",
    "            TRACKING_URI=\"http://localhost:5000\"\n",
    "            mlflow.set_tracking_uri(TRACKING_URI)\n",
    "            client = mlflow.MlflowClient()\n",
    "            name = mlflow_model_name\n",
    "            alias = mlflow_model_alias\n",
    "            version = client.get_model_version_by_alias(name=name,alias=alias).version\n",
    "            self.modelversion = f'{name}:{version}'\n",
    "            self.modelURI = f'models:/{name}/{version}'\n",
    "            self.model = mlflow.pyfunc.load_model(self.modelURI)\n",
    "        else:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "            print('Device:', device)\n",
    "            self.model = Yolov8DetectionModel(\n",
    "                                                        model=YOLO(path_to_weights,task='detect'),\n",
    "                                                        confidence_threshold=confidence_threshold,\n",
    "                                                        image_size=self.tilesize,\n",
    "                                                        device=device,\n",
    "                                                        )\n",
    "            self.modelversion = Path(path_to_weights).stem\n",
    "            \n",
    "        # LS label config\n",
    "        self.from_name = \"label\"\n",
    "        self.to_name = \"image\"\n",
    "        self.label_type = \"rectanglelabels\"\n",
    "        if mlflow_model_version is not None:\n",
    "            self.modelversion = mlflow_model_version\n",
    "\n",
    "    def predict(self, image:bytearray):\n",
    "\n",
    "        if self.path_to_weights is None:\n",
    "            return self.model.predict(image)\n",
    "        \n",
    "        result = get_sliced_prediction(image,\n",
    "                                        self.model,\n",
    "                                        slice_height=self.tilesize,\n",
    "                                        slice_width=self.tilesize,\n",
    "                                        overlap_height_ratio=self.overlapratio,\n",
    "                                        overlap_width_ratio=self.overlapratio,\n",
    "                                        postprocess_type=self.sahi_prostprocess,\n",
    "                                        )\n",
    "        return result.to_coco_annotations()\n",
    "\n",
    "    def format_prediction(self,pred:dict,img_height:int,img_width:int):\n",
    "        # formatting the prediction to work with Label studio\n",
    "        x, y, width, height = pred['bbox']\n",
    "        label = pred['category_name']\n",
    "        score = pred['score']\n",
    "        if not isinstance(score,float):\n",
    "            score = 0.0\n",
    "        template = {\n",
    "                    \"from_name\": self.from_name,\n",
    "                    \"to_name\": self.to_name,\n",
    "                    \"type\": self.label_type,\n",
    "                    \"original_width\":img_width,\n",
    "                    \"original_height\":img_height,\n",
    "                    \"image_rotation\":0,\n",
    "                    'value': {\n",
    "                        self.label_type: [label,],\n",
    "                        'x': x / img_width * 100,\n",
    "                        'y': y / img_height * 100,\n",
    "                        'width': width / img_width * 100,\n",
    "                        'height': height / img_height * 100,\n",
    "                        'rotation':0\n",
    "                    },\n",
    "                    'score': score\n",
    "        }\n",
    "        return template\n",
    "    \n",
    "    def upload_predictions(self,project_id:int):\n",
    "\n",
    "        # Select project\n",
    "        project = self.labelstudio_client.get_project(id=project_id)\n",
    "\n",
    "        # Upload predictions for each task\n",
    "        tasks = project.get_tasks()\n",
    "        for task in tqdm(tasks,desc=\"Uploading predictions\"):\n",
    "            task_id = task['id']\n",
    "            img_url = task['data']['image']\n",
    "            img_path = get_local_path(img_url)\n",
    "            img = Image.open(img_path)\n",
    "            prediction = self.predict(img)\n",
    "            img_width, img_height = img.size\n",
    "            formatted_pred = [self.format_prediction(pred,\n",
    "                                                    img_height=img_height,\n",
    "                                                    img_width=img_width) for pred in prediction]\n",
    "            conf_scores = [pred['score'] for pred in prediction]\n",
    "            max_score = 0.0\n",
    "            if len(conf_scores)>0:\n",
    "                max_score = max(conf_scores)\n",
    "            project.create_prediction(task_id=task_id,\n",
    "                                score=max_score,\n",
    "                                result=formatted_pred,\n",
    "                                model_version=self.modelversion)\n",
    "        \n",
    "    def build_upload_json(self,project_id:int,path_img_dir:str=None,root:str=None,\n",
    "                          pattern=\"*.JPG\",\n",
    "                          bulk_predictions:list[dict]=None,\n",
    "                          save_json_path:str=None):\n",
    "\n",
    "        directory_preds = list()\n",
    "        project = self.labelstudio_client.get_project(id=project_id)\n",
    "\n",
    "        # Upload predictions for each task\n",
    "        # for image_path in Path(path_img_dir).glob(pattern):\n",
    "        #     d=image_path.relative_to(Path(root)).as_posix()\n",
    "        tasks = project.get_tasks()\n",
    "        for task in tqdm(tasks,desc=\"Uploading predictions\"):\n",
    "            img_url = task['data']['image']\n",
    "            image_path = Path(get_local_path(img_url))\n",
    "            pred = { \n",
    "                        \"data\": {\"image\" : img_url},\n",
    "                        \"predictions\":[],\n",
    "                    }\n",
    "            # get predictions\n",
    "            if bulk_predictions is None:\n",
    "                start = time()\n",
    "                image = Image.open(image_path)\n",
    "                predictions = self.predict(image)\n",
    "                print(f'Prediction time:{time() - start:.3f} seconds.')\n",
    "                # format predictions\n",
    "                img_width, img_height = image.size\n",
    "                formatted_pred = [self.format_prediction(pred,\n",
    "                                                        img_height=img_height,\n",
    "                                                        img_width=img_width) for pred in predictions]\n",
    "            else:\n",
    "                predictions = bulk_predictions[image_path.name]\n",
    "                formatted_pred = [self.format_prediction(pred,\n",
    "                                                        img_height=pred['height'],\n",
    "                                                        img_width=pred['width']) for pred in predictions]\n",
    "            conf_scores = [pred['score'] for pred in predictions]\n",
    "            # store predictions\n",
    "            if len(conf_scores)>0:\n",
    "                pred['predictions'].append({'result':formatted_pred,\n",
    "                                            'model_version':self.modelversion,\n",
    "                                            'score':max(conf_scores),\n",
    "                                            }\n",
    "                                            )\n",
    "            else:\n",
    "                pred['predictions'].append({'result':formatted_pred,\n",
    "                                            'model_version':self.modelversion,\n",
    "                                            'score':0.0\n",
    "                                            }\n",
    "                                            )\n",
    "            # update buffer\n",
    "            directory_preds.append(pred)\n",
    "\n",
    "        if save_json_path is not None:\n",
    "            with open(Path(save_json_path),'w') as file:\n",
    "                json.dump(directory_preds,file,indent=2)\n",
    "\n",
    "        return directory_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "handler = Annotator(mlflow_model_alias='cycle1')\n",
    "# directory_preds = handler.build_upload_json(project_id=37)\n",
    "handler.upload_predictions(project_id=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_img_dir=r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images\"\n",
    "# save_json_path = os.path.join(Path(path_img_dir).parent,\n",
    "#                               f\"{Path(path_img_dir).name}_preannotation_label-studio.json\")\n",
    "# if save_json_path is not None:\n",
    "#             with open(Path(save_json_path),'w') as file:\n",
    "#                 json.dump(directory_preds,file,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(directory_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sahi.models.yolov8 import Yolov8DetectionModel\n",
    "# from ultralytics import YOLO\n",
    "# from sahi.predict import get_sliced_prediction\n",
    "# import torch\n",
    "from PIL import Image\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                path_to_weights:str,\n",
    "                confidence_threshold:float=0.3):\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.detection_model = Yolov8DetectionModel(\n",
    "                                                    # model_path=path_to_weights,\n",
    "                                                    model=YOLO(path_to_weights,task='detect'),\n",
    "                                                    confidence_threshold=confidence_threshold,\n",
    "                                                    image_size=640,\n",
    "                                                    device=device,\n",
    "                                                    )\n",
    "        self.tilesize=640\n",
    "        self.overlapratio=0.1\n",
    "        self.sahi_prostprocess='NMS'\n",
    "        print('Device:', device)\n",
    "        \n",
    "    def predict(self, image:str):\n",
    "        image = Image.open(image)\n",
    "        result = get_sliced_prediction(image, \n",
    "                                        self.detection_model,\n",
    "                                        slice_height=self.tilesize,\n",
    "                                        slice_width=self.tilesize,\n",
    "                                        overlap_height_ratio=self.overlapratio,\n",
    "                                        overlap_width_ratio=self.overlapratio,\n",
    "                                        postprocess_type=self.sahi_prostprocess,\n",
    "                                        ) \n",
    "\n",
    "        return result.to_coco_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"D:\\PhD\\Data per camp\\Dry season\\Kapiri\\Camp 6-8\\Rep 1 - tiled\\DJI_20231003081043_0016_1.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for ext in ['.pt','.onnx']:\n",
    "    path = r\"..\\base_models_weights\\yolov8.kaza\" + ext\n",
    "    model = Detector(path_to_weights=path,confidence_threshold=0.3)\n",
    "    start = time()\n",
    "    model.predict(image=image_path)\n",
    "    times.append((ext,time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = Path(r\"C:\\Users\\fadel\\OneDrive\\Bureau\\e-savior\\SAVMAP_samples\\00a033fefe644429a1e0fcffe88f8b39.JPG\")\n",
    "# directory = img_path.parent/'preprocessed'\n",
    "# directory.mkdir(parents=False,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = imread(str(img_path))\n",
    "# tilesize_h = 1000\n",
    "# tilesize_w = 1000\n",
    "# height, width, channels = data.shape \n",
    "# count = 0\n",
    "# for i,j in tqdm(product(list(range(0,height,tilesize_h)),list(range(0,width,tilesize_w)))):\n",
    "#     tile = data[i:min(i+tilesize_h,height),j:min(j+tilesize_w,width),:]\n",
    "#     count += 1\n",
    "#     filename = img_path.name.split('.')[0] + f'#{i}#{j}' + img_path.suffix\n",
    "#     savepath = directory/filename\n",
    "#     imsave(savepath,tile)\n",
    "#     #assert sum(tile.shape) == tilesize_h+tilesize_w+channels,f\"{tile.shape}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(tile)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height,width\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO data_config.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "from arguments import Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label mapping\n",
    "args = Arguments()\n",
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\label_mapping.json\",'r') as file:\n",
    "    label_map = json.load(file)\n",
    "names = [p['name'] for p in label_map if p['name'] not in args.discard_labels ]\n",
    "label_map = dict(zip(range(len(names)),names))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_config.update({'names':label_map,'nc':len(label_map)})\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\",'w') as file:\n",
    "    yaml.dump(yolo_config,file,default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\Extra training data\\WAID\\data_config.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = yolo_config['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "\n",
    "path_dataset = os.path.join(yolo_config['path'],yolo_config[split][0])\n",
    "path_dataset = path_dataset.replace('images','labels')\n",
    "\n",
    "path_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "\n",
    "for txtfile in Path(path_dataset).glob(\"*.txt\"):\n",
    "\n",
    "    df = pd.read_csv(txtfile,sep=\" \",names = ['class','x','y','w','h'] )\n",
    "    df['class'] = df['class'].astype(int)    \n",
    "    df['image'] = txtfile.stem\n",
    "    labels.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(labels,axis=0)\n",
    "df['class'] = df['class'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_class = dict()\n",
    "for cls in df['class'].unique():\n",
    "    num_imge = df.loc[df['class'] == cls,'image'].unique().shape[0]\n",
    "    images_per_class[cls] = num_imge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Split:\", split)\n",
    "print(images_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Split:',split)\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts().plot(kind='bar',figsize=(10,5),logy=True,title=f\"{split} label distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model\n",
    "path = r\"C:/Users/Machine Learning/Desktop/workspace-wildAI/datalabeling/runs/mlflow/382537255263464058/5cc559b1a98d487983b3defbabe95c5f/artifacts/weights/best.pt\"\n",
    "model = YOLO(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize validation settings\n",
    "validation_results = model.val(data=r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\", imgsz=640, batch=64, conf=0.25, iou=0.5, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sahi tutorials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sahi.slicing import slice_coco\n",
    "from sahi.utils.file import load_json\n",
    "from skimage.io import imread,imsave\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from arguments import Arguments\n",
    "from utils import save_df_as_yolo, sample_data, get_slices, convert_json_annotations_to_coco,COCO_DIR_PATH,JSON_DIR_PATH, save_tiles, ALL_CSV\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_dict = load_json(r\"..\\exported_annotations\\coco-format\\result.json\")\n",
    "coco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_coco_dataset(input_dir=COCO_DIR_PATH):\n",
    "\n",
    "    def get_upload_img_dir(coco_annotation:dict):\n",
    "        directory = set([os.path.dirname(metadata['file_name']) for metadata in coco_annotation['images']])\n",
    "        assert len(directory)==1,'There should be one upload directory per annotation project'\n",
    "        return directory.pop() #list(directory)[0]\n",
    "\n",
    "    upload_img_dirs,coco_paths = list(),list()\n",
    "    for path in Path(input_dir).glob('*.json'):\n",
    "        annot = load_json(path)\n",
    "        upload_img_dirs.append(get_upload_img_dir(coco_annotation=annot))\n",
    "        coco_paths.append(path)\n",
    "    \n",
    "    return dict(zip(upload_img_dirs,coco_paths))\n",
    "\n",
    "load_coco_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_yolo_dataset(args:Arguments,ls_json_dir:str=JSON_DIR_PATH,clear_out_dir:bool=False,load_coco_existing:bool=False,ls_coco_dir:str=COCO_DIR_PATH):\n",
    "\n",
    "    #clear directories\n",
    "    if clear_out_dir:\n",
    "        for p in [args.dest_path_images,args.dest_path_labels,COCO_DIR_PATH]:\n",
    "            shutil.rmtree(p)\n",
    "            Path(p).mkdir(parents=True,exist_ok=True)\n",
    "    if load_coco_existing:\n",
    "        map_imgdir_cocopath = load_coco_dataset(ls_coco_dir)\n",
    "    else:\n",
    "        # convert  json to coco\n",
    "        map_imgdir_cocopath = convert_json_annotations_to_coco(input_dir=ls_json_dir)\n",
    "\n",
    "    # slice coco annotations and save tiles\n",
    "    for img_dir,cocopath in map_imgdir_cocopath.items():\n",
    "        # slice annotations\n",
    "        coco_dict_slices = get_slices(coco_annotation_file_path=cocopath,\n",
    "                            img_dir=img_dir,\n",
    "                            slice_height=args.height,\n",
    "                            slice_width=args.width,\n",
    "                            overlap_height_ratio=args.overlap_ratio,\n",
    "                            overlap_width_ratio=args.overlap_ratio,\n",
    "                            min_area_ratio=args.min_visibility\n",
    "                            )\n",
    "        # sample tiles\n",
    "        df_tiles = sample_data(coco_dict_slices=coco_dict_slices,\n",
    "                                empty_ratio=args.empty_ratio,\n",
    "                                out_csv_path=None,\n",
    "                                img_dir=img_dir,\n",
    "                                labels_to_discard=args.discard_labels\n",
    "                                )\n",
    "        return df_tiles\n",
    "        # save tiles\n",
    "        # save_tiles(df_tiles=df_tiles,\n",
    "        #            out_img_dir=args.dest_path_images,\n",
    "        #            clear_out_img_dir=False)\n",
    "        # # save labels in yolo format\n",
    "        # save_df_as_yolo(df_annotation=df_tiles[~df_tiles['x'].isna()].copy(),\n",
    "        #                 slice_height=args.height,\n",
    "        #                 slice_width=args.width,\n",
    "        #                 dest_path_labels=args.dest_path_labels)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.empty_ratio = 1\n",
    "df_tiles = build_yolo_dataset(args=args,clear_out_dir=False,load_coco_existing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tiles) - 1537*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiles['images'].iloc[:10].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = df_tiles.duplicated(['x0','x1','y0','y1','images'])\n",
    "df_tiles[~duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiles.duplicated(['images']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_annot = list()\n",
    "for image_name,df in df_tiles.groupby('images'):\n",
    "    # print(len(df),image_name)\n",
    "    num_annot.append(len(df))\n",
    "    # print(image_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(num_annot),max(num_annot),min(num_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2205+869"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(num_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(num_annot,bins=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
