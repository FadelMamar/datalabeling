{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image tiling for annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Meanings of arguments\n",
    "- ```-ratioheight``` : proportion of tile  w.r.t height of image. Example 0.5 means dividing the image in two bands w.r.t height.\n",
    "- ```-ratiowidth``` : proportion of tile w.r.t to width of image. Example 1.0 means the width of the tile is the same as the image.\n",
    "- ```-overlapfactor``` : percentage of overlap. It should be less than 1.\n",
    "- ```-rmheight``` : percentage of height to remove or crop at bottom and top\n",
    "- ```-rmwidth``` : percentage of width to remove or crop on each side of the image\n",
    "- ```-pattern``` : \"**/*.JPG\" will get all .JPG images in directory and subdirectories. On windows it will get both .JPG and .jpg. On unix it will only get .JPG images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnexpected end of JSON input. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# New script for tiling data\n",
    "# images_to_tile = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images\"\n",
    "# destination_directory = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images-tiled\"\n",
    "!python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Wet season\\Kapiri\\Camp 3\\DJI_202402051048_003_KapiriCamp3\" 0 0 0 -overlapfactor 0.1  -ratiowidth 0.5 -ratioheight 0.5 -rmheight 0 -rmwidth 0 -dest \"D:\\PhD\\Data per camp\\Wet season\\Kapiri\\Camp 3\\DJI_202402051048_003_KapiriCamp3 - tiled\" -pattern \"**/*.JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-annotating data for Labelstudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from datalabeling.annotator import Annotator\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a JSON file to be uuploaded to Label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "alias = \"last\" # the aliases are found in mlflow tracker UI, use \"last-1\" to use the previous model\n",
    "name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "handler = Annotator(mlflow_model_alias=alias,\n",
    "                    mlflow_model_name=name,\n",
    "                    is_yolo_obb= name.strip() == \"obb-detector\",\n",
    "                    # dotenv_path=\"../.env\"\n",
    "                    )\n",
    "path_img_dir=r\"D:\\PhD\\Africa Parks\\Liuwa aerial survey_ALL\\CENSUS 2019\\DAY 2 CENSUS 2019_CONVERTED\\AP 2019 day 2 - tiled\"\n",
    "root=\"D:\\\\\"\n",
    "save_json_path = os.path.join(Path(path_img_dir).parent, f\"{Path(path_img_dir).name}_preannotation_label-studio.json\")\n",
    "\n",
    "# build and saves json\n",
    "directory_preds = handler.build_upload_json(path_img_dir=path_img_dir,\n",
    "                                            root=root,\n",
    "                                            save_json_path=save_json_path,\n",
    "                                            pattern=\"**/*.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-annotating an existing project using Label studio API\n",
    "It seems that it will not work well (i.e. filtering) with older projects created prior to Label studio software update.\n",
    "It is the **recommended way of pre-annotating data in Labelstudio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "aliases = [\"version11\",]\n",
    "project_id = 40 # insert correct project_id by loooking at the url\n",
    "for alias in aliases:\n",
    "    name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "    handler = Annotator(mlflow_model_alias=alias,\n",
    "                        mlflow_model_name=name,\n",
    "                        confidence_threshold=0.15,\n",
    "                        is_yolo_obb=name.strip() == \"obb-detector\",\n",
    "                        dotenv_path=\"../.env\")\n",
    "    handler.upload_predictions(project_id=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the script below, make sure you have exported the annotations so you CAN revert back!!!**\n",
    "- CLEANING ANNOTATIONS that have been mistakenly saved with label=\"wildlife\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Cleaning annotations - NO WAY BACK\n",
    "name = \"obb-detector\"\n",
    "handler = Annotator(mlflow_model_alias=\"version6\",\n",
    "                        mlflow_model_name=name,\n",
    "                        confidence_threshold=0.25,\n",
    "                        is_yolo_obb=name.strip() == \"obb-detector\",\n",
    "                        dotenv_path=\"../.env\")\n",
    "\n",
    "# Select project\n",
    "project_id = 88\n",
    "project = handler.labelstudio_client.get_project(id=project_id)\n",
    "\n",
    "# Delete annotations saved with label \"wildlife\" assigned by the predictor\n",
    "tasks = project.get_tasks()\n",
    "for task in tqdm(tasks,desc=\"correcting annotations\"):\n",
    "        task_id = task['id']\n",
    "        img_url = task['data']['image']\n",
    "\n",
    "        if len(task[\"annotations\"][0]['result'])>1:\n",
    "            results_to_keep = []\n",
    "            annot_id = task[\"annotations\"][0][\"id\"]\n",
    "            for annot in task['annotations'][0]['result']:\n",
    "                if annot['value']['rectanglelabels'][0] != 'wildlife':\n",
    "                    results_to_keep.append(annot)\n",
    "                    # print(annot['value'],annot['id'],end=\"\\n\")\n",
    "            # print(f\"Updating annotations {annot_id} from task {task_id}.\")\n",
    "            # print(results_to_keep)\n",
    "            project.update_annotation(annot_id,result=results_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(task['annotations']), len(task['annotations'][0]['result']), task['id'], task[\"annotations\"][0][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task['annotations'][0]['result'][0] #['value']['rectanglelabels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_keep = []\n",
    "for annot in task['annotations'][0]['result']:\n",
    "    if annot['value']['rectanglelabels'][0] != 'wildlife':\n",
    "        results_to_keep.append(annot)\n",
    "        print(annot['value'],annot['id'],end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.update_annotation(annotation_id=...,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up inference on intel, make changes inn ultralytics/nn/autobackend.py:\n",
    "```\n",
    "- device_name = \"AUTO:NPU,GPU,CPU\" # CPU, GPU, NPU, AUTO,\"AUTO:GPU,NPU\"\n",
    "- inference_mode = \"LATENCY\" # OpenVINO inference modes are 'LATENCY', 'THROUGHPUT' (not recommended), or 'CUMULATIVE_THROUGHPUT'\n",
    "- LOGGER.info(f\"Using OpenVINO {inference_mode} mode for inference...\")\n",
    "- ov_compiled_model = core.compile_model(\n",
    "                ov_model,\n",
    "                device_name=device_name,  # AUTO selects best available device, do not modify\n",
    "                config={\"PERFORMANCE_HINT\": inference_mode,\n",
    "                        \"CACHE_DIR\": os.environ[\"OPENVINO_CACHE_MODEL\"]}, # make sure to set environment variable\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using path_to_weights\n",
    "# go to ultralytics.nn.autobackend to modify ov_compiled device to \"AUTO:NPU,GPU,CPU\"\n",
    "\n",
    "use_sliding_window=True\n",
    "\n",
    "handler = Annotator(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                    is_yolo_obb=True,\n",
    "                    tilesize=1280,\n",
    "                    overlapratio=0.1,\n",
    "                    use_sliding_window=use_sliding_window,\n",
    "                    confidence_threshold=0.5,\n",
    "                    device=\"NPU\", # \"cpu\", \"cuda\"\n",
    "                    tag_to_append=f\"-sahi:{use_sliding_window}\",\n",
    "                    dotenv_path=\"../.env\")\n",
    "\n",
    "project_id = 3 # insert correct project_id by loooking at the url\n",
    "top_n=10\n",
    "handler.upload_predictions(project_id=project_id,top_n=top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_ml.utils import get_local_path\n",
    "from urllib.parse import unquote, quote\n",
    "import os\n",
    "path = unquote(\"/data/local-files/?d=savmap_dataset_v2%5Cimages_splits%5C003a34ee6b7841e6851b8fe511ebe102_0.JPG\")\n",
    "get_local_path(path,download_resources=False)#,os.path.exists(get_local_path(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with Sahi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import time\n",
    "import numpy as np\n",
    "from datalabeling.annotator import Detector\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load env variable, loads model cache location!!\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = r\"D:\\savmap_dataset_v2\\images_splits\\00a033fefe644429a1e0fcffe88f8b39_1.JPG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing with Openvino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up inference on intel, make changes inn ultralytics/nn/autobackend.py:\n",
    "```\n",
    "- device_name = \"AUTO:NPU,GPU,CPU\" # CPU, GPU, NPU, AUTO,\"AUTO:GPU,NPU\"\n",
    "- inference_mode = \"LATENCY\" # OpenVINO inference modes are 'LATENCY', 'THROUGHPUT' (not recommended), or 'CUMULATIVE_THROUGHPUT'\n",
    "- LOGGER.info(f\"Using OpenVINO {inference_mode} mode for inference...\")\n",
    "- ov_compiled_model = core.compile_model(\n",
    "                ov_model,\n",
    "                device_name=device_name,  # AUTO selects best available device, do not modify\n",
    "                config={\"PERFORMANCE_HINT\": inference_mode,\n",
    "                        \"CACHE_DIR\": os.environ[\"OPENVINO_CACHE_MODEL\"]}, # make sure to set environment variable\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define detector\n",
    "# to speed up inference on intel, make\n",
    "model = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                confidence_threshold=0.1,\n",
    "                overlap_ratio=0.1,\n",
    "                tilesize=1280,\n",
    "                device='CPU',\n",
    "                use_sliding_window=False,\n",
    "                is_yolo_obb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(IMAGE_PATH)\n",
    "\n",
    "while True:\n",
    "    start_time = time.perf_counter()\n",
    "    print(model.predict(image,return_coco=True,nms_iou=0.5))\n",
    "    end_time = time.perf_counter()\n",
    "    print(f\"Device took {end_time-start_time:.2f} seconds.\")\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with openvino\n",
    "import openvino as ov\n",
    "import openvino.properties.hint as hints\n",
    "import torch\n",
    "import torchvision.transforms as F\n",
    "from ultralytics.utils import DEFAULT_CFG\n",
    "from ultralytics.cfg import get_cfg\n",
    "from ultralytics.data.converter import coco80_to_coco91_class\n",
    "\n",
    "# load validator\n",
    "args = get_cfg(cfg=DEFAULT_CFG)\n",
    "det_model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\")\n",
    "det_validator = det_model.task_map[det_model.task][\"validator\"](args=args)\n",
    "det_validator.is_coco = True\n",
    "det_validator.class_map = coco80_to_coco91_class()\n",
    "det_validator.names = det_model.model.names\n",
    "det_validator.metrics.names = det_validator.names\n",
    "det_validator.nc = det_model.model.model[-1].nc\n",
    "det_validator.stride = 32\n",
    "args = get_cfg(cfg=DEFAULT_CFG)\n",
    "det_model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\")\n",
    "\n",
    "core = ov.Core()\n",
    "det_model_path = r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\\best.xml\"\n",
    "det_ov_model = core.read_model(det_model_path)\n",
    "\n",
    "device = \"AUTO:NPU,GPU\" # CPU, NPU, GPU \"AUTO:NPU,GPU,CPU\" \n",
    "\n",
    "print(\"Available core devices: \",core.available_devices)\n",
    "\n",
    "# reshaping for batch prediction\n",
    "input_layer = det_ov_model.input(0)\n",
    "output_layer = det_ov_model.output(0)\n",
    "new_shape = ov.PartialShape([1, 3, 1280, 1280])\n",
    "det_ov_model.reshape({input_layer.any_name: new_shape})\n",
    "\n",
    "ov_config = {hints.performance_mode: hints.PerformanceMode.THROUGHPUT,\n",
    "             \"CACHE_DIR\": '../models/model_cache'}\n",
    "\n",
    "if (\"GPU\" in core.available_devices) and device==\"GPU\":\n",
    "    ov_config[\"GPU_DISABLE_WINOGRAD_CONVOLUTION\"] = \"YES\"\n",
    "det_compiled_model = core.compile_model(det_ov_model, device, ov_config)\n",
    "\n",
    "def infer(image):\n",
    "    image = det_validator.preprocess({\"img\":image,\"batch_idx\":torch.Tensor([0]),\n",
    "                                      \"cls\":torch.Tensor([0]),\n",
    "                                      \"bboxes\":torch.Tensor([0.,0.,0.,0.])})[\"img\"]\n",
    "    results = det_compiled_model(image)\n",
    "    preds = torch.from_numpy(results[det_compiled_model.output(0)])\n",
    "    return det_validator.postprocess(preds) #torch.from_numpy(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = Image.open(IMAGE_PATH)\n",
    "# image = F.PILToTensor()(image)[None,:,:1280,:1280]\n",
    "# infer(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with pt\n",
    "# model = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best.pt\",task='obb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescaling input images\n",
    "# model(image/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference with openvino\n",
    "# model_vino = YOLO(r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",task='obb')\n",
    "# model_vino(image/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sahi_model_obb = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "#                     confidence_threshold=0.6,\n",
    "#                     overlap_ratio=0.1,\n",
    "#                     tilesize=640,\n",
    "#                     is_yolo_obb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = r\"D:\\savmap_dataset_v2\\images\\0d1ba3c424ad4414ac37dbd0c93460ea.JPG\"\n",
    "# image = Image.open(image_path)\n",
    "# print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = sahi_model_obb.predict(image,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result\n",
    "# result.export_visuals('../.tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sahi inference calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "overlap_ratios = [0.1,0.2,0.3]\n",
    "tilesizes = [640,2*640,3*640]\n",
    "imgsz = [640,2*640,3*640]\n",
    "\n",
    "for ratio, tilesize, image_size in product(overlap_ratios,tilesizes,imgsz):\n",
    "    print(ratio,tilesize,image_size)\n",
    "    # Define detector\n",
    "    # to speed up inference on intel, make\n",
    "    model = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                    confidence_threshold=0.1,\n",
    "                    overlap_ratio=0.1,\n",
    "                    tilesize=2000,\n",
    "                    imgsz=1280,\n",
    "                    device='CPU',\n",
    "                    use_sliding_window=True,\n",
    "                    is_yolo_obb=True)\n",
    "    \n",
    "    #TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO data_config.yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import json\n",
    "from datalabeling.arguments import Arguments\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\DetectionDataset\\hard_samples\\train_ratio_20-seed_41.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(os.path.join(yolo_config[\"path\"],yolo_config['train']),header=None,names=['paths'])['paths'].to_list()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label mapping\n",
    "args = Arguments()\n",
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\label_mapping.json\",'r') as file:\n",
    "    label_map = json.load(file)\n",
    "names = [p['name'] for p in label_map if p['name'] not in args.discard_labels ]\n",
    "label_map = dict(zip(range(len(names)),names))\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from label_studio_sdk import Client\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "def get_ls_parsed_config(ls_json_path:str):\n",
    "\n",
    "    ls_client = None\n",
    "    if ls_client is None:\n",
    "        # Connect to the Label Studio API and check the connection\n",
    "        LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "        API_KEY = os.getenv(\"LABEL_STUDIO_API_KEY\")\n",
    "        labelstudio_client = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "\n",
    "    with open(ls_json_path,'r') as f:\n",
    "        ls_annotation = json.load(fp=f)\n",
    "    ids = set([annot['project'] for annot in ls_annotation])\n",
    "    assert len(ids)==1, \"annotations come from different project. Not allowed!\"\n",
    "    project_id = ids.pop()\n",
    "    project = labelstudio_client.get_project(id=project_id)\n",
    "\n",
    "    return project.parsed_label_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_config.update({'names':label_map,'nc':len(label_map)})\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"D:\\PhD\\Data per camp\\IdentificationDataset\\data_config.yaml\",'w') as file:\n",
    "    yaml.dump(yolo_config,file,default_flow_style=False, sort_keys=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize distribution per annotation project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalabeling.dataset import convert_json_annotations_to_coco, load_coco_annotations\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from dotenv import load_dotenv\n",
    "from label_studio_sdk import Client\n",
    "# from itertools import chain\n",
    "import traceback\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path=r\"..\\.env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "# Connect to the Label Studio API and check the connection\n",
    "LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "API_KEY = os.getenv(\"LABEL_STUDIO_API_KEY\")\n",
    "labelstudio_client = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_project_stats(project_id:int,annotator_id = 0):\n",
    "    \n",
    "    project = labelstudio_client.get_project(id=project_id)\n",
    "    num_images = dict()\n",
    "    # Iterating \n",
    "    tasks = project.get_tasks()\n",
    "     # because there is\n",
    "    labels = []\n",
    "\n",
    "    for task in tasks:\n",
    "        try:\n",
    "            result = task['annotations'][annotator_id]['result']\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "        img_labels = []\n",
    "        for annot in result:\n",
    "            img_labels = annot['value']['rectanglelabels'] + img_labels\n",
    "        labels = labels + img_labels\n",
    "        # update stats holder\n",
    "        for label in set(img_labels):\n",
    "            try:\n",
    "                num_images[label] += 1\n",
    "            except:\n",
    "                num_images[label] = 1\n",
    "\n",
    "    stats = {f\"{k}\":labels.count(k) for k in set(labels)}\n",
    "    print(\"Number of instances for each label is:\\n\",stats,end=\"\\n\\n\")\n",
    "    print(\"Number of images for each label is:\\n\",num_images)\n",
    "\n",
    "    return stats, num_images\n",
    "\n",
    "# get stats\n",
    "for project_id in [93,]:\n",
    "    get_project_stats(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_dir = r\"D:\\PhD\\Data per camp\\Exported annotations and labels\\Wet season - Rep 1\\all\\labelstudio\"\n",
    "dest_dir = Path(ls_dir).with_name(\"coco-format\")\n",
    "save_excel_path = Path(ls_dir).with_name(\"stats.xlsx\")\n",
    "\n",
    "# Uncomment to run if needed\n",
    "# convert_json_annotations_to_coco(input_dir=ls_dir,\n",
    "#                                  dest_dir_coco=str(dest_dir),\n",
    "#                                  ls_client=labelstudio_client,\n",
    "#                                  parse_ls_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_annotations_dict = load_coco_annotations(dest_dir)\n",
    "coco_annotations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_count(coco_annotation:dict):\n",
    "\n",
    "    result = Counter([annot['category_id'] for annot in coco_annotation['annotations']])\n",
    "\n",
    "    label_map = {cat['id']:cat['name'] for cat in coco_annotation['categories']}\n",
    "\n",
    "    result = {label_map[k]:v for k,v in result.items()}\n",
    "\n",
    "    return result\n",
    "\n",
    "label_stats = dict()\n",
    "\n",
    "for img_dir,coco_path in coco_annotations_dict.items():\n",
    "\n",
    "    with open(coco_path,'r') as f:\n",
    "        coco_annotation = json.load(fp=f)\n",
    "    \n",
    "    label_stats[img_dir] = get_labels_count(coco_annotation)\n",
    "\n",
    "label_stats = pd.DataFrame.from_dict(label_stats,orient='index').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save\n",
    "label_stats.to_excel(save_excel_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize splits' distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load yaml\n",
    "with open(r\"D:\\PhD\\Data per camp\\Extra training data\\WAID\\data_config.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "yolo_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = yolo_config['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "\n",
    "path_dataset = os.path.join(yolo_config['path'],yolo_config[split][0])\n",
    "path_dataset = path_dataset.replace('images','labels')\n",
    "\n",
    "path_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "\n",
    "for txtfile in Path(path_dataset).glob(\"*.txt\"):\n",
    "\n",
    "    df = pd.read_csv(txtfile,sep=\" \",names = ['class','x','y','w','h'] )\n",
    "    df['class'] = df['class'].astype(int)    \n",
    "    df['image'] = txtfile.stem\n",
    "    labels.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(labels,axis=0)\n",
    "df['class'] = df['class'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_class = dict()\n",
    "for cls in df['class'].unique():\n",
    "    num_imge = df.loc[df['class'] == cls,'image'].unique().shape[0]\n",
    "    images_per_class[cls] = num_imge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Split:\", split)\n",
    "print(images_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Split:',split)\n",
    "print(df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts().plot(kind='bar',figsize=(10,5),logy=True,title=f\"{split} label distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing metrics on Validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO or ultralytics models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# from pathlib import Path\n",
    "from datalabeling.train import remove_label_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnexpected end of JSON input. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# [IMPORTANT] Run this cell to convert the datasets to yolo format\n",
    "!python  ../tools/build_dataset.py --obb-to-yolo --data-config-yaml \"..\\data\\dataset_identification.yaml\" --skip\n",
    "!python  ../tools/build_dataset.py --obb-to-yolo --data-config-yaml \"..\\data\\dataset_identification-detection.yaml\" --skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting results for yolov12s : Detection and Identification\n",
    "paths = [\"...\", # Identification model weights\n",
    "         \"../runs/mlflow/140168774036374062/a59eda79d9444ff4befc561ac21da6b4/artifacts/weights/best.pt\" # Detection model weights\n",
    "        ]\n",
    "\n",
    "dataconfigs = [\n",
    "                # r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification.yaml\",\n",
    "               r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification-detection.yaml\"\n",
    "              ]\n",
    "\n",
    "imgsz = 800\n",
    "iou_threshold=0.45\n",
    "conf_threshold=0.235\n",
    "splits = [\n",
    "            # \"val\", \n",
    "          \"test\",\n",
    "          ]\n",
    "\n",
    "# remove label.cache files\n",
    "for dataconfig in dataconfigs:\n",
    "    remove_label_cache(data_config_yaml=dataconfig)\n",
    "\n",
    "for split in splits:\n",
    "    for path,dataconfig in zip(paths,dataconfigs):\n",
    "        print(\"\\n\",'-'*20,split,'-'*20)\n",
    "        model = YOLO(path)\n",
    "        model.info()\n",
    "        \n",
    "        # Customize validation settings\n",
    "        validation_results = model.val(data=dataconfig,\n",
    "                                        imgsz=imgsz,\n",
    "                                        batch=64,\n",
    "                                        split=split,\n",
    "                                        conf=conf_threshold,\n",
    "                                        iou=iou_threshold,\n",
    "                                        device=\"cuda\"\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PhD\\Data per camp\\IdentificationDataset\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\IdentificationDataset\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\IdentificationDataset\\test\\images\\../labels.cache does not exist.\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\images\\../labels.cache does not exist.\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLOv5s summary: 262 layers, 9,124,514 parameters, 0 gradients, 24.1 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLOv5s summary (fused): 193 layers, 9,113,858 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels... 1061 images, 21220 backgrounds, 0 corrupt: 100%|██████████| 22281/22281 [00:12<00:00, 1748.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 349/349 [01:29<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      22281       2585      0.487      0.406      0.443      0.255\n",
      "               buffalo         67        283      0.619      0.636      0.628      0.257\n",
      "                impala        170        515      0.816      0.353      0.595      0.376\n",
      "                 nyala        123        259      0.216      0.147      0.173     0.0992\n",
      "              nyala(m)         55         55      0.317      0.345        0.4      0.247\n",
      "                  roan        138        205      0.128      0.307      0.106     0.0621\n",
      "                 sable        532       1268      0.826      0.645      0.759       0.49\n",
      "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val15\u001b[0m\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLOv5s summary: 262 layers, 9,122,579 parameters, 0 gradients, 24.0 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLOv5s summary (fused): 193 layers, 9,111,923 parameters, 0 gradients, 23.8 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels... 1424 images, 28480 backgrounds, 0 corrupt: 100%|██████████| 29904/29904 [00:16<00:00, 1771.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 468/468 [02:00<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      29904       4034       0.84       0.72      0.809      0.476\n",
      "Speed: 0.2ms preprocess, 3.4ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\val16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Getting results for yolov5s : Detection and Identification\n",
    "paths = [\"../runs/mlflow/140168774036374062/87718ce84ce04dacac6ab8c92328eae7/artifacts/weights/best.pt\", # Identification model weights\n",
    "         \"../runs/mlflow/140168774036374062/e5e3bf93d34f48f1bb7d0a648530bb45/artifacts/weights/best.pt\" # Detection model weights\n",
    "        ]\n",
    "\n",
    "dataconfigs = [r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification.yaml\",\n",
    "               r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification-detection.yaml\"\n",
    "              ]\n",
    "\n",
    "imgsz = 800\n",
    "iou_threshold=0.45\n",
    "conf_threshold=0.235\n",
    "splits = [\n",
    "            # \"val\", \n",
    "          \"test\",\n",
    "          ]\n",
    "\n",
    "# remove label.cache files\n",
    "for dataconfig in dataconfigs:\n",
    "    remove_label_cache(data_config_yaml=dataconfig)\n",
    "\n",
    "for split in splits:\n",
    "    for path,dataconfig in zip(paths,dataconfigs):\n",
    "        print(\"\\n\",'-'*20,split,'-'*20)\n",
    "        model = YOLO(path)\n",
    "        model.info()\n",
    "        \n",
    "        # Customize validation settings\n",
    "        validation_results = model.val(data=dataconfig,\n",
    "                                        imgsz=imgsz,\n",
    "                                        batch=64,\n",
    "                                        split=split,\n",
    "                                        conf=conf_threshold,\n",
    "                                        iou=iou_threshold,\n",
    "                                        device=\"cuda\"\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/02/2025 12:22:01 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\IdentificationDataset\\train\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 12it [00:00, 119.58it/s]\n",
      "yolo->obb: 26it [00:00, 128.29it/s]\n",
      "yolo->obb: 40it [00:00, 129.84it/s]\n",
      "yolo->obb: 54it [00:00, 130.55it/s]\n",
      "yolo->obb: 68it [00:00, 131.84it/s]\n",
      "yolo->obb: 82it [00:00, 132.62it/s]\n",
      "yolo->obb: 96it [00:00, 133.50it/s]\n",
      "yolo->obb: 110it [00:00, 135.36it/s]\n",
      "yolo->obb: 124it [00:00, 134.57it/s]\n",
      "yolo->obb: 138it [00:01, 134.04it/s]\n",
      "yolo->obb: 152it [00:01, 133.25it/s]\n",
      "yolo->obb: 166it [00:01, 134.30it/s]\n",
      "yolo->obb: 180it [00:01, 134.65it/s]\n",
      "yolo->obb: 194it [00:01, 134.11it/s]\n",
      "yolo->obb: 208it [00:01, 132.96it/s]\n",
      "yolo->obb: 222it [00:01, 134.05it/s]\n",
      "yolo->obb: 236it [00:01, 133.69it/s]\n",
      "yolo->obb: 250it [00:01, 134.22it/s]\n",
      "yolo->obb: 264it [00:01, 132.66it/s]\n",
      "yolo->obb: 278it [00:02, 132.35it/s]\n",
      "yolo->obb: 292it [00:02, 131.75it/s]\n",
      "yolo->obb: 306it [00:02, 131.34it/s]\n",
      "yolo->obb: 320it [00:02, 132.55it/s]\n",
      "yolo->obb: 334it [00:02, 130.05it/s]\n",
      "yolo->obb: 348it [00:02, 130.51it/s]\n",
      "yolo->obb: 362it [00:02, 130.07it/s]\n",
      "yolo->obb: 376it [00:02, 132.01it/s]\n",
      "yolo->obb: 390it [00:02, 129.33it/s]\n",
      "yolo->obb: 403it [00:03, 128.30it/s]\n",
      "yolo->obb: 416it [00:03, 124.37it/s]\n",
      "yolo->obb: 430it [00:03, 128.27it/s]\n",
      "yolo->obb: 445it [00:03, 130.98it/s]\n",
      "yolo->obb: 460it [00:03, 133.60it/s]\n",
      "yolo->obb: 474it [00:03, 133.01it/s]\n",
      "yolo->obb: 488it [00:03, 129.31it/s]\n",
      "yolo->obb: 502it [00:03, 129.99it/s]\n",
      "yolo->obb: 516it [00:03, 127.97it/s]\n",
      "yolo->obb: 529it [00:04, 121.58it/s]\n",
      "yolo->obb: 542it [00:04, 121.44it/s]\n",
      "yolo->obb: 555it [00:04, 123.69it/s]\n",
      "yolo->obb: 568it [00:04, 124.30it/s]\n",
      "yolo->obb: 581it [00:04, 125.09it/s]\n",
      "yolo->obb: 594it [00:04, 125.29it/s]\n",
      "yolo->obb: 607it [00:04, 123.20it/s]\n",
      "yolo->obb: 620it [00:04, 122.56it/s]\n",
      "yolo->obb: 633it [00:04, 123.15it/s]\n",
      "yolo->obb: 646it [00:04, 122.18it/s]\n",
      "yolo->obb: 659it [00:05, 122.88it/s]\n",
      "yolo->obb: 673it [00:05, 126.59it/s]\n",
      "yolo->obb: 687it [00:05, 129.96it/s]\n",
      "yolo->obb: 701it [00:05, 130.09it/s]\n",
      "yolo->obb: 715it [00:05, 130.18it/s]\n",
      "yolo->obb: 729it [00:05, 127.00it/s]\n",
      "yolo->obb: 742it [00:05, 122.52it/s]\n",
      "yolo->obb: 755it [00:05, 121.43it/s]\n",
      "yolo->obb: 768it [00:05, 123.36it/s]\n",
      "yolo->obb: 783it [00:06, 128.25it/s]\n",
      "yolo->obb: 796it [00:06, 120.70it/s]\n",
      "yolo->obb: 810it [00:06, 124.53it/s]\n",
      "yolo->obb: 823it [00:06, 122.83it/s]\n",
      "yolo->obb: 836it [00:06, 115.01it/s]\n",
      "yolo->obb: 850it [00:06, 119.06it/s]\n",
      "yolo->obb: 863it [00:06, 121.12it/s]\n",
      "yolo->obb: 876it [00:06, 121.44it/s]\n",
      "yolo->obb: 889it [00:06, 122.69it/s]\n",
      "yolo->obb: 902it [00:07, 124.65it/s]\n",
      "yolo->obb: 915it [00:07, 124.63it/s]\n",
      "yolo->obb: 928it [00:07, 124.97it/s]\n",
      "yolo->obb: 941it [00:07, 119.02it/s]\n",
      "yolo->obb: 953it [00:07, 116.87it/s]\n",
      "yolo->obb: 966it [00:07, 119.11it/s]\n",
      "yolo->obb: 980it [00:07, 122.80it/s]\n",
      "yolo->obb: 994it [00:07, 125.78it/s]\n",
      "yolo->obb: 1008it [00:07, 128.62it/s]\n",
      "yolo->obb: 1021it [00:08, 127.41it/s]\n",
      "yolo->obb: 1034it [00:08, 126.20it/s]\n",
      "yolo->obb: 1048it [00:08, 128.57it/s]\n",
      "yolo->obb: 1062it [00:08, 129.86it/s]\n",
      "yolo->obb: 1076it [00:08, 129.29it/s]\n",
      "yolo->obb: 1090it [00:08, 130.73it/s]\n",
      "yolo->obb: 1104it [00:08, 129.52it/s]\n",
      "yolo->obb: 1117it [00:08, 126.63it/s]\n",
      "yolo->obb: 1130it [00:08, 125.28it/s]\n",
      "yolo->obb: 1143it [00:08, 125.07it/s]\n",
      "yolo->obb: 1156it [00:09, 126.36it/s]\n",
      "yolo->obb: 1170it [00:09, 128.32it/s]\n",
      "yolo->obb: 1185it [00:09, 132.89it/s]\n",
      "yolo->obb: 1199it [00:09, 133.27it/s]\n",
      "yolo->obb: 1213it [00:09, 132.39it/s]\n",
      "yolo->obb: 1227it [00:09, 131.78it/s]\n",
      "yolo->obb: 1241it [00:09, 134.01it/s]\n",
      "yolo->obb: 1255it [00:09, 133.63it/s]\n",
      "yolo->obb: 1270it [00:09, 137.05it/s]\n",
      "yolo->obb: 1284it [00:10, 136.97it/s]\n",
      "yolo->obb: 1298it [00:10, 135.73it/s]\n",
      "yolo->obb: 1313it [00:10, 137.73it/s]\n",
      "yolo->obb: 1328it [00:10, 140.34it/s]\n",
      "yolo->obb: 1343it [00:10, 140.95it/s]\n",
      "yolo->obb: 1358it [00:10, 140.97it/s]\n",
      "yolo->obb: 1373it [00:10, 137.07it/s]\n",
      "yolo->obb: 1388it [00:10, 138.59it/s]\n",
      "yolo->obb: 1404it [00:10, 142.11it/s]\n",
      "yolo->obb: 1419it [00:10, 142.59it/s]\n",
      "yolo->obb: 1434it [00:11, 142.93it/s]\n",
      "yolo->obb: 1449it [00:11, 144.82it/s]\n",
      "yolo->obb: 1464it [00:11, 144.49it/s]\n",
      "yolo->obb: 1479it [00:11, 145.53it/s]\n",
      "yolo->obb: 1494it [00:11, 142.91it/s]\n",
      "yolo->obb: 1509it [00:11, 143.57it/s]\n",
      "yolo->obb: 1524it [00:11, 143.20it/s]\n",
      "yolo->obb: 1539it [00:11, 142.91it/s]\n",
      "yolo->obb: 1554it [00:11, 141.93it/s]\n",
      "yolo->obb: 1569it [00:12, 140.84it/s]\n",
      "yolo->obb: 1584it [00:12, 140.90it/s]\n",
      "yolo->obb: 1599it [00:12, 139.75it/s]\n",
      "yolo->obb: 1614it [00:12, 140.13it/s]\n",
      "yolo->obb: 1629it [00:12, 140.79it/s]\n",
      "yolo->obb: 1644it [00:12, 139.28it/s]\n",
      "yolo->obb: 1658it [00:12, 138.17it/s]\n",
      "yolo->obb: 1673it [00:12, 140.17it/s]\n",
      "yolo->obb: 1688it [00:12, 137.68it/s]\n",
      "yolo->obb: 1702it [00:12, 137.03it/s]\n",
      "yolo->obb: 1716it [00:13, 137.75it/s]\n",
      "yolo->obb: 1730it [00:13, 136.67it/s]\n",
      "yolo->obb: 1744it [00:13, 136.31it/s]\n",
      "yolo->obb: 1759it [00:13, 138.35it/s]\n",
      "yolo->obb: 1773it [00:13, 138.29it/s]\n",
      "yolo->obb: 1787it [00:13, 135.46it/s]\n",
      "yolo->obb: 1802it [00:13, 137.93it/s]\n",
      "yolo->obb: 1817it [00:13, 137.65it/s]\n",
      "yolo->obb: 1832it [00:13, 138.66it/s]\n",
      "yolo->obb: 1846it [00:14, 136.55it/s]\n",
      "yolo->obb: 1860it [00:14, 134.31it/s]\n",
      "yolo->obb: 1874it [00:14, 135.41it/s]\n",
      "yolo->obb: 1889it [00:14, 138.29it/s]\n",
      "yolo->obb: 1904it [00:14, 140.32it/s]\n",
      "yolo->obb: 1919it [00:14, 142.95it/s]\n",
      "yolo->obb: 1934it [00:14, 144.02it/s]\n",
      "yolo->obb: 1949it [00:14, 145.20it/s]\n",
      "yolo->obb: 1964it [00:14, 144.71it/s]\n",
      "yolo->obb: 1979it [00:14, 144.41it/s]\n",
      "yolo->obb: 1994it [00:15, 145.90it/s]\n",
      "yolo->obb: 2009it [00:15, 144.82it/s]\n",
      "yolo->obb: 2024it [00:15, 143.66it/s]\n",
      "yolo->obb: 2039it [00:15, 143.27it/s]\n",
      "yolo->obb: 2054it [00:15, 141.37it/s]\n",
      "yolo->obb: 2069it [00:15, 140.07it/s]\n",
      "yolo->obb: 2084it [00:15, 141.15it/s]\n",
      "yolo->obb: 2099it [00:15, 141.47it/s]\n",
      "yolo->obb: 2114it [00:15, 141.34it/s]\n",
      "yolo->obb: 2129it [00:16, 141.24it/s]\n",
      "yolo->obb: 2144it [00:16, 141.53it/s]\n",
      "yolo->obb: 2159it [00:16, 140.98it/s]\n",
      "yolo->obb: 2174it [00:16, 140.99it/s]\n",
      "yolo->obb: 2189it [00:16, 141.80it/s]\n",
      "yolo->obb: 2204it [00:16, 140.77it/s]\n",
      "yolo->obb: 2219it [00:16, 138.11it/s]\n",
      "yolo->obb: 2233it [00:16, 136.57it/s]\n",
      "yolo->obb: 2247it [00:16, 135.09it/s]\n",
      "yolo->obb: 2261it [00:16, 136.36it/s]\n",
      "yolo->obb: 2275it [00:17, 135.31it/s]\n",
      "yolo->obb: 2289it [00:17, 134.58it/s]\n",
      "yolo->obb: 2303it [00:17, 133.68it/s]\n",
      "yolo->obb: 2317it [00:17, 131.56it/s]\n",
      "yolo->obb: 2331it [00:17, 131.17it/s]\n",
      "yolo->obb: 2345it [00:17, 130.94it/s]\n",
      "yolo->obb: 2359it [00:17, 127.90it/s]\n",
      "yolo->obb: 2372it [00:17, 126.93it/s]\n",
      "yolo->obb: 2385it [00:17, 126.24it/s]\n",
      "yolo->obb: 2398it [00:18, 125.39it/s]\n",
      "yolo->obb: 2411it [00:18, 126.58it/s]\n",
      "yolo->obb: 2426it [00:18, 131.34it/s]\n",
      "yolo->obb: 2441it [00:18, 134.66it/s]\n",
      "yolo->obb: 2455it [00:18, 135.67it/s]\n",
      "yolo->obb: 2470it [00:18, 139.31it/s]\n",
      "yolo->obb: 2485it [00:18, 140.65it/s]\n",
      "yolo->obb: 2500it [00:18, 142.40it/s]\n",
      "yolo->obb: 2515it [00:18, 143.76it/s]\n",
      "yolo->obb: 2530it [00:18, 145.02it/s]\n",
      "yolo->obb: 2545it [00:19, 145.05it/s]\n",
      "yolo->obb: 2560it [00:19, 143.39it/s]\n",
      "yolo->obb: 2575it [00:19, 140.65it/s]\n",
      "yolo->obb: 2590it [00:19, 141.16it/s]\n",
      "yolo->obb: 2605it [00:19, 140.32it/s]\n",
      "yolo->obb: 2620it [00:19, 142.54it/s]\n",
      "yolo->obb: 2635it [00:19, 142.08it/s]\n",
      "yolo->obb: 2650it [00:19, 138.57it/s]\n",
      "yolo->obb: 2664it [00:19, 134.25it/s]\n",
      "yolo->obb: 2678it [00:20, 132.38it/s]\n",
      "yolo->obb: 2692it [00:20, 133.26it/s]\n",
      "yolo->obb: 2706it [00:20, 128.08it/s]\n",
      "yolo->obb: 2718it [00:20, 133.35it/s]\n",
      "03/02/2025 12:22:21 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\IdentificationDataset\\val\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 26it [00:00, 259.10it/s]\n",
      "yolo->obb: 54it [00:00, 266.13it/s]\n",
      "yolo->obb: 81it [00:00, 266.25it/s]\n",
      "yolo->obb: 109it [00:00, 271.25it/s]\n",
      "yolo->obb: 138it [00:00, 275.54it/s]\n",
      "yolo->obb: 167it [00:00, 278.20it/s]\n",
      "yolo->obb: 195it [00:00, 278.47it/s]\n",
      "yolo->obb: 223it [00:00, 276.90it/s]\n",
      "yolo->obb: 252it [00:00, 278.06it/s]\n",
      "yolo->obb: 281it [00:01, 278.84it/s]\n",
      "yolo->obb: 310it [00:01, 279.38it/s]\n",
      "yolo->obb: 339it [00:01, 280.49it/s]\n",
      "yolo->obb: 368it [00:01, 275.63it/s]\n",
      "yolo->obb: 396it [00:01, 275.01it/s]\n",
      "yolo->obb: 424it [00:01, 275.31it/s]\n",
      "yolo->obb: 452it [00:01, 275.59it/s]\n",
      "yolo->obb: 480it [00:01, 274.18it/s]\n",
      "yolo->obb: 508it [00:01, 274.80it/s]\n",
      "yolo->obb: 536it [00:01, 276.05it/s]\n",
      "yolo->obb: 564it [00:02, 275.30it/s]\n",
      "yolo->obb: 592it [00:02, 272.36it/s]\n",
      "yolo->obb: 620it [00:02, 270.34it/s]\n",
      "yolo->obb: 649it [00:02, 274.21it/s]\n",
      "yolo->obb: 677it [00:02, 275.62it/s]\n",
      "yolo->obb: 706it [00:02, 277.86it/s]\n",
      "yolo->obb: 734it [00:02, 277.38it/s]\n",
      "yolo->obb: 755it [00:02, 275.36it/s]\n",
      "03/02/2025 12:22:24 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 27it [00:00, 269.07it/s]\n",
      "yolo->obb: 54it [00:00, 269.06it/s]\n",
      "yolo->obb: 82it [00:00, 271.14it/s]\n",
      "yolo->obb: 110it [00:00, 270.00it/s]\n",
      "yolo->obb: 138it [00:00, 269.38it/s]\n",
      "yolo->obb: 166it [00:00, 272.60it/s]\n",
      "yolo->obb: 194it [00:00, 272.04it/s]\n",
      "yolo->obb: 222it [00:00, 274.14it/s]\n",
      "yolo->obb: 250it [00:00, 275.65it/s]\n",
      "yolo->obb: 279it [00:01, 277.19it/s]\n",
      "yolo->obb: 308it [00:01, 279.08it/s]\n",
      "yolo->obb: 337it [00:01, 280.28it/s]\n",
      "yolo->obb: 366it [00:01, 281.21it/s]\n",
      "yolo->obb: 395it [00:01, 281.85it/s]\n",
      "yolo->obb: 424it [00:01, 281.46it/s]\n",
      "yolo->obb: 453it [00:01, 282.02it/s]\n",
      "yolo->obb: 482it [00:01, 282.32it/s]\n",
      "yolo->obb: 511it [00:01, 282.62it/s]\n",
      "yolo->obb: 540it [00:01, 281.18it/s]\n",
      "yolo->obb: 569it [00:02, 281.00it/s]\n",
      "yolo->obb: 598it [00:02, 280.87it/s]\n",
      "yolo->obb: 627it [00:02, 280.79it/s]\n",
      "yolo->obb: 656it [00:02, 281.54it/s]\n",
      "yolo->obb: 685it [00:02, 278.81it/s]\n",
      "yolo->obb: 713it [00:02, 278.87it/s]\n",
      "yolo->obb: 742it [00:02, 280.20it/s]\n",
      "yolo->obb: 771it [00:02, 281.06it/s]\n",
      "yolo->obb: 800it [00:02, 280.91it/s]\n",
      "yolo->obb: 829it [00:02, 280.81it/s]\n",
      "yolo->obb: 858it [00:03, 281.56it/s]\n",
      "yolo->obb: 887it [00:03, 282.09it/s]\n",
      "yolo->obb: 916it [00:03, 282.46it/s]\n",
      "yolo->obb: 945it [00:03, 282.72it/s]\n",
      "yolo->obb: 974it [00:03, 282.90it/s]\n",
      "yolo->obb: 1003it [00:03, 281.38it/s]\n",
      "yolo->obb: 1032it [00:03, 282.79it/s]\n",
      "yolo->obb: 1061it [00:03, 282.95it/s]\n",
      "yolo->obb: 1061it [00:03, 279.61it/s]\n",
      "03/02/2025 12:22:31 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\train\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 26it [00:00, 259.10it/s]\n",
      "yolo->obb: 54it [00:00, 269.07it/s]\n",
      "yolo->obb: 83it [00:00, 276.88it/s]\n",
      "yolo->obb: 112it [00:00, 279.44it/s]\n",
      "yolo->obb: 141it [00:00, 281.85it/s]\n",
      "yolo->obb: 170it [00:00, 281.41it/s]\n",
      "yolo->obb: 199it [00:00, 282.95it/s]\n",
      "yolo->obb: 228it [00:00, 282.19it/s]\n",
      "yolo->obb: 257it [00:00, 280.82it/s]\n",
      "yolo->obb: 286it [00:01, 281.59it/s]\n",
      "yolo->obb: 315it [00:01, 282.12it/s]\n",
      "yolo->obb: 344it [00:01, 280.82it/s]\n",
      "yolo->obb: 373it [00:01, 280.74it/s]\n",
      "yolo->obb: 402it [00:01, 280.69it/s]\n",
      "yolo->obb: 431it [00:01, 281.41it/s]\n",
      "yolo->obb: 460it [00:01, 282.82it/s]\n",
      "yolo->obb: 489it [00:01, 282.97it/s]\n",
      "yolo->obb: 518it [00:01, 283.08it/s]\n",
      "yolo->obb: 547it [00:01, 283.15it/s]\n",
      "yolo->obb: 576it [00:02, 283.21it/s]\n",
      "yolo->obb: 605it [00:02, 284.08it/s]\n",
      "yolo->obb: 634it [00:02, 283.85it/s]\n",
      "yolo->obb: 663it [00:02, 283.69it/s]\n",
      "yolo->obb: 692it [00:02, 284.42it/s]\n",
      "yolo->obb: 721it [00:02, 284.09it/s]\n",
      "yolo->obb: 750it [00:02, 283.86it/s]\n",
      "yolo->obb: 779it [00:02, 283.63it/s]\n",
      "yolo->obb: 808it [00:02, 283.54it/s]\n",
      "yolo->obb: 837it [00:02, 283.47it/s]\n",
      "yolo->obb: 866it [00:03, 284.27it/s]\n",
      "yolo->obb: 895it [00:03, 283.07it/s]\n",
      "yolo->obb: 924it [00:03, 283.15it/s]\n",
      "yolo->obb: 953it [00:03, 283.20it/s]\n",
      "yolo->obb: 982it [00:03, 283.24it/s]\n",
      "yolo->obb: 1011it [00:03, 284.10it/s]\n",
      "yolo->obb: 1040it [00:03, 283.03it/s]\n",
      "yolo->obb: 1069it [00:03, 282.29it/s]\n",
      "yolo->obb: 1098it [00:03, 283.43it/s]\n",
      "yolo->obb: 1127it [00:03, 282.57it/s]\n",
      "yolo->obb: 1156it [00:04, 282.80it/s]\n",
      "yolo->obb: 1185it [00:04, 282.96it/s]\n",
      "yolo->obb: 1214it [00:04, 282.24it/s]\n",
      "yolo->obb: 1243it [00:04, 282.56it/s]\n",
      "yolo->obb: 1272it [00:04, 282.79it/s]\n",
      "yolo->obb: 1301it [00:04, 282.95it/s]\n",
      "yolo->obb: 1330it [00:04, 282.24it/s]\n",
      "yolo->obb: 1359it [00:04, 282.56it/s]\n",
      "yolo->obb: 1388it [00:04, 282.79it/s]\n",
      "yolo->obb: 1417it [00:05, 282.12it/s]\n",
      "yolo->obb: 1446it [00:05, 283.31it/s]\n",
      "yolo->obb: 1475it [00:05, 281.56it/s]\n",
      "yolo->obb: 1504it [00:05, 281.27it/s]\n",
      "yolo->obb: 1533it [00:05, 280.97it/s]\n",
      "yolo->obb: 1562it [00:05, 281.68it/s]\n",
      "yolo->obb: 1591it [00:05, 282.17it/s]\n",
      "yolo->obb: 1620it [00:05, 281.69it/s]\n",
      "yolo->obb: 1649it [00:05, 281.35it/s]\n",
      "yolo->obb: 1678it [00:05, 280.30it/s]\n",
      "yolo->obb: 1707it [00:06, 281.20it/s]\n",
      "yolo->obb: 1736it [00:06, 281.02it/s]\n",
      "yolo->obb: 1765it [00:06, 277.65it/s]\n",
      "yolo->obb: 1794it [00:06, 278.52it/s]\n",
      "yolo->obb: 1822it [00:06, 277.86it/s]\n",
      "yolo->obb: 1850it [00:06, 276.62it/s]\n",
      "yolo->obb: 1879it [00:06, 279.44it/s]\n",
      "yolo->obb: 1908it [00:06, 280.53it/s]\n",
      "yolo->obb: 1937it [00:06, 282.20it/s]\n",
      "yolo->obb: 1966it [00:06, 281.71it/s]\n",
      "yolo->obb: 1995it [00:07, 282.19it/s]\n",
      "yolo->obb: 2024it [00:07, 281.71it/s]\n",
      "yolo->obb: 2053it [00:07, 281.37it/s]\n",
      "yolo->obb: 2082it [00:07, 281.13it/s]\n",
      "yolo->obb: 2111it [00:07, 280.15it/s]\n",
      "yolo->obb: 2140it [00:07, 279.46it/s]\n",
      "yolo->obb: 2169it [00:07, 281.43it/s]\n",
      "yolo->obb: 2198it [00:07, 281.17it/s]\n",
      "yolo->obb: 2227it [00:07, 280.99it/s]\n",
      "yolo->obb: 2256it [00:08, 273.69it/s]\n",
      "yolo->obb: 2284it [00:08, 271.31it/s]\n",
      "yolo->obb: 2313it [00:08, 275.55it/s]\n",
      "yolo->obb: 2342it [00:08, 277.85it/s]\n",
      "yolo->obb: 2371it [00:08, 280.29it/s]\n",
      "yolo->obb: 2400it [00:08, 282.02it/s]\n",
      "yolo->obb: 2429it [00:08, 282.41it/s]\n",
      "yolo->obb: 2458it [00:08, 283.52it/s]\n",
      "yolo->obb: 2487it [00:08, 284.30it/s]\n",
      "yolo->obb: 2516it [00:08, 284.85it/s]\n",
      "yolo->obb: 2545it [00:09, 284.39it/s]\n",
      "yolo->obb: 2574it [00:09, 284.91it/s]\n",
      "yolo->obb: 2603it [00:09, 284.12it/s]\n",
      "yolo->obb: 2632it [00:09, 283.88it/s]\n",
      "yolo->obb: 2661it [00:09, 283.71it/s]\n",
      "yolo->obb: 2690it [00:09, 284.35it/s]\n",
      "yolo->obb: 2719it [00:09, 284.88it/s]\n",
      "yolo->obb: 2748it [00:09, 285.26it/s]\n",
      "yolo->obb: 2777it [00:09, 285.52it/s]\n",
      "yolo->obb: 2806it [00:09, 285.70it/s]\n",
      "yolo->obb: 2835it [00:10, 284.99it/s]\n",
      "yolo->obb: 2864it [00:10, 285.33it/s]\n",
      "yolo->obb: 2893it [00:10, 285.49it/s]\n",
      "yolo->obb: 2922it [00:10, 285.68it/s]\n",
      "yolo->obb: 2951it [00:10, 284.97it/s]\n",
      "yolo->obb: 2980it [00:10, 284.48it/s]\n",
      "yolo->obb: 3009it [00:10, 284.97it/s]\n",
      "yolo->obb: 3038it [00:10, 284.48it/s]\n",
      "yolo->obb: 3067it [00:10, 284.89it/s]\n",
      "yolo->obb: 3096it [00:10, 285.26it/s]\n",
      "yolo->obb: 3125it [00:11, 283.84it/s]\n",
      "yolo->obb: 3154it [00:11, 283.69it/s]\n",
      "yolo->obb: 3183it [00:11, 284.42it/s]\n",
      "yolo->obb: 3212it [00:11, 284.09it/s]\n",
      "yolo->obb: 3241it [00:11, 284.70it/s]\n",
      "yolo->obb: 3270it [00:11, 284.29it/s]\n",
      "yolo->obb: 3299it [00:11, 284.00it/s]\n",
      "yolo->obb: 3328it [00:11, 283.80it/s]\n",
      "yolo->obb: 3357it [00:11, 283.66it/s]\n",
      "yolo->obb: 3386it [00:11, 283.56it/s]\n",
      "yolo->obb: 3415it [00:12, 283.49it/s]\n",
      "yolo->obb: 3444it [00:12, 284.28it/s]\n",
      "yolo->obb: 3473it [00:12, 284.74it/s]\n",
      "yolo->obb: 3502it [00:12, 285.16it/s]\n",
      "yolo->obb: 3531it [00:12, 284.61it/s]\n",
      "yolo->obb: 3560it [00:12, 285.06it/s]\n",
      "yolo->obb: 3589it [00:12, 285.29it/s]\n",
      "yolo->obb: 3618it [00:12, 284.70it/s]\n",
      "yolo->obb: 3647it [00:12, 284.29it/s]\n",
      "yolo->obb: 3676it [00:13, 282.33it/s]\n",
      "yolo->obb: 3705it [00:13, 280.16it/s]\n",
      "yolo->obb: 3734it [00:13, 278.67it/s]\n",
      "yolo->obb: 3762it [00:13, 277.96it/s]\n",
      "yolo->obb: 3790it [00:13, 275.84it/s]\n",
      "yolo->obb: 3819it [00:13, 278.07it/s]\n",
      "yolo->obb: 3848it [00:13, 279.57it/s]\n",
      "yolo->obb: 3877it [00:13, 280.69it/s]\n",
      "yolo->obb: 3906it [00:13, 279.03it/s]\n",
      "yolo->obb: 3935it [00:13, 279.49it/s]\n",
      "yolo->obb: 3964it [00:14, 279.82it/s]\n",
      "yolo->obb: 3993it [00:14, 280.86it/s]\n",
      "yolo->obb: 4022it [00:14, 281.51it/s]\n",
      "yolo->obb: 4051it [00:14, 281.23it/s]\n",
      "yolo->obb: 4080it [00:14, 281.86it/s]\n",
      "yolo->obb: 4109it [00:14, 282.30it/s]\n",
      "yolo->obb: 4138it [00:14, 282.61it/s]\n",
      "yolo->obb: 4167it [00:14, 281.99it/s]\n",
      "yolo->obb: 4196it [00:14, 282.39it/s]\n",
      "yolo->obb: 4225it [00:14, 281.77it/s]\n",
      "yolo->obb: 4254it [00:15, 279.78it/s]\n",
      "yolo->obb: 4282it [00:15, 279.56it/s]\n",
      "yolo->obb: 4310it [00:15, 279.31it/s]\n",
      "yolo->obb: 4338it [00:15, 277.58it/s]\n",
      "yolo->obb: 4366it [00:15, 277.19it/s]\n",
      "yolo->obb: 4394it [00:15, 277.73it/s]\n",
      "yolo->obb: 4422it [00:15, 277.29it/s]\n",
      "yolo->obb: 4450it [00:15, 275.35it/s]\n",
      "yolo->obb: 4478it [00:15, 276.44it/s]\n",
      "yolo->obb: 4506it [00:15, 277.21it/s]\n",
      "yolo->obb: 4534it [00:16, 277.75it/s]\n",
      "yolo->obb: 4562it [00:16, 277.31it/s]\n",
      "yolo->obb: 4591it [00:16, 278.30it/s]\n",
      "yolo->obb: 4619it [00:16, 278.44it/s]\n",
      "yolo->obb: 4647it [00:16, 278.62it/s]\n",
      "yolo->obb: 4675it [00:16, 278.74it/s]\n",
      "yolo->obb: 4703it [00:16, 278.83it/s]\n",
      "yolo->obb: 4731it [00:16, 278.89it/s]\n",
      "yolo->obb: 4759it [00:16, 271.61it/s]\n",
      "yolo->obb: 4787it [00:17, 269.82it/s]\n",
      "yolo->obb: 4815it [00:17, 270.15it/s]\n",
      "yolo->obb: 4843it [00:17, 270.37it/s]\n",
      "yolo->obb: 4871it [00:17, 268.89it/s]\n",
      "yolo->obb: 4898it [00:17, 265.83it/s]\n",
      "yolo->obb: 4925it [00:17, 266.00it/s]\n",
      "yolo->obb: 4953it [00:17, 269.04it/s]\n",
      "yolo->obb: 4982it [00:17, 272.51it/s]\n",
      "yolo->obb: 5011it [00:17, 275.75it/s]\n",
      "yolo->obb: 5039it [00:17, 276.71it/s]\n",
      "yolo->obb: 5068it [00:18, 278.70it/s]\n",
      "yolo->obb: 5096it [00:18, 278.80it/s]\n",
      "yolo->obb: 5125it [00:18, 280.17it/s]\n",
      "yolo->obb: 5154it [00:18, 281.12it/s]\n",
      "yolo->obb: 5183it [00:18, 281.78it/s]\n",
      "yolo->obb: 5212it [00:18, 282.25it/s]\n",
      "yolo->obb: 5241it [00:18, 281.74it/s]\n",
      "yolo->obb: 5270it [00:18, 281.39it/s]\n",
      "yolo->obb: 5299it [00:18, 279.51it/s]\n",
      "yolo->obb: 5327it [00:18, 278.55it/s]\n",
      "yolo->obb: 5356it [00:19, 279.90it/s]\n",
      "yolo->obb: 5384it [00:19, 279.64it/s]\n",
      "yolo->obb: 5413it [00:19, 279.93it/s]\n",
      "yolo->obb: 5441it [00:19, 279.58it/s]\n",
      "yolo->obb: 5470it [00:19, 279.88it/s]\n",
      "yolo->obb: 5498it [00:19, 279.63it/s]\n",
      "yolo->obb: 5526it [00:19, 272.96it/s]\n",
      "yolo->obb: 5554it [00:19, 267.68it/s]\n",
      "yolo->obb: 5582it [00:19, 270.18it/s]\n",
      "yolo->obb: 5610it [00:19, 268.07it/s]\n",
      "yolo->obb: 5637it [00:20, 268.36it/s]\n",
      "yolo->obb: 5664it [00:20, 267.78it/s]\n",
      "yolo->obb: 5692it [00:20, 269.51it/s]\n",
      "yolo->obb: 5719it [00:20, 266.15it/s]\n",
      "yolo->obb: 5746it [00:20, 263.90it/s]\n",
      "yolo->obb: 5760it [00:20, 280.09it/s]\n",
      "03/02/2025 12:22:51 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\val\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 26it [00:00, 259.10it/s]\n",
      "yolo->obb: 53it [00:00, 260.37it/s]\n",
      "yolo->obb: 80it [00:00, 260.76it/s]\n",
      "yolo->obb: 107it [00:00, 259.95it/s]\n",
      "yolo->obb: 134it [00:00, 261.32it/s]\n",
      "yolo->obb: 162it [00:00, 264.59it/s]\n",
      "yolo->obb: 189it [00:00, 263.49it/s]\n",
      "yolo->obb: 216it [00:00, 263.50it/s]\n",
      "yolo->obb: 243it [00:00, 265.21it/s]\n",
      "yolo->obb: 271it [00:01, 269.42it/s]\n",
      "yolo->obb: 300it [00:01, 273.70it/s]\n",
      "yolo->obb: 328it [00:01, 274.38it/s]\n",
      "yolo->obb: 356it [00:01, 275.78it/s]\n",
      "yolo->obb: 384it [00:01, 276.75it/s]\n",
      "yolo->obb: 413it [00:01, 278.75it/s]\n",
      "yolo->obb: 441it [00:01, 278.84it/s]\n",
      "yolo->obb: 469it [00:01, 277.24it/s]\n",
      "yolo->obb: 497it [00:01, 276.95it/s]\n",
      "yolo->obb: 525it [00:01, 277.57it/s]\n",
      "yolo->obb: 553it [00:02, 277.18it/s]\n",
      "yolo->obb: 582it [00:02, 279.04it/s]\n",
      "yolo->obb: 611it [00:02, 280.33it/s]\n",
      "yolo->obb: 640it [00:02, 281.23it/s]\n",
      "yolo->obb: 669it [00:02, 281.86it/s]\n",
      "yolo->obb: 698it [00:02, 282.30it/s]\n",
      "yolo->obb: 727it [00:02, 283.45it/s]\n",
      "yolo->obb: 756it [00:02, 284.25it/s]\n",
      "yolo->obb: 785it [00:02, 284.73it/s]\n",
      "yolo->obb: 814it [00:02, 285.15it/s]\n",
      "yolo->obb: 843it [00:03, 285.45it/s]\n",
      "yolo->obb: 872it [00:03, 283.97it/s]\n",
      "yolo->obb: 901it [00:03, 284.61it/s]\n",
      "yolo->obb: 930it [00:03, 284.98it/s]\n",
      "yolo->obb: 939it [00:03, 276.73it/s]\n",
      "03/02/2025 12:22:55 - INFO - __main__ -   Converting D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels: yolo->obb\n",
      "\n",
      "yolo->obb: 0it [00:00, ?it/s]\n",
      "yolo->obb: 29it [00:00, 286.13it/s]\n",
      "yolo->obb: 58it [00:00, 284.48it/s]\n",
      "yolo->obb: 87it [00:00, 285.23it/s]\n",
      "yolo->obb: 116it [00:00, 284.48it/s]\n",
      "yolo->obb: 145it [00:00, 285.07it/s]\n",
      "yolo->obb: 174it [00:00, 285.34it/s]\n",
      "yolo->obb: 203it [00:00, 285.60it/s]\n",
      "yolo->obb: 232it [00:00, 285.77it/s]\n",
      "yolo->obb: 261it [00:00, 285.00it/s]\n",
      "yolo->obb: 290it [00:01, 285.35it/s]\n",
      "yolo->obb: 319it [00:01, 285.59it/s]\n",
      "yolo->obb: 348it [00:01, 285.75it/s]\n",
      "yolo->obb: 377it [00:01, 285.02it/s]\n",
      "yolo->obb: 406it [00:01, 284.43it/s]\n",
      "yolo->obb: 435it [00:01, 284.94it/s]\n",
      "yolo->obb: 464it [00:01, 285.30it/s]\n",
      "yolo->obb: 493it [00:01, 284.70it/s]\n",
      "yolo->obb: 522it [00:01, 285.98it/s]\n",
      "yolo->obb: 551it [00:01, 286.03it/s]\n",
      "yolo->obb: 580it [00:02, 285.21it/s]\n",
      "yolo->obb: 609it [00:02, 286.34it/s]\n",
      "yolo->obb: 638it [00:02, 286.28it/s]\n",
      "yolo->obb: 667it [00:02, 286.23it/s]\n",
      "yolo->obb: 696it [00:02, 286.21it/s]\n",
      "yolo->obb: 725it [00:02, 287.04it/s]\n",
      "yolo->obb: 754it [00:02, 287.62it/s]\n",
      "yolo->obb: 783it [00:02, 287.17it/s]\n",
      "yolo->obb: 812it [00:02, 286.86it/s]\n",
      "yolo->obb: 841it [00:02, 286.64it/s]\n",
      "yolo->obb: 870it [00:03, 285.64it/s]\n",
      "yolo->obb: 899it [00:03, 285.79it/s]\n",
      "yolo->obb: 928it [00:03, 285.89it/s]\n",
      "yolo->obb: 957it [00:03, 285.96it/s]\n",
      "yolo->obb: 986it [00:03, 285.93it/s]\n",
      "yolo->obb: 1015it [00:03, 285.99it/s]\n",
      "yolo->obb: 1044it [00:03, 286.03it/s]\n",
      "yolo->obb: 1073it [00:03, 286.06it/s]\n",
      "yolo->obb: 1102it [00:03, 285.24it/s]\n",
      "yolo->obb: 1131it [00:03, 285.51it/s]\n",
      "yolo->obb: 1160it [00:04, 285.69it/s]\n",
      "yolo->obb: 1189it [00:04, 285.83it/s]\n",
      "yolo->obb: 1218it [00:04, 285.07it/s]\n",
      "yolo->obb: 1247it [00:04, 286.24it/s]\n",
      "yolo->obb: 1276it [00:04, 286.21it/s]\n",
      "yolo->obb: 1305it [00:04, 286.18it/s]\n",
      "yolo->obb: 1334it [00:04, 283.56it/s]\n",
      "yolo->obb: 1363it [00:04, 284.33it/s]\n",
      "yolo->obb: 1392it [00:04, 277.48it/s]\n",
      "yolo->obb: 1420it [00:04, 270.83it/s]\n",
      "yolo->obb: 1424it [00:05, 284.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# [IMPORTANT] Run this cell to convert the datasets to obb format\n",
    "!python  ../tools/build_dataset.py --yolo-to-obb --data-config-yaml \"..\\data\\dataset_identification.yaml\" --skip\n",
    "!python  ../tools/build_dataset.py --yolo-to-obb --data-config-yaml \"..\\data\\dataset_identification-detection.yaml\" --skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PhD\\Data per camp\\IdentificationDataset\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\IdentificationDataset\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\IdentificationDataset\\test\\images\\../labels.cache does not exist.\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\images\\../labels.cache does not exist.\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLO11s-obb summary: 344 layers, 9,716,293 parameters, 0 gradients, 22.5 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLO11s-obb summary (fused): 257 layers, 9,701,109 parameters, 0 gradients, 22.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels... 1061 images, 21220 backgrounds, 0 corrupt: 100%|██████████| 22281/22281 [00:04<00:00, 4930.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 349/349 [01:45<00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      22281       2585      0.552      0.448      0.504      0.388\n",
      "               buffalo         67        283      0.554      0.767       0.69      0.496\n",
      "                impala        170        515      0.719      0.388      0.546      0.439\n",
      "                 nyala        123        259      0.287      0.158      0.206       0.15\n",
      "              nyala(m)         55         55      0.773      0.309      0.567      0.441\n",
      "                  roan        138        205      0.182      0.312      0.197       0.14\n",
      "                 sable        532       1268      0.798      0.753      0.817      0.658\n",
      "Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\obb\\val12\u001b[0m\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLO11s-obb summary: 344 layers, 9,714,358 parameters, 0 gradients, 22.5 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLO11s-obb summary (fused): 257 layers, 9,699,174 parameters, 0 gradients, 22.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels... 1424 images, 28480 backgrounds, 0 corrupt: 100%|██████████| 29904/29904 [00:06<00:00, 4663.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 468/468 [02:23<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      29904       4034      0.867      0.752      0.844      0.651\n",
      "Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\obb\\val13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load yolov11s-obb\n",
    "paths = [\"../runs/mlflow/140168774036374062/34c709364c0e46dcb72c526de34a7fa4/artifacts/weights/best.pt\", # Identification\n",
    "         \"../runs/mlflow/140168774036374062/f5b7124be14c4c89b8edd26bcf7a9a76/artifacts/weights/best.pt\", # Detection\n",
    "        ]\n",
    "\n",
    "\n",
    "dataconfigs = [r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification.yaml\",\n",
    "               r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification-detection.yaml\"\n",
    "              ]\n",
    "\n",
    "imgsz = 800\n",
    "iou_threshold=0.45\n",
    "conf_threshold=0.235\n",
    "splits = [\n",
    "        #   \"val\", \n",
    "          \"test\",\n",
    "          ]\n",
    "\n",
    "# remove label.cache files\n",
    "for dataconfig in dataconfigs:\n",
    "    remove_label_cache(data_config_yaml=dataconfig)\n",
    "\n",
    "for split in splits:\n",
    "    for path,dataconfig in zip(paths,dataconfigs):\n",
    "        print(\"\\n\",'-'*20,split,'-'*20)\n",
    "        model = YOLO(path)\n",
    "        model.info()\n",
    "        \n",
    "        # Customize validation settings\n",
    "        validation_results = model.val(data=dataconfig,\n",
    "                                        imgsz=imgsz,\n",
    "                                        batch=64,\n",
    "                                        split=split,\n",
    "                                        conf=conf_threshold,\n",
    "                                        iou=iou_threshold,\n",
    "                                        device=\"cuda\"\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\PhD\\Data per camp\\IdentificationDataset\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\IdentificationDataset\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\IdentificationDataset\\test\\images\\../labels.cache does not exist.\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\train\\images\\../labels.cache does not exist.\n",
      "Removing: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\val\\images\\../labels.cache\n",
      "D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\images\\../labels.cache does not exist.\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLOv8s-obb summary: 250 layers, 11,424,101 parameters, 0 gradients, 29.6 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLOv8s-obb summary (fused): 187 layers, 11,413,893 parameters, 0 gradients, 29.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels... 1061 images, 21220 backgrounds, 0 corrupt: 100%|██████████| 22281/22281 [00:04<00:00, 5322.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\IdentificationDataset\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 349/349 [01:40<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      22281       2585      0.475      0.421      0.441      0.324\n",
      "               buffalo         67        283        0.5      0.753      0.607      0.405\n",
      "                impala        170        515       0.77       0.26      0.515      0.408\n",
      "                 nyala        123        259      0.104      0.124     0.0854     0.0666\n",
      "              nyala(m)         55         55      0.576      0.345      0.502      0.336\n",
      "                  roan        138        205       0.15      0.376      0.188      0.133\n",
      "                 sable        532       1268       0.75      0.671       0.75      0.597\n",
      "Speed: 0.2ms preprocess, 3.8ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\obb\\val18\u001b[0m\n",
      "\n",
      " -------------------- test --------------------\n",
      "YOLOv8s-obb summary: 250 layers, 11,429,132 parameters, 0 gradients, 29.7 GFLOPs\n",
      "Ultralytics 8.3.27  Python-3.12.2 torch-2.2.2+cu118 CUDA:0 (NVIDIA RTX A5000, 24563MiB)\n",
      "YOLOv8s-obb summary (fused): 187 layers, 11,418,924 parameters, 0 gradients, 29.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels... 1424 images, 28480 backgrounds, 0 corrupt: 100%|██████████| 29904/29904 [00:13<00:00, 2169.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\PhD\\Data per camp\\DetectionDataset\\Identification-split\\test\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 468/468 [02:17<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      29904       4034      0.866      0.617      0.765      0.587\n",
      "             Waterbuck       1424       4034      0.866      0.617      0.765      0.587\n",
      "Speed: 0.2ms preprocess, 3.9ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\obb\\val19\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load yolov8s-obb\n",
    "paths = [\n",
    "         \"../runs/mlflow/140168774036374062/b883bd2b31f94f29807ea3b94e8ff8fc/artifacts/weights/best.pt\", # Identification\n",
    "         \"../runs/mlflow/140168774036374062/8a76c60253fc48788b5324096d035420/artifacts/weights/best.pt\"  # Detection\n",
    "        ]\n",
    "\n",
    "\n",
    "dataconfigs = [\n",
    "                r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification.yaml\",\n",
    "               r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification-detection.yaml\"\n",
    "              ]\n",
    "\n",
    "imgsz = 800\n",
    "iou_threshold=0.45\n",
    "conf_threshold=0.235\n",
    "splits = [\n",
    "        #   \"val\", \n",
    "          \"test\",\n",
    "          ]\n",
    "\n",
    "# remove label.cache files\n",
    "for dataconfig in dataconfigs:\n",
    "    remove_label_cache(data_config_yaml=dataconfig)\n",
    "\n",
    "for split in splits:\n",
    "    for path,dataconfig in zip(paths,dataconfigs):\n",
    "        print(\"\\n\",'-'*20,split,'-'*20)\n",
    "        model = YOLO(path)\n",
    "        model.info()\n",
    "        \n",
    "        # Customize validation settings\n",
    "        validation_results = model.val(data=dataconfig,\n",
    "                                        imgsz=imgsz,\n",
    "                                        batch=64,\n",
    "                                        split=split,\n",
    "                                        conf=conf_threshold,\n",
    "                                        iou=iou_threshold,\n",
    "                                        device=\"cuda\"\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from datalabeling.annotator import Annotator\n",
    "\n",
    "for alias in [\"version9\", \"version6\"]:\n",
    "    print(\"-\"*10,alias,end=\"\\n\\n\")\n",
    "    name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "    handler = Annotator(mlflow_model_alias=alias,\n",
    "                            mlflow_model_name=name,\n",
    "                            confidence_threshold=0.25,\n",
    "                            is_yolo_obb=name.strip() == \"obb-detector\",\n",
    "                            dotenv_path=\"../.env\")\n",
    "\n",
    "    yolo_model = handler.model.unwrap_python_model().detection_model.detection_model.model\n",
    "    validation_results = yolo_model.val(data=r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_hn.yaml\",\n",
    "                                    imgsz=1280,\n",
    "                                    batch=32,\n",
    "                                    conf=0.25,\n",
    "                                    iou=0.45,\n",
    "                                    device=\"cuda\"\n",
    "                                )\n",
    "    \n",
    "    print(validation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herdnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnexpected end of JSON input. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from datalabeling.train.herdnet import HerdnetData, HerdnetTrainer\n",
    "from datalabeling.arguments import Arguments\n",
    "import lightning as L\n",
    "import os, yaml\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowering matrix multiplication precision\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "args = Arguments()\n",
    "args.lr0 = 3e-4\n",
    "args.epochs = 15\n",
    "args.imgsz = 800\n",
    "args.batchsize = 8\n",
    "down_ratio = 2\n",
    "args.data_config_yaml = r\"D:\\datalabeling\\data\\data_config.yaml\"\n",
    "args.path_weights = r\"D:\\datalabeling\\models\\20220329_HerdNet_Ennedi_dataset_2023.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load Prediction images\n",
    "with open(args.data_config_yaml, 'r') as file:\n",
    "    data_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "images_path = os.path.join(data_config['path'],data_config['test'][0])\n",
    "images_path = list(Path(images_path).glob('*'))\n",
    "\n",
    "\n",
    "# Data\n",
    "datamodule = HerdnetData(data_config_yaml=args.data_config_yaml,\n",
    "                            patch_size=args.imgsz,\n",
    "                            batch_size=args.batchsize,\n",
    "                            down_ratio=down_ratio,\n",
    "                            train_empty_ratio=0.,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a few\n",
    "# random.shuffle(images_path)\n",
    "images_path = images_path[:10]\n",
    "datamodule.set_predict_dataset(images_path=images_path,batchsize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "for img in datamodule.predict_dataloader():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ckpt: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "checkpoint_path = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\tools\\lightning-ckpts\\epoch=23-step=2040.ckpt\"\n",
    "herdnet_trainer = HerdnetTrainer.load_from_checkpoint(checkpoint_path=checkpoint_path,\n",
    "                                                            args=args,\n",
    "                                                            ce_weight=None,\n",
    "                                                            work_dir='../.tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(accelerator=\"auto\",profiler='simple')\n",
    "out = trainer.predict(model=herdnet_trainer,\n",
    "                datamodule=datamodule,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [[57.0, 213.0], [394.0, 291.0]],\n",
       "   'labels': [1, 2],\n",
       "   'scores': [0.308662086725235, 0.2863273024559021],\n",
       "   'dscores': [0.11291475594043732, 0.05149130895733833]},\n",
       "  'est_count': [1, 1, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [[215.0, 112.0]],\n",
       "   'labels': [4],\n",
       "   'scores': [0.33474990725517273],\n",
       "   'dscores': [0.2716710865497589]},\n",
       "  'est_count': [0, 0, 0, 1, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]},\n",
       " {'preds': {'loc': [], 'labels': [], 'scores': [], 'dscores': []},\n",
       "  'est_count': [0, 0, 0, 0, 0, 0]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preds</th>\n",
       "      <th>est_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'loc': [[57.0, 213.0], [394.0, 291.0]], 'labe...</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'loc': [[215.0, 112.0]], 'labels': [4], 'scor...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'loc': [], 'labels': [], 'scores': [], 'dscor...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               preds           est_count\n",
       "0  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "1  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "2  {'loc': [[57.0, 213.0], [394.0, 291.0]], 'labe...  [1, 1, 0, 0, 0, 0]\n",
       "3  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "4  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "5  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "6  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "7  {'loc': [[215.0, 112.0]], 'labels': [4], 'scor...  [0, 0, 0, 1, 0, 0]\n",
       "8  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]\n",
       "9  {'loc': [], 'labels': [], 'scores': [], 'dscor...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records(out,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing inference params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalabeling.annotator import Detector\n",
    "from datalabeling.arguments import Arguments\n",
    "from datalabeling.dataset.sampling import (get_preds_targets, compute_detector_performance, get_uncertainty)    \n",
    "import yaml, os\n",
    "from hyperopt import tpe, hp, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params \n",
    "args = Arguments()\n",
    "args.path_to_weights = r\"C:/Users/Machine Learning/Desktop/workspace-wildAI/datalabeling/runs/mlflow/140168774036374062/57daf3bcd99b4dd4b040cb4f8670960c/artifacts/weights/best.pt\"\n",
    "# args.confidence_threshold = 0.2\n",
    "# args.overlap_ratio = 0.1\n",
    "args.use_sliding_window = True\n",
    "args.device = \"cuda\"\n",
    "args.is_yolo_obb = True\n",
    "args.pred_results_dir = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\.tmp\"\n",
    "args.data_config_yaml = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_hn.yaml\"\n",
    "args.hn_uncertainty_method = \"entropy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth\n",
    "with open(args.data_config_yaml,'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "\n",
    "split='val'\n",
    "images_path = [os.path.join(yolo_config['path'],yolo_config[split][i]) for i in range(len(yolo_config[split]))]\n",
    "images_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params:dict):\n",
    "\n",
    "    # Define detector\n",
    "    model = Detector(path_to_weights=args.path_to_weights,\n",
    "                        confidence_threshold=params['confidence_threshold'],\n",
    "                        overlap_ratio=params['overlap_ratio'],\n",
    "                        tilesize=params['tilesize'],\n",
    "                        imgsz=params['imgsz'],\n",
    "                        use_sliding_window=args.use_sliding_window,\n",
    "                        device=args.device,\n",
    "                        is_yolo_obb=args.is_yolo_obb\n",
    "                    )\n",
    "\n",
    "    df_results, df_labels, col_names = get_preds_targets(images_dirs=images_path,\n",
    "                                                        pred_results_dir=args.pred_results_dir,\n",
    "                                                        detector=model,\n",
    "                                                        load_results=False,\n",
    "                                                        save_tag=f\"{params['imgsz']}-{params['tilesize']}-{params['overlap_ratio']}-{params['confidence_threshold']}\"\n",
    "                                                        )\n",
    "\n",
    "    df_results_per_img = compute_detector_performance(df_results,df_labels,col_names)\n",
    "    # df_results_per_img = get_uncertainty(df_results_per_img=df_results_per_img,mode=args.hn_uncertainty_method)\n",
    "\n",
    "    # minizing loss -> maximize map50 and map75\n",
    "    loss = -1.0*df_results_per_img[\"map50\"].mean() - df_results_per_img[\"map75\"].mean() #+ df_results_per_img[\"uncertainty\"].mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "                'confidence_threshold': hp.uniform('x', 0.1, 0.7),\n",
    "                'overlap_ratio': hp.uniform('y', 0, 0.25),\n",
    "                'tilesize': hp.choice(label='tilesize',options=[640, 2*640]),\n",
    "                'imgsz': hp.choice(label='imgsz',options=[640, 2*640, 3*640, 4*640]),\n",
    "            }\n",
    "\n",
    "best = fmin(\n",
    "    fn=objective, # Objective Function to optimize\n",
    "    space=search_space, # Hyperparameter's Search Space\n",
    "    algo=tpe.suggest, # Optimization algorithm (representative TPE)\n",
    "    max_evals=2 # Number of optimization attempts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset label format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_label_format(loaded_df:pd.DataFrame)->str:\n",
    "    \"\"\"checks label format\n",
    "\n",
    "    Args:\n",
    "        loaded_df (pd.DataFrame): target values\n",
    "\n",
    "    Raises:\n",
    "        NotImplementedError: when the format is not yolo or yolo-obb\n",
    "\n",
    "    Returns:\n",
    "        str: yolo or yolo-obb\n",
    "    \"\"\"\n",
    "\n",
    "    num_features = len(loaded_df.columns)\n",
    "\n",
    "    if num_features == 5:\n",
    "        return \"yolo\"\n",
    "    elif num_features == 9:\n",
    "        return \"yolo-obb\"\n",
    "    else:\n",
    "        raise NotImplementedError(f\"The number of features ({num_features}) in the label file is wrong. Check yolo or yolo-obb format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_path = r\"D:\\PhD\\Data per camp\\DetectionDataset\\Rep 1\\train\\labels\\DJI_20231002150401_0009_0_48_0_1271_640_1911.txt\"\n",
    "df = pd.read_csv(label_path,sep=' ',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(df.iloc[:,0].dtype, np.dtypes.IntDType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_label_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id','x1','y1','x2','y2','x3','y3','x4','y4']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from datalabeling.arguments import Arguments, Dataprepconfigs\n",
    "import os, logging, traceback\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import math\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Dataprepconfigs()\n",
    "\n",
    "args.empty_ratio = 15\n",
    "args.parse_ls_config = True\n",
    "args.label_map =  r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\exported_annotations\\label_mapping.json\" \n",
    "args.min_visibility = 0.7 \n",
    "args.dest_path_labels =  r\"D:\\PhD\\Data per camp\\IdentificationDataset\\val\\labels\"  \n",
    "args.ls_json_dir =  r\"D:\\PhD\\Data per camp\\Exported annotations and labels\\identification-splits\\val\\labelstudio\" \n",
    "args.dest_path_images = r\"D:\\PhD\\Data per camp\\IdentificationDataset\\val\\images\" \n",
    "args.coco_json_dir = r\"D:\\PhD\\Data per camp\\Exported annotations and labels\\identification-splits\\val\\coco-format\"\n",
    "args.height = 800\n",
    "args.width = 800\n",
    "args.data_config_yaml =  r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\dataset_identification.yaml\"\n",
    "args.keep_labels = (\"buffalo\", \"impala\", \"nyala\", \"nyala(m)\", \"roan\", \"sable\")\n",
    "args.discard_labels = None\n",
    "args.save_all = False\n",
    "args.clear_yolo_dir = False\n",
    "args.save_only_empty = False\n",
    "args.is_detector = False\n",
    "\n",
    "args.load_coco_annotations = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datalabeling.dataset import  update_yolo_data_cfg, get_slices, sample_data, load_coco_annotations, load_label_map\n",
    "\n",
    "if args.load_coco_annotations:\n",
    "    map_imgdir_cocopath = load_coco_annotations(dest_dir_coco=args.coco_json_dir)\n",
    "\n",
    "    # load label map\n",
    "if not args.is_detector:\n",
    "    label_map = load_label_map(path=args.label_map,\n",
    "                                label_to_discard=args.discard_labels,\n",
    "                                labels_to_keep=args.keep_labels)\n",
    "    # update_yolo_data_cfg(args.data_config_yaml, label_map=label_map)\n",
    "    name_id_map = {val:key for key,val in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'buffalo', 1: 'impala', 2: 'nyala', 3: 'nyala(m)', 4: 'roan', 5: 'sable'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing coco dataset annotations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading coco annotations: 100%|██████████| 1152/1152 [00:00<00:00, 104359.36it/s]\n",
      "100%|██████████| 1152/1152 [00:37<00:00, 31.02it/s]\n"
     ]
    }
   ],
   "source": [
    "       \n",
    "# slice coco annotations and save tiles\n",
    "for img_dir,cocopath in map_imgdir_cocopath.items():\n",
    "    # try:\n",
    "    # slice annotations\n",
    "    coco_dict_slices = get_slices(coco_annotation_file_path=cocopath,\n",
    "                        img_dir=img_dir,\n",
    "                        slice_height=args.height,\n",
    "                        slice_width=args.width,\n",
    "                        overlap_height_ratio=args.overlap_ratio,\n",
    "                        overlap_width_ratio=args.overlap_ratio,\n",
    "                        min_area_ratio=args.min_visibility,\n",
    "                        ignore_negative_samples= (args.empty_ratio<1e-8 and not args.save_all), # equivalent to args.empty_ratio == 0.0\n",
    "                        )\n",
    "    \n",
    "    break\n",
    "    # sample tiles\n",
    "    df_tiles = sample_data(coco_dict_slices=coco_dict_slices,\n",
    "                            empty_ratio=args.empty_ratio,\n",
    "                            out_csv_path= None, #Path(args.dest_path_images).with_name(\"gt.csv\"),\n",
    "                            img_dir=img_dir,\n",
    "                            save_all=args.save_all,\n",
    "                            labels_to_discard=args.discard_labels,\n",
    "                            labels_to_keep=args.keep_labels,\n",
    "                            sample_only_empty=args.save_only_empty\n",
    "                            )\n",
    "    # except Exception as e:\n",
    "    #     traceback.print_exc()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_image(file_name:str):\n",
    "    ext = '.jpg' \n",
    "    file_name = Path(file_name).stem\n",
    "    # print(file_name)\n",
    "    parent_file = '_'.join(file_name.split('_')[:-5])\n",
    "    p = os.path.join(img_dir,parent_file+ext)\n",
    "    if os.path.exists(p):\n",
    "        return p\n",
    "    raise FileNotFoundError(f'Parent file note found for {file_name} in {img_dir} >> {parent_file}')\n",
    "    \n",
    "    \n",
    "# build mapping for labels\n",
    "label_ids = [cat['id'] for cat in coco_dict_slices['categories']]\n",
    "label_name = [cat['name'] for cat in coco_dict_slices['categories']]\n",
    "label_map = dict(zip(label_ids,label_name))\n",
    "\n",
    "# build dataFrame of image slices \n",
    "ids = list()\n",
    "x0s, x1s = list(), list()\n",
    "y0s, y1s = list(), list()\n",
    "file_paths = list()\n",
    "parent_file_paths = list()\n",
    "for metadata in coco_dict_slices['images']:\n",
    "    # img_path = os.path.join(img_dir,metadata['file_name'])\n",
    "    file_paths.append(metadata['file_name'])\n",
    "    file_name = os.path.basename(metadata['file_name'])\n",
    "    x_0,y_0,x_1,y_1 = file_name.split('.')[0].split('_')[-4:]\n",
    "    parent_image = get_parent_image(file_name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'height': 800,\n",
       "  'width': 800,\n",
       "  'id': 1,\n",
       "  'file_name': 'DJI_20231003094758_0001_0_0_0_0_800_800.jpg'},\n",
       " 'D:\\\\PhD\\\\Data per camp\\\\Dry season\\\\Kapiri\\\\Camp 3\\\\Rep 1 - tiled')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata, img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([False,True]) + pd.Series([False,True]) + pd.Series([False,True])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
