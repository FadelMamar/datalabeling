{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements, uncomment to run\n",
    "# !pip install geopandas pillow label-studio-converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Savmap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from torchvision.ops import nms\n",
    "import torch\n",
    "from label_studio_sdk import Client\n",
    "from dotenv import load_dotenv\n",
    "from label_studio_tools.core.utils.io import get_local_path\n",
    "from urllib.parse import unquote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "path_to_images = os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polygon points\n",
    "xx,yy = polygons['geometry'].iloc[0].exterior.coords.xy\n",
    "np.array(list(zip(xx,yy))) * 100 / np.array([4000,3000]).reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in tqdm(range(len(polygons))):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    # try:\n",
    "    width, height = Image.open(image_path).size\n",
    "    # except:\n",
    "    #     continue\n",
    "    polygons['x_min'].iat[i] = int(x_min)\n",
    "    polygons['x_max'].iat[i] = int(x_max)\n",
    "    polygons['y_min'].iat[i] = int(y_min)\n",
    "    polygons['y_max'].iat[i] = int(y_max)\n",
    "    polygons['x'].iat[i] = round(0.5*(x_max+x_min))\n",
    "    polygons['y'].iat[i] = round(0.5*(y_max+y_min))\n",
    "    polygons['width'].iat[i] = width\n",
    "    polygons['height'].iat[i] = height\n",
    "\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-max suppresion\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.ops.nms.html\n",
    "\n",
    "def nms_to_bbox(df_annotations:pd.DataFrame,iou_threshold:float=0.5):\n",
    "    dfs = list()\n",
    "\n",
    "    for IMAGEUUID, df in tqdm(df_annotations.groupby('IMAGEUUID')):\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        bbox = df[['x_min','y_min','x_max','y_max']].to_numpy().astype(float)\n",
    "        scores = np.ones((bbox.shape[0],)).astype(float)\n",
    "\n",
    "        bbox_indices= nms(boxes=torch.from_numpy(bbox),\n",
    "                            scores=torch.from_numpy(scores),\n",
    "                            iou_threshold=iou_threshold).numpy()\n",
    "        \n",
    "        # print(bbox[bbox_indices],'\\n',df.iloc[bbox_indices,:])\n",
    "\n",
    "        dfs.append(df.iloc[bbox_indices,:].copy())\n",
    "\n",
    "    return pd.concat(dfs,axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nms filtering of bbox\n",
    "df_filtered = nms_to_bbox(polygons,iou_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered df vs unfiltered df\n",
    "len(df_filtered), len(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select labels\n",
    "data = polygons.loc[:,['x_min','x_max','y_min','y_max','IMAGEUUID','width','height','class']].copy()\n",
    "data.rename(columns={'IMAGEUUID':'filename',\n",
    "                     'x_max':'xmax',\n",
    "                     'x_min':'xmin',\n",
    "                     'y_min':'ymin',\n",
    "                     'y_max':'ymax'},inplace=True)\n",
    "data['filename'] = data['filename'].apply(lambda x: f\"{x}.JPG\")\n",
    "data = data.dropna()\n",
    "data = data[['filename','class','width', 'height','xmin','ymin','xmax','ymax']]\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert CSV to COCO\n",
    "# save_json_path = ... #'cocoformat.json'\n",
    "\n",
    "# images = []\n",
    "# categories = []\n",
    "# annotations = []\n",
    "\n",
    "# category = {}\n",
    "# category[\"supercategory\"] = 'None'\n",
    "# category[\"id\"] = 0\n",
    "# category[\"category_name\"] = 'wildlife'\n",
    "# categories.append(category)\n",
    "\n",
    "# data['fileid'] = data['filename'].astype('category').cat.codes\n",
    "# data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n",
    "# # data['categoryid'] = data['categoryid']+1\n",
    "# data['annid'] = data.index\n",
    "\n",
    "# def image(row):\n",
    "#     image = {}\n",
    "#     image[\"height\"] = row.height\n",
    "#     image[\"width\"] = row.width\n",
    "#     image[\"id\"] = row.fileid\n",
    "#     image[\"file_name\"] = row.filename\n",
    "#     return image\n",
    "\n",
    "# # def category(row):\n",
    "# #     category = {}\n",
    "# #     category[\"supercategory\"] = 'None'\n",
    "# #     category[\"id\"] = row.categoryid\n",
    "# #     category[\"category_name\"] = row[2]\n",
    "# #     return category\n",
    "\n",
    "# def annotation(row):\n",
    "#     annotation = {}\n",
    "#     area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
    "#     annotation[\"segmentation\"] = []\n",
    "#     annotation[\"iscrowd\"] = 0\n",
    "#     annotation[\"area\"] = area\n",
    "#     annotation[\"image_id\"] = row.fileid\n",
    "#     annotation[\"score\"] = 1.0\n",
    "\n",
    "#     annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
    "\n",
    "#     annotation[\"category_id\"] = row.categoryid\n",
    "#     annotation[\"id\"] = row.annid\n",
    "#     return annotation\n",
    "\n",
    "# for row in data.itertuples():\n",
    "#     annotations.append(annotation(row))\n",
    "\n",
    "# imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "# for row in imagedf.itertuples():\n",
    "#     images.append(image(row))\n",
    "\n",
    "# # catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "# # for row in catdf.itertuples():\n",
    "# #     categories.append(category(row))\n",
    "\n",
    "# data_coco = {}\n",
    "# data_coco[\"images\"] = images\n",
    "# data_coco[\"categories\"] = categories\n",
    "# data_coco[\"annotations\"] = annotations\n",
    "# # json.dump(data_coco, open(save_json_path, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth = {annot['file_name']:[] for annot in data_coco['images']}\n",
    "# for annot,image_data in zip(data_coco['annotations'],data_coco['images']):\n",
    "#     annot.update(image_data)\n",
    "#     # pprint.pp(annot)\n",
    "#     annot['category_name'] = category['category_name']\n",
    "#     groundtruth[annot['file_name']].append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "# handler = Annotator(mlflow_model_alias='pt',\n",
    "#                     mlflow_model_version=\"groundtruth\")\n",
    "# directory_preds = handler.build_upload_json(path_img_dir='/Users/sfadel/Desktop/savmap',\n",
    "#                                             root='/Users/sfadel',\n",
    "#                                             bulk_predictions=groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_local_path(url:str):\n",
    "#     root = os.getenv(\"LOCAL_FILES_DOCUMENT_ROOT\")\n",
    "#     filename = unquote(url).split('?d=')[1] #.replace('%5C','\\\\')\n",
    "#     return os.path.join(root,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\.env\"\n",
    "if dotenv_path is not None:\n",
    "    load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Label Studio API and check the connection\n",
    "LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "API_KEY = os.getenv(\"LABEL_STUDIO_API_KEY \")\n",
    "labelstudio_client = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)\n",
    "project_id = 1\n",
    "top_n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = labelstudio_client.get_project(id=project_id)\n",
    "tasks = project.get_tasks()\n",
    "# tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"/data/local-files/?d=Users%5Cfadel%5COneDrive%5CBureau%5CWILD-AI%5Cdatalabeling%5Cdata%5Ctrain_wildai%5Cimages%5C003a34ee6b7841e6851b8fe511ebe102.JPG\"\n",
    "# get_local_path(url=unquote(url),\n",
    "#                download_resources=False\n",
    "#                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unquote(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading Polygons\n",
    "def format_prediction_polygon(points:list,width:int,height:int,label:list=['wildlife',]):\n",
    "    \n",
    "    template = {\n",
    "            \"original_width\": width,\n",
    "            \"original_height\": height,\n",
    "            \"image_rotation\": 0,\n",
    "            \"value\": {\n",
    "                \"points\": points,\n",
    "                \"closed\":True,\n",
    "                \"polygonlabels\": label\n",
    "            }\n",
    "    }\n",
    "\n",
    "    return template\n",
    "\n",
    "def format_predictions_polygon(polygons:list,widths:list,heights:list,label:list=['wildlife',]):\n",
    "\n",
    "    results = list()\n",
    "    for polygon,w,h in zip(polygons,widths,heights):\n",
    "        xx,yy=polygon.exterior.coords.xy\n",
    "        points = list(zip(xx,yy))\n",
    "\n",
    "        # convert points to percent\n",
    "        points = np.array(points) * 100 / np.array([w,h]).reshape((1,2))\n",
    "        points = points.tolist()      \n",
    "\n",
    "        # append result\n",
    "        results.append(format_prediction_polygon(points,width=w,height=h,label=label))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# uploading polygons\n",
    " # Select project\n",
    "# project = labelstudio_client.get_project(id=project_id)\n",
    "# # Upload predictions for each task\n",
    "# tasks = project.get_tasks()\n",
    "# if top_n > 0:\n",
    "#     tasks = sorted(tasks,key=lambda x:x['id'])[:top_n]\n",
    "\n",
    "for task in tqdm(tasks[:10],desc=\"Uploading predictions\"):\n",
    "    task_id = task['id']\n",
    "    img_url = unquote(task['data']['image'])\n",
    "    img_path = get_local_path(img_url)\n",
    "    img_name = Path(img_path).stem\n",
    "    mask = polygons['IMAGEUUID']==img_name\n",
    "    polys = polygons.loc[mask,['IMAGEUUID','geometry','width','height']]\n",
    "    formatted_pred = format_predictions_polygon(polygons=polys['geometry'],widths=polys['width'],heights=polys['height'],label=['wildlife',])\n",
    "    # conf_scores = [pred['score'] for pred in prediction]\n",
    "    # max_score = 0.0\n",
    "    project.create_prediction(task_id=task_id,\n",
    "                               result=formatted_pred,model_version='gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbox\n",
    "def format_prediction_bbox(pred:dict,img_height:int,img_width:int,\n",
    "                           from_name:str='label',\n",
    "                           to_name:str='image',\n",
    "                           label_type:str='rectanglelabels') -> dict:\n",
    "        \"\"\"Converts prediction Label studio format\n",
    "\n",
    "        Args:\n",
    "            pred (dict): prediction in coco format\n",
    "            img_height (int): image height\n",
    "            img_width (int): image width\n",
    "\n",
    "        Returns:\n",
    "            dict: Label studio formated prediction\n",
    "        \"\"\"\n",
    "        # formatting the prediction to work with Label studio\n",
    "        x, y, width, height = pred['bbox']\n",
    "        label = pred['category_name']\n",
    "        score = pred['score']\n",
    "        if not isinstance(score,float):\n",
    "            score = 0.0\n",
    "        template = {\n",
    "                    \"from_name\": from_name,\n",
    "                    \"to_name\": to_name,\n",
    "                    \"type\": label_type,\n",
    "                    \"original_width\":img_width,\n",
    "                    \"original_height\":img_height,\n",
    "                    \"image_rotation\":0,\n",
    "                    'value': {\n",
    "                        label_type: [label,],\n",
    "                        'x': x / img_width * 100,\n",
    "                        'y': y / img_height * 100,\n",
    "                        'width': width / img_width * 100,\n",
    "                        'height': height / img_height * 100,\n",
    "                        'rotation':0\n",
    "                    },\n",
    "                    # 'score': score\n",
    "        }\n",
    "        return template\n",
    "\n",
    "def format_predictions_bbox(xs:list,ys:list,ws:list,hs:list,img_width:int,img_height:int,label:str='wildlife'):\n",
    "      \n",
    "    results = list()\n",
    "    for x,y,w,h in zip(xs,ys,ws,hs):\n",
    "        \n",
    "        annot = {'bbox':[x,y,w,h],\n",
    "                 'category_name':label,\n",
    "                 'score':None\n",
    "                 }\n",
    "\n",
    "        # append result\n",
    "        results.append(format_prediction_bbox(annot,img_width=img_width,img_height=img_height))\n",
    "\n",
    "    return results\n",
    "\n",
    "#Define annotations dataframe\n",
    "df_annotations = df_filtered\n",
    "# upload\n",
    "for task in tqdm(tasks[:],desc=\"Uploading predictions\"):\n",
    "    task_id = task['id']\n",
    "    img_url = unquote(task['data']['image'])\n",
    "    img_path = get_local_path(img_url)\n",
    "    img_name = Path(img_path).stem\n",
    "    mask = df_annotations['IMAGEUUID']==img_name\n",
    "    df_bbox = df_annotations.loc[mask,['x','y','bbox_w','bbox_h','width','height']]\n",
    "    img_width = df_bbox['width'].iloc[0]\n",
    "    img_height = df_bbox['height'].iloc[0]\n",
    "    formatted_pred = format_predictions_bbox(xs=df_bbox['x'],\n",
    "                                             ys=df_bbox['y'],\n",
    "                                             ws=df_bbox['bbox_w'],\n",
    "                                             hs=df_bbox['bbox_h'],\n",
    "                                             img_width=img_width,\n",
    "                                             img_height=img_height,\n",
    "                                             label='wildlife'\n",
    "                                             )\n",
    "    project.create_prediction(task_id=task_id,\n",
    "                               result=formatted_pred,\n",
    "                               model_version='gt'\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_predictions(polygons=polys['geometry'],widths=polys['width'],heights=polys['height'],label=['wildlife',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting savmap dataset\n",
    "Formatting the savmap dataset so it can be imported in label studio through a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "# create directories\n",
    "path_to_images = os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')\n",
    "Path(path_to_images).mkdir(exist_ok=True,parents=True)\n",
    "Path(path_to_labels).mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files\n",
    "# ! mv ../data/savmap_dataset_v2/*.JPG ../data/savmap_dataset_v2/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in range(len(polygons)):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    width, height = Image.open(image_path).size\n",
    "    polygons['x_min'].iat[i] = int(x_min)\n",
    "    polygons['x_max'].iat[i] = int(x_max)\n",
    "    polygons['y_min'].iat[i] = int(y_min)\n",
    "    polygons['y_max'].iat[i] = int(y_max)\n",
    "    polygons['x'].iat[i] = round(0.5*(x_max+x_min))\n",
    "    polygons['y'].iat[i] = round(0.5*(y_max+y_min))\n",
    "    polygons['width'].iat[i] = width\n",
    "    polygons['height'].iat[i] = height\n",
    "\n",
    "# creat bbox width and height\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:gdp.GeoDataFrame,dest_path_labels:str):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('IMAGEUUID'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{image_name}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_df_as_yolo(df_annotation=polygons,dest_path_labels=path_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial here: https://github.com/HumanSignal/label-studio-converter/tree/master\n",
    "# if it does not work, use a terminal\n",
    "# !label-studio-converter import yolo -i \"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\" --image-ext \".JPG\" --out-type \"predictions\" -o \"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\ls_tasks.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting General Dataset from Delplanque 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling test\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\test\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\test_tiled\\images\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\test_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling val\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\val_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling Train\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\train_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:pd.DataFrame,dest_path_labels:str,is_detector:bool=False):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "    \n",
    "    for col in ['x','y','bbox_w','bbox_h']:\n",
    "        df_annotation[col] = df_annotation[col].astype(float)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "\n",
    "    if is_detector:\n",
    "        df_annotation['class'] = 0\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('images'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{Path(image_name).stem}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='train' # 'train' 'test', 'val\n",
    "root = Path(rf\"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\{split}_tiled\")\n",
    "path_to_csv = root/\"gt.csv\"\n",
    "path_images = root/'images'\n",
    "path_to_labels = root/'labels'\n",
    "detection_mode=False # save label for wildlife detection only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(path_to_csv)\n",
    "# df_annotations.head(2)\n",
    "\n",
    "# update df_annotations\n",
    "df_annotations['width'] = 0.0\n",
    "df_annotations['height'] = 0.0\n",
    "\n",
    "\n",
    "for name in set(df_annotations.images):\n",
    "    width, height = Image.open(root/f\"images/{name}\").size\n",
    "    df_annotations.loc[df_annotations.images==name,'width'] = float(width)\n",
    "    df_annotations.loc[df_annotations.images==name,'height'] = float(height)\n",
    "\n",
    "df_annotations['x'] = 0.5*(df_annotations['x_min'] + df_annotations['x_max'])\n",
    "df_annotations['y'] = 0.5*(df_annotations['y_min'] + df_annotations['y_max'])\n",
    "df_annotations['bbox_h'] = df_annotations['y_max'] - df_annotations['y_min']\n",
    "df_annotations['bbox_w'] = df_annotations['x_max'] - df_annotations['x_min']\n",
    "\n",
    "df_annotations.rename(columns={'labels':'class'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotations.head(2)\n",
    "# df_annotations['class'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_yolo(df_annotations,path_to_labels,is_detector=detection_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasforming labels for detector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\WAID\\labels\"\n",
    "path = Path(path)\n",
    "\n",
    "for p in tqdm(path.glob(\"*/**/*.txt\")):\n",
    "    df = pd.read_csv(p,sep=\" \",header=None)\n",
    "    df.columns = [\"class\",'x','y','w','h']\n",
    "    df['class'] = 0\n",
    "    # un-comment to run\n",
    "    # df.to_csv(p, sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping labels to a reference mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting datasets to yolo<>OBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_yolo_to_obb(yolo_dataset_dir:str,output_dir:str)->None:\n",
    "\n",
    "    cols = ['id','x1','y1','x2','y2','x3','y3','x4','y4']\n",
    "    names = ['id','x','y','w','h']\n",
    "\n",
    "    # Iterate through labels\n",
    "    for label_path in tqdm(Path(yolo_dataset_dir).glob(\"*.txt\"),desc='yolo->obb'):\n",
    "        df = pd.read_csv(label_path,sep=' ',names=names)\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        for col in names[1:]:\n",
    "            df[col] = df[col].astype(float)\n",
    "        df['id'] = df['id'].astype(int)\n",
    "\n",
    "        df['w'] = 0.5*df['w']\n",
    "        df['h'] = 0.5*df['h']\n",
    "        # top left\n",
    "        df['x1'] = df['x'] - df['w']\n",
    "        df['y1'] = df['y'] - df['h']\n",
    "        # top right\n",
    "        df['x2'] = df['x'] + df['w']\n",
    "        df['y2'] = df['y'] - df['h']\n",
    "        # bottom right\n",
    "        df['x3'] = df['x'] + df['w']\n",
    "        df['y3'] = df['y'] + df['h']\n",
    "        # bottom left\n",
    "        df['x4'] = df['x'] - df['w']\n",
    "        df['y4'] = df['y'] + df['h']\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # save file\n",
    "        df[cols].to_csv(Path(output_dir)/label_path.name,\n",
    "                        sep=' ',index=False,header=False)\n",
    "\n",
    "def convert_obb_to_yolo(obb_dataset_dir:str,output_dir:str)->None:\n",
    "\n",
    "    names = ['id','x1','y1','x2','y2','x3','y3','x4','y4']\n",
    "    cols = ['id','x','y','w','h']\n",
    "\n",
    "    # Iterate through labels\n",
    "    for label_path in tqdm(Path(obb_dataset_dir).glob(\"*.txt\"),desc='obb->yolo'):\n",
    "        df = pd.read_csv(label_path,sep=' ',names=names)\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # center\n",
    "        df['x'] = (df['x1'] + df['x2'])/2.\n",
    "        df['y'] = (df['y1'] + df['y4'])/2.\n",
    "        # width\n",
    "        df['w'] = df['x2'] - df['x1']\n",
    "        # height\n",
    "        df['h'] = df['y4'] - df['y1']\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # save file\n",
    "        df[cols].to_csv(Path(output_dir)/label_path.name,sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to run\n",
    "# convert_yolo_to_obb(yolo_dataset_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\",\n",
    "#                     output_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run\n",
    "# convert_obb_to_yolo(obb_dataset_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\",\n",
    "#                     output_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
