{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements, uncomment to run\n",
    "# !pip install geopandas pillow label-studio-converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading Savmap dataset to label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from torchvision.ops import nms\n",
    "import torch\n",
    "from label_studio_sdk import Client\n",
    "from dotenv import load_dotenv\n",
    "from label_studio_tools.core.utils.io import get_local_path\n",
    "from urllib.parse import unquote\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "path_to_images = os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # polygon points\n",
    "# xx,yy = polygons['geometry'].iloc[0].exterior.coords.xy\n",
    "# np.array(list(zip(xx,yy))) * 100 / np.array([4000,3000]).reshape((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in tqdm(range(len(polygons))):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    # try:\n",
    "    width, height = Image.open(image_path).size\n",
    "    # except:\n",
    "    #     continue\n",
    "    polygons['x_min'].iat[i] = max(int(x_min),0)\n",
    "    polygons['x_max'].iat[i] = max(int(x_max),0)\n",
    "    polygons['y_min'].iat[i] = max(int(y_min),0)\n",
    "    polygons['y_max'].iat[i] = max(int(y_max),0)\n",
    "    polygons['x'].iat[i] = 0.5*(x_max+x_min)\n",
    "    polygons['y'].iat[i] = 0.5*(y_max+y_min)\n",
    "    polygons['width'].iat[i] = width\n",
    "    polygons['height'].iat[i] = height\n",
    "\n",
    "polygons['bbox_w'] = (polygons['x_max'] - polygons['x_min'])*1.0\n",
    "polygons['bbox_h'] = (polygons['y_max'] - polygons['y_min'])*1.0\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-max suppresion\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.ops.nms.html\n",
    "\n",
    "def nms_to_bbox(df_annotations:pd.DataFrame,iou_threshold:float=0.5):\n",
    "    dfs = list()\n",
    "\n",
    "    for IMAGEUUID, df in tqdm(df_annotations.groupby('IMAGEUUID')):\n",
    "\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        bbox = df[['x_min','y_min','x_max','y_max']].to_numpy().astype(float)\n",
    "        scores = np.ones((bbox.shape[0],)).astype(float)\n",
    "\n",
    "        bbox_indices= nms(boxes=torch.from_numpy(bbox),\n",
    "                            scores=torch.from_numpy(scores),\n",
    "                            iou_threshold=iou_threshold).numpy()\n",
    "        \n",
    "        # print(bbox[bbox_indices],'\\n',df.iloc[bbox_indices,:])\n",
    "\n",
    "        dfs.append(df.iloc[bbox_indices,:].copy())\n",
    "\n",
    "    return pd.concat(dfs,axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nms filtering of bbox\n",
    "df_filtered = nms_to_bbox(polygons,iou_threshold=0.4)\n",
    "df_filtered.rename(columns={'class':'labels'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.drop(columns=['level_0','index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered df vs unfiltered df\n",
    "len(df_filtered), len(polygons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filtered annotations as csv\n",
    "savepath = os.path.join(root,'savmap_annotations_2014_filtered.csv')\n",
    "df_filtered['images'] = df_filtered['IMAGEUUID'].apply(lambda x: f\"{x}.JPG\")\n",
    "df_filtered.to_csv(savepath,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = os.path.join(root,'savmap_annotations_2014_filtered.csv')\n",
    "df_filtered = pd.read_csv(savepath)\n",
    "df_filtered.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling images\n",
    "!python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images\" 2000 2000 100 -dest \"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images_splits\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\savmap_annotations_2014_filtered.csv\" -min 0.5 -all False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth for split images\n",
    "path_to_images_splits = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\images_splits\"\n",
    "df_splits = pd.read_csv(os.path.join(path_to_images_splits,\"..\\gt_splits.csv\"))\n",
    "\n",
    "try:\n",
    "    df_splits[\"IMAGEUUID\"] = df_splits['images'].apply(lambda x: str(x).split(\".\")[0])\n",
    "    df_splits['x'] = df_splits[\"x_min\"] #+df_splits[\"x_max\"])\n",
    "    df_splits['y'] = df_splits[\"y_min\"] #+df_splits[\"y_max\"])\n",
    "    df_splits[\"width\"] = 0.\n",
    "    df_splits[\"height\"] = 0.\n",
    "    df_splits['bbox_w'] = df_splits['x_max'] - df_splits['x_min']\n",
    "    df_splits['bbox_h'] = df_splits['y_max'] - df_splits['y_min']\n",
    "    \n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    df_splits['x'] = df_splits['x'] - 0.5*df_splits['bbox_w']\n",
    "    df_splits['y'] = df_splits['y'] - 0.5*df_splits['bbox_h']\n",
    "\n",
    "\n",
    "for name,df in tqdm(df_splits.groupby(\"images\")):\n",
    "    image_path = os.path.join(path_to_images_splits,name)\n",
    "    width, height = Image.open(image_path).size\n",
    "    mask = (df_splits[\"images\"] == name)\n",
    "    df_splits.loc[mask,'width']  = width\n",
    "    df_splits.loc[mask,'height'] = height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_splits.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select labels\n",
    "# data = polygons.loc[:,['x_min','x_max','y_min','y_max','IMAGEUUID','width','height','class']].copy()\n",
    "# data.rename(columns={'IMAGEUUID':'filename',\n",
    "#                      'x_max':'xmax',\n",
    "#                      'x_min':'xmin',\n",
    "#                      'y_min':'ymin',\n",
    "#                      'y_max':'ymax'},inplace=True)\n",
    "# data['filename'] = data['filename'].apply(lambda x: f\"{x}.JPG\")\n",
    "# data = data.dropna()\n",
    "# data = data[['filename','class','width', 'height','xmin','ymin','xmax','ymax']]\n",
    "# data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert CSV to COCO\n",
    "# save_json_path = ... #'cocoformat.json'\n",
    "\n",
    "# images = []\n",
    "# categories = []\n",
    "# annotations = []\n",
    "\n",
    "# category = {}\n",
    "# category[\"supercategory\"] = 'None'\n",
    "# category[\"id\"] = 0\n",
    "# category[\"category_name\"] = 'wildlife'\n",
    "# categories.append(category)\n",
    "\n",
    "# data['fileid'] = data['filename'].astype('category').cat.codes\n",
    "# data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n",
    "# # data['categoryid'] = data['categoryid']+1\n",
    "# data['annid'] = data.index\n",
    "\n",
    "# def image(row):\n",
    "#     image = {}\n",
    "#     image[\"height\"] = row.height\n",
    "#     image[\"width\"] = row.width\n",
    "#     image[\"id\"] = row.fileid\n",
    "#     image[\"file_name\"] = row.filename\n",
    "#     return image\n",
    "\n",
    "# # def category(row):\n",
    "# #     category = {}\n",
    "# #     category[\"supercategory\"] = 'None'\n",
    "# #     category[\"id\"] = row.categoryid\n",
    "# #     category[\"category_name\"] = row[2]\n",
    "# #     return category\n",
    "\n",
    "# def annotation(row):\n",
    "#     annotation = {}\n",
    "#     area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
    "#     annotation[\"segmentation\"] = []\n",
    "#     annotation[\"iscrowd\"] = 0\n",
    "#     annotation[\"area\"] = area\n",
    "#     annotation[\"image_id\"] = row.fileid\n",
    "#     annotation[\"score\"] = 1.0\n",
    "\n",
    "#     annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
    "\n",
    "#     annotation[\"category_id\"] = row.categoryid\n",
    "#     annotation[\"id\"] = row.annid\n",
    "#     return annotation\n",
    "\n",
    "# for row in data.itertuples():\n",
    "#     annotations.append(annotation(row))\n",
    "\n",
    "# imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "# for row in imagedf.itertuples():\n",
    "#     images.append(image(row))\n",
    "\n",
    "# # catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "# # for row in catdf.itertuples():\n",
    "# #     categories.append(category(row))\n",
    "\n",
    "# data_coco = {}\n",
    "# data_coco[\"images\"] = images\n",
    "# data_coco[\"categories\"] = categories\n",
    "# data_coco[\"annotations\"] = annotations\n",
    "# # json.dump(data_coco, open(save_json_path, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruth = {annot['file_name']:[] for annot in data_coco['images']}\n",
    "# for annot,image_data in zip(data_coco['annotations'],data_coco['images']):\n",
    "#     annot.update(image_data)\n",
    "#     # pprint.pp(annot)\n",
    "#     annot['category_name'] = category['category_name']\n",
    "#     groundtruth[annot['file_name']].append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = r\"..\\.env\"\n",
    "if dotenv_path is not None:\n",
    "    load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Label Studio API and check the connection\n",
    "LABEL_STUDIO_URL = os.getenv('LABEL_STUDIO_URL')\n",
    "API_KEY = os.getenv(\"LABEL_STUDIO_API_KEY\")\n",
    "labelstudio_client = Client(url=LABEL_STUDIO_URL, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"/data/local-files/?d=Users%5Cfadel%5COneDrive%5CBureau%5CWILD-AI%5Cdatalabeling%5Cdata%5Ctrain_wildai%5Cimages%5C003a34ee6b7841e6851b8fe511ebe102.JPG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unquote(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading Polygons\n",
    "def format_prediction_polygon(points:list,width:int,height:int,label:list=['wildlife',]):\n",
    "    \n",
    "    template = {\n",
    "            \"original_width\": width,\n",
    "            \"original_height\": height,\n",
    "            \"image_rotation\": 0,\n",
    "            \"value\": {\n",
    "                \"points\": points,\n",
    "                \"closed\":True,\n",
    "                \"polygonlabels\": label\n",
    "            }\n",
    "    }\n",
    "\n",
    "    return template\n",
    "\n",
    "def format_predictions_polygon(polygons:list,widths:list,heights:list,label:list=['wildlife',]):\n",
    "\n",
    "    results = list()\n",
    "    for polygon,w,h in zip(polygons,widths,heights):\n",
    "        xx,yy=polygon.exterior.coords.xy\n",
    "        points = list(zip(xx,yy))\n",
    "\n",
    "        # convert points to percent\n",
    "        points = np.array(points) * 100 / np.array([w,h]).reshape((1,2))\n",
    "        points = points.tolist()      \n",
    "\n",
    "        # append result\n",
    "        results.append(format_prediction_polygon(points,width=w,height=h,label=label))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# uploading polygons\n",
    " # Select project\n",
    "# project = labelstudio_client.get_project(id=project_id)\n",
    "# # Upload predictions for each task\n",
    "# tasks = project.get_tasks()\n",
    "# if top_n > 0:\n",
    "#     tasks = sorted(tasks,key=lambda x:x['id'])[:top_n]\n",
    "\n",
    "for task in tqdm(tasks[:10],desc=\"Uploading predictions\"):\n",
    "    task_id = task['id']\n",
    "    img_url = unquote(task['data']['image'])\n",
    "    img_path = get_local_path(img_url)\n",
    "    img_name = Path(img_path).stem\n",
    "    mask = polygons['IMAGEUUID']==img_name\n",
    "    polys = polygons.loc[mask,['IMAGEUUID','geometry','width','height']]\n",
    "    formatted_pred = format_predictions_polygon(polygons=polys['geometry'],widths=polys['width'],heights=polys['height'],label=['wildlife',])\n",
    "    # conf_scores = [pred['score'] for pred in prediction]\n",
    "    # max_score = 0.0\n",
    "    project.create_prediction(task_id=task_id,\n",
    "                               result=formatted_pred,model_version='gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "# uploading gt bbox\n",
    "def format_prediction_bbox(pred:dict,img_height:int,img_width:int,\n",
    "                           from_name:str='label',\n",
    "                           to_name:str='image',\n",
    "                           label_type:str='rectanglelabels') -> dict:\n",
    "        \"\"\"Converts prediction Label studio format\n",
    "\n",
    "        Args:\n",
    "            pred (dict): prediction in coco format\n",
    "            img_height (int): image height\n",
    "            img_width (int): image width\n",
    "\n",
    "        Returns:\n",
    "            dict: Label studio formated prediction\n",
    "        \"\"\"\n",
    "        # formatting the prediction to work with Label studio\n",
    "        x, y, width, height = pred['bbox']\n",
    "        label = pred['category_name']\n",
    "        # score = pred['score']\n",
    "        # if not isinstance(score,float):\n",
    "        #     score = 0.0\n",
    "        template = {\n",
    "                    \"from_name\": from_name,\n",
    "                    \"to_name\": to_name,\n",
    "                    \"type\": label_type,\n",
    "                    \"original_width\":img_width,\n",
    "                    \"original_height\":img_height,\n",
    "                    \"image_rotation\":0,\n",
    "                    'value': {\n",
    "                        label_type: [label,],\n",
    "                        'x': x / img_width * 100.,\n",
    "                        'y': y / img_height * 100.,\n",
    "                        'width': width / img_width * 100.,\n",
    "                        'height': height / img_height * 100.,\n",
    "                        'rotation':0.\n",
    "                    },\n",
    "                    # 'score': score\n",
    "        }\n",
    "        return template\n",
    "\n",
    "def format_predictions_bbox(xs:list,ys:list,ws:list,hs:list,img_width:int,img_height:int,label:str='wildlife'):\n",
    "      \n",
    "    results = list()\n",
    "    for x,y,w,h in zip(xs,ys,ws,hs):\n",
    "        \n",
    "        annot = {'bbox':[x,y,w,h],\n",
    "                 'category_name':label,\n",
    "                 'score':None\n",
    "                 }\n",
    "\n",
    "        # append result\n",
    "        results.append(format_prediction_bbox(annot,img_width=img_width,img_height=img_height))\n",
    "\n",
    "    return results\n",
    "\n",
    "def upload_predictions_bbox(df_annotations:pd.DataFrame,project_id:int):\n",
    "\n",
    "    # get tasks\n",
    "    project = labelstudio_client.get_project(id=project_id)\n",
    "    tasks = project.get_tasks()\n",
    "\n",
    "    # upload\n",
    "    failed_uploads = set()\n",
    "    for task in tqdm(tasks[:],desc=\"Uploading predictions\"):\n",
    "        task_id = task['id']\n",
    "        img_url = unquote(task['data']['image'])\n",
    "        img_path = get_local_path(img_url)\n",
    "        img_name = Path(img_path).stem\n",
    "        try:\n",
    "            mask = df_annotations['IMAGEUUID']==img_name\n",
    "            df_bbox = df_annotations.loc[mask,['x','y','bbox_w','bbox_h','width','height']]\n",
    "            img_width = df_bbox['width'].iat[0]\n",
    "            img_height = df_bbox['height'].iat[0]\n",
    "            formatted_pred = format_predictions_bbox(xs=df_bbox['x'],\n",
    "                                                    ys=df_bbox['y'],\n",
    "                                                    ws=df_bbox['bbox_w'],\n",
    "                                                    hs=df_bbox['bbox_h'],\n",
    "                                                    img_width=int(img_width),\n",
    "                                                    img_height=int(img_height),\n",
    "                                                    label='wildlife'\n",
    "                                                    )\n",
    "            # project.create_annotation(task_id=task_id,\n",
    "            #                         result=formatted_pred,\n",
    "            #                         # model_version='gt'\n",
    "            #                         )\n",
    "            project.create_prediction(task_id=task_id,\n",
    "                                    result=formatted_pred,\n",
    "                                    model_version='gt')\n",
    "        except Exception as e:\n",
    "            # skipping empty df\n",
    "            if len(df_bbox)<1:\n",
    "                failed_uploads.add(task_id)\n",
    "                continue\n",
    "            else:\n",
    "                print(\"Failed for: \",img_name,df_bbox,end=\"\\n\")\n",
    "                traceback.print_exc()\n",
    "                break\n",
    "    return failed_uploads\n",
    "\n",
    "def delete_tasks(project_id:int,failed_uploads:set[int]):\n",
    "\n",
    "    # get project\n",
    "    project = labelstudio_client.get_project(id=project_id)\n",
    "\n",
    "    # delete tasks\n",
    "    for task_id in tqdm(failed_uploads,desc=\"deleting tasks\"):\n",
    "        project.delete_task(task_id=task_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savmap original\n",
    "project_id = 71\n",
    "failed_uploads = upload_predictions_bbox(df_annotations=df_filtered,project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_uploads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# savmap splits\n",
    "project_id = 70\n",
    "failed_uploads = upload_predictions_bbox(df_annotations=df_splits,project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_uploads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete empty images\n",
    "delete_tasks(project_id=project_id,failed_uploads=failed_uploads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format_predictions(polygons=polys['geometry'],widths=polys['width'],heights=polys['height'],label=['wildlife',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting savmap dataset\n",
    "Formatting the savmap dataset so it can be imported in label studio through a json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "# create directories\n",
    "path_to_images = os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')\n",
    "Path(path_to_images).mkdir(exist_ok=True,parents=True)\n",
    "Path(path_to_labels).mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files\n",
    "# ! mv ../data/savmap_dataset_v2/*.JPG ../data/savmap_dataset_v2/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in range(len(polygons)):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    width, height = Image.open(image_path).size\n",
    "    polygons['x_min'].iat[i] = max(0,int(x_min))\n",
    "    polygons['x_max'].iat[i] = max(0,int(x_max))\n",
    "    polygons['y_min'].iat[i] = max(0,int(y_min))\n",
    "    polygons['y_max'].iat[i] = max(0,int(y_max))\n",
    "    polygons['x'].iat[i] = 0.5*(x_max+x_min)\n",
    "    polygons['y'].iat[i] = 0.5*(y_max+y_min)\n",
    "    polygons['width'].iat[i] = width\n",
    "    polygons['height'].iat[i] = height\n",
    "\n",
    "# creat bbox width and height\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:gdp.GeoDataFrame,dest_path_labels:str):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('IMAGEUUID'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{image_name}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_yolo(df_annotation=polygons,dest_path_labels=path_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial here: https://github.com/HumanSignal/label-studio-converter/tree/master\n",
    "# if it does not work, use a terminal\n",
    "# !label-studio-converter import yolo -i \"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\" --image-ext \".JPG\" --out-type \"predictions\" -o \"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\ls_tasks.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting General Dataset from Delplanque 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling test\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\test\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\test_tiled\\images\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\test_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling val\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\val_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling Train\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\train_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:pd.DataFrame,dest_path_labels:str,is_detector:bool=False):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "    \n",
    "    for col in ['x','y','bbox_w','bbox_h']:\n",
    "        df_annotation[col] = df_annotation[col].astype(float)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "\n",
    "    if is_detector:\n",
    "        df_annotation['class'] = 0\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('images'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{Path(image_name).stem}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='train' # 'train' 'test', 'val\n",
    "root = Path(rf\"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\{split}_tiled\")\n",
    "path_to_csv = root/\"gt.csv\"\n",
    "path_images = root/'images'\n",
    "path_to_labels = root/'labels'\n",
    "detection_mode=True # save label for wildlife detection only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(path_to_csv)\n",
    "# df_annotations.head(2)\n",
    "\n",
    "# update df_annotations\n",
    "df_annotations['width'] = 0.0\n",
    "df_annotations['height'] = 0.0\n",
    "\n",
    "\n",
    "for name in set(df_annotations.images):\n",
    "    width, height = Image.open(root/f\"images/{name}\").size\n",
    "    df_annotations.loc[df_annotations.images==name,'width'] = float(width)\n",
    "    df_annotations.loc[df_annotations.images==name,'height'] = float(height)\n",
    "\n",
    "df_annotations['x'] = 0.5*(df_annotations['x_min'] + df_annotations['x_max'])\n",
    "df_annotations['y'] = 0.5*(df_annotations['y_min'] + df_annotations['y_max'])\n",
    "df_annotations['bbox_h'] = df_annotations['y_max'] - df_annotations['y_min']\n",
    "df_annotations['bbox_w'] = df_annotations['x_max'] - df_annotations['x_min']\n",
    "\n",
    "df_annotations.rename(columns={'labels':'class'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotations.head(2)\n",
    "# df_annotations['class'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_as_yolo(df_annotations,path_to_labels,is_detector=detection_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasforming labels for detector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\WAID\\labels\"\n",
    "path = Path(path)\n",
    "\n",
    "for p in tqdm(path.glob(\"*/**/*.txt\")):\n",
    "    df = pd.read_csv(p,sep=\" \",header=None)\n",
    "    df.columns = [\"class\",'x','y','w','h']\n",
    "    df['class'] = 0\n",
    "    # un-comment to run\n",
    "    # df.to_csv(p, sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard sample mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "from datalabeling.annotator import Detector, Annotator\n",
    "from datalabeling.dataset.sampling import (get_preds_targets, \n",
    "                                           select_hard_samples,\n",
    "                                           compute_detector_performance)\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define detector\n",
    "# to speed up inference on intel, make\n",
    "conf=0.1\n",
    "overlap=0.1\n",
    "tilesize=2000\n",
    "imgsz=1280\n",
    "sahi=True\n",
    "save_tag=f\"_conf{conf}-imgsz{imgsz}-tile{tilesize}-overlap{overlap}-sahi{sahi}\"\n",
    "model = Detector(path_to_weights=r\"C:\\Users\\FADELCO\\OneDrive\\Bureau\\datalabeling\\models\\best_openvino_model\",\n",
    "                confidence_threshold=conf,\n",
    "                overlap_ratio=overlap,\n",
    "                tilesize=tilesize,\n",
    "                imgsz=imgsz,\n",
    "                device='CPU',\n",
    "                use_sliding_window=sahi,\n",
    "                is_yolo_obb=True)\n",
    "\n",
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "# alias = \"last\"\n",
    "# name = \"obb-detector\" # detector, \"obb-detector\"\n",
    "# handler = Annotator(mlflow_model_alias=alias,\n",
    "#                     mlflow_model_name=name,\n",
    "#                     confidence_threshold=0.1,\n",
    "#                     is_yolo_obb=name.strip() == \"obb-detector\",\n",
    "#                     dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detector for mlflow registered model\n",
    "model = handler.model.unwrap_python_model().detection_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth\n",
    "with open(r\"..\\data\\dataset_labeler.yaml\",'r') as file:\n",
    "    yolo_config = yaml.load(file,Loader=yaml.FullLoader)\n",
    "\n",
    "train_images_path = [os.path.join(yolo_config['path'],yolo_config['train'][i]) for i in range(len(yolo_config['train']))]\n",
    "train_labels_path = [p.replace('images','labels') for p in train_images_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path,train_labels_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_path = [r\"D:\\general_dataset\\tiled-data\\test\\images\",]\n",
    "pred_results_dir = r\"D:\\general_dataset\\tiled-data\\results\"\n",
    "df_results, df_labels, col_names = get_preds_targets(images_dirs=train_images_path,\n",
    "                                                  pred_results_dir=pred_results_dir,\n",
    "                                                  detector=model,\n",
    "                                                  save_tag=save_tag,\n",
    "                                                  load_results=True\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['image_path'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_per_img = compute_detector_performance(df_results,df_labels,col_names)\n",
    "df_results_per_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_per_img['min_scores'] = df_results_per_img['all_scores'].apply(np.min)\n",
    "df_results_per_img['mean_scores'] = df_results_per_img['all_scores'].apply(np.mean)\n",
    "df_results_per_img['median_scores'] = df_results_per_img['all_scores'].apply(np.median)\n",
    "df_results_per_img['var_scores'] = df_results_per_img['all_scores'].apply(np.var)\n",
    "\n",
    "df_results_per_img['failed'] = df_results_per_img['map75']<0.3\n",
    "# df_results_per_img['success'] = df_results_per_img['map75']>0.8\n",
    "\n",
    "df_results_per_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df_results_per_img.drop(columns=['all_scores','image_paths']),hue='failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df_results_per_img.drop(columns=['all_scores','image_paths']).corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load results\n",
    "# df_results_per_img = pd.read_csv(r\"D:\\PhD\\Data per camp\\DetectionDataset\\hard_samples\\df_results_per_img.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to save\n",
    "# df_results_per_img.to_csv(r\"D:\\PhD\\Data per camp\\DetectionDataset\\hard_samples\\df_results_per_img.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hard samples\n",
    "df_hard_samples = select_hard_samples(df_results_per_img=df_results_per_img,\n",
    "                                            map_thrs=0.3,\n",
    "                                            score_thrs=0.,\n",
    "                                            save_path_samples=r\"D:\\general_dataset\\tiled-data\\results\\hard_samples_test.txt\",\n",
    "                                            root='D:\\\\',\n",
    "                                            # save_data_yaml=r\"D:\\general_dataset\\tiled-data\\results\\hard_samples.yaml\"\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard_samples.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hard_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting datasets to yolo<>OBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_yolo_to_obb(yolo_dataset_dir:str,output_dir:str)->None:\n",
    "\n",
    "    cols = ['id','x1','y1','x2','y2','x3','y3','x4','y4']\n",
    "    names = ['id','x','y','w','h']\n",
    "\n",
    "    # Iterate through labels\n",
    "    for label_path in tqdm(Path(yolo_dataset_dir).glob(\"*.txt\"),desc='yolo->obb'):\n",
    "        df = pd.read_csv(label_path,sep=' ',names=names)\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        for col in names[1:]:\n",
    "            df[col] = df[col].astype(float)\n",
    "        df['id'] = df['id'].astype(int)\n",
    "\n",
    "        df['w'] = 0.5*df['w']\n",
    "        df['h'] = 0.5*df['h']\n",
    "        # top left\n",
    "        df['x1'] = df['x'] - df['w']\n",
    "        df['y1'] = df['y'] - df['h']\n",
    "        # top right\n",
    "        df['x2'] = df['x'] + df['w']\n",
    "        df['y2'] = df['y'] - df['h']\n",
    "        # bottom right\n",
    "        df['x3'] = df['x'] + df['w']\n",
    "        df['y3'] = df['y'] + df['h']\n",
    "        # bottom left\n",
    "        df['x4'] = df['x'] - df['w']\n",
    "        df['y4'] = df['y'] + df['h']\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # save file\n",
    "        df[cols].to_csv(Path(output_dir)/label_path.name,\n",
    "                        sep=' ',index=False,header=False)\n",
    "\n",
    "def convert_obb_to_yolo(obb_dataset_dir:str,output_dir:str)->None:\n",
    "\n",
    "    names = ['id','x1','y1','x2','y2','x3','y3','x4','y4']\n",
    "    cols = ['id','x','y','w','h']\n",
    "\n",
    "    # Iterate through labels\n",
    "    for label_path in tqdm(Path(obb_dataset_dir).glob(\"*.txt\"),desc='obb->yolo'):\n",
    "        df = pd.read_csv(label_path,sep=' ',names=names)\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # center\n",
    "        df['x'] = (df['x1'] + df['x2'])/2.\n",
    "        df['y'] = (df['y1'] + df['y4'])/2.\n",
    "        # width\n",
    "        df['w'] = df['x2'] - df['x1']\n",
    "        # height\n",
    "        df['h'] = df['y4'] - df['y1']\n",
    "\n",
    "        # check bounds\n",
    "        assert df[names[1:]].all().max() <=1., \"max value <= 1\"\n",
    "        assert df[names[1:]].all().min() >= 0., \"min value >=0\"\n",
    "\n",
    "        # save file\n",
    "        df[cols].to_csv(Path(output_dir)/label_path.name,sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to run\n",
    "# convert_yolo_to_obb(yolo_dataset_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\",\n",
    "#                     output_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to run\n",
    "# convert_obb_to_yolo(obb_dataset_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\",\n",
    "#                     output_dir=r\"C:\\Users\\fadel\\OneDrive\\Bureau\\WILD-AI\\datalabeling\\data\\train_wildai\\labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "label-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
