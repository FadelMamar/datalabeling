{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements, uncomment to run\n",
    "!pip install geopandas pillow label-studio-converter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Savmap dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = \"/Users/sfadel/Desktop/savmap\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "path_to_images = root #os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in range(len(polygons)):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    try:\n",
    "        width, height = Image.open(image_path).size\n",
    "    except:\n",
    "        continue\n",
    "    polygons['x_min'].iat[i] = int(x_min)\n",
    "    polygons['x_max'].iat[i] = int(x_max)\n",
    "    polygons['y_min'].iat[i] = int(y_min)\n",
    "    polygons['y_max'].iat[i] = int(y_max)\n",
    "    polygons['x'].iat[i] = round(0.5*(x_max+x_min))\n",
    "    polygons['y'].iat[i] = round(0.5*(y_max+y_min))\n",
    "    polygons['width'] = width\n",
    "    polygons['height'] = height\n",
    "\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polygons.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select labels\n",
    "data = polygons.loc[:,['x_min','x_max','y_min','y_max','IMAGEUUID','width','height','class']].copy()\n",
    "data.rename(columns={'IMAGEUUID':'filename',\n",
    "                     'x_max':'xmax',\n",
    "                     'x_min':'xmin',\n",
    "                     'y_min':'ymin',\n",
    "                     'y_max':'ymax'},inplace=True)\n",
    "data['filename'] = data['filename'].apply(lambda x: f\"{x}.JPG\")\n",
    "data = data.dropna()\n",
    "data = data[['filename','class','width', 'height','xmin','ymin','xmax','ymax']]\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert CSV to COCO\n",
    "save_json_path = ... #'cocoformat.json'\n",
    "\n",
    "images = []\n",
    "categories = []\n",
    "annotations = []\n",
    "\n",
    "category = {}\n",
    "category[\"supercategory\"] = 'None'\n",
    "category[\"id\"] = 0\n",
    "category[\"category_name\"] = 'wildlife'\n",
    "categories.append(category)\n",
    "\n",
    "data['fileid'] = data['filename'].astype('category').cat.codes\n",
    "data['categoryid']= pd.Categorical(data['class'],ordered= True).codes\n",
    "# data['categoryid'] = data['categoryid']+1\n",
    "data['annid'] = data.index\n",
    "\n",
    "def image(row):\n",
    "    image = {}\n",
    "    image[\"height\"] = row.height\n",
    "    image[\"width\"] = row.width\n",
    "    image[\"id\"] = row.fileid\n",
    "    image[\"file_name\"] = row.filename\n",
    "    return image\n",
    "\n",
    "# def category(row):\n",
    "#     category = {}\n",
    "#     category[\"supercategory\"] = 'None'\n",
    "#     category[\"id\"] = row.categoryid\n",
    "#     category[\"category_name\"] = row[2]\n",
    "#     return category\n",
    "\n",
    "def annotation(row):\n",
    "    annotation = {}\n",
    "    area = (row.xmax -row.xmin)*(row.ymax - row.ymin)\n",
    "    annotation[\"segmentation\"] = []\n",
    "    annotation[\"iscrowd\"] = 0\n",
    "    annotation[\"area\"] = area\n",
    "    annotation[\"image_id\"] = row.fileid\n",
    "    annotation[\"score\"] = 1.0\n",
    "\n",
    "    annotation[\"bbox\"] = [row.xmin, row.ymin, row.xmax -row.xmin,row.ymax-row.ymin ]\n",
    "\n",
    "    annotation[\"category_id\"] = row.categoryid\n",
    "    annotation[\"id\"] = row.annid\n",
    "    return annotation\n",
    "\n",
    "for row in data.itertuples():\n",
    "    annotations.append(annotation(row))\n",
    "\n",
    "imagedf = data.drop_duplicates(subset=['fileid']).sort_values(by='fileid')\n",
    "for row in imagedf.itertuples():\n",
    "    images.append(image(row))\n",
    "\n",
    "# catdf = data.drop_duplicates(subset=['categoryid']).sort_values(by='categoryid')\n",
    "# for row in catdf.itertuples():\n",
    "#     categories.append(category(row))\n",
    "\n",
    "data_coco = {}\n",
    "data_coco[\"images\"] = images\n",
    "data_coco[\"categories\"] = categories\n",
    "data_coco[\"annotations\"] = annotations\n",
    "# json.dump(data_coco, open(save_json_path, \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundtruth = {annot['file_name']:[] for annot in data_coco['images']}\n",
    "for annot,image_data in zip(data_coco['annotations'],data_coco['images']):\n",
    "    annot.update(image_data)\n",
    "    # pprint.pp(annot)\n",
    "    annot['category_name'] = category['category_name']\n",
    "    groundtruth[annot['file_name']].append(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide correct alias, \"pt\", \"onnx\"\n",
    "handler = Annotator(mlflow_model_alias='pt',\n",
    "                    mlflow_model_version=\"groundtruth\")\n",
    "directory_preds = handler.build_upload_json(path_img_dir='/Users/sfadel/Desktop/savmap',\n",
    "                                            root='/Users/sfadel',\n",
    "                                            bulk_predictions=groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting savmap dataset\n",
    "Formatting the savmap dataset so it can be imported in label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gdp\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load data\n",
    "root = r\"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\"\n",
    "polygons = gdp.read_file(os.path.join(root,'savmap_annotations_2014.geojson'))\n",
    "\n",
    "# create directories\n",
    "path_to_images = os.path.join(root,'images')\n",
    "path_to_labels = os.path.join(root,'labels')\n",
    "Path(path_to_images).mkdir(exist_ok=True,parents=True)\n",
    "Path(path_to_labels).mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move files\n",
    "# ! mv ../data/savmap_dataset_v2/*.JPG ../data/savmap_dataset_v2/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding boxs\n",
    "for cat in ['x_min', 'y_min', 'x_max', 'y_max','width','height','x','y']:\n",
    "    polygons[cat] = None\n",
    "for i in range(len(polygons)):\n",
    "    x_min, y_min, x_max, y_max = polygons['geometry'].iloc[i].bounds\n",
    "    image_path = os.path.join(path_to_images,f\"{polygons['IMAGEUUID'].iloc[i]}.JPG\")\n",
    "    width, height = Image.open(image_path).size\n",
    "    polygons['x_min'].iat[i] = int(x_min)\n",
    "    polygons['x_max'].iat[i] = int(x_max)\n",
    "    polygons['y_min'].iat[i] = int(y_min)\n",
    "    polygons['y_max'].iat[i] = int(y_max)\n",
    "    polygons['x'].iat[i] = round(0.5*(x_max+x_min))\n",
    "    polygons['y'].iat[i] = round(0.5*(y_max+y_min))\n",
    "    polygons['width'] = width\n",
    "    polygons['height'] = height\n",
    "\n",
    "polygons['bbox_w'] = polygons['x_max'] - polygons['x_min']\n",
    "polygons['bbox_h'] = polygons['y_max'] - polygons['y_min']\n",
    "polygons['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGEUUID</th>\n",
       "      <th>TAGUUID</th>\n",
       "      <th>geometry</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>bbox_w</th>\n",
       "      <th>bbox_h</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f77f4af5a1344b9086b307d2b4ba61ff</td>\n",
       "      <td>a9b3a2325dbe4a208bc3ae37eeb8e1e1</td>\n",
       "      <td>POLYGON ((1197.00000 568.00000, 1186.00000 568...</td>\n",
       "      <td>1179</td>\n",
       "      <td>568</td>\n",
       "      <td>1230</td>\n",
       "      <td>597</td>\n",
       "      <td>4608</td>\n",
       "      <td>3456</td>\n",
       "      <td>1204</td>\n",
       "      <td>582</td>\n",
       "      <td>51</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          IMAGEUUID                           TAGUUID  \\\n",
       "0  f77f4af5a1344b9086b307d2b4ba61ff  a9b3a2325dbe4a208bc3ae37eeb8e1e1   \n",
       "\n",
       "                                            geometry x_min y_min x_max y_max  \\\n",
       "0  POLYGON ((1197.00000 568.00000, 1186.00000 568...  1179   568  1230   597   \n",
       "\n",
       "   width  height     x    y bbox_w bbox_h  class  \n",
       "0   4608    3456  1204  582     51     29      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygons.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:gdp.GeoDataFrame,dest_path_labels:str):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('IMAGEUUID'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{image_name}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving yolo labels:   0%|          | 0/654 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving yolo labels: 100%|██████████| 654/654 [00:00<00:00, 1191.47it/s]\n"
     ]
    }
   ],
   "source": [
    "save_df_as_yolo(df_annotation=polygons,dest_path_labels=path_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutorial here: https://github.com/HumanSignal/label-studio-converter/tree/master\n",
    "# if it does not work, use a terminal\n",
    "# !label-studio-converter import yolo -i \"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\" -o \"D:\\PhD\\Data per camp\\Extra training data\\savmap_dataset_v2\\raw_data\\labelstudio.json\" --image-root-url \"/data/local-files/?d=PhD/Data per camp/Extra training data/savmap_dataset_v2/raw_data/images\" --image-ext \".JPG\" --out-type \"predictions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting General Dataset from Delplanque 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling test\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\test\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\test_tiled\\images\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\test_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling val\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\val_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\val_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiling Train\n",
    "# !python ../../HerdNet/tools/patcher.py \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train\" 640 640 64  -dest \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\train_tiled\" -pattern \"**/*.JPG\" -csv \"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\groundtruth\\csv\\train_big_size_A_B_E_K_WH_WB.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to YOLO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to yolo format\n",
    "def save_df_as_yolo(df_annotation:pd.DataFrame,dest_path_labels:str,is_detector:bool=False):\n",
    "    \n",
    "    cols = ['class','x','y','bbox_w','bbox_h']\n",
    "    for col in cols:\n",
    "        assert df_annotation[col].isna().sum()<1,'there are NaN values. Check out.'\n",
    "        # df_annotation[col] = df_annotation[col].apply(int)\n",
    "    \n",
    "    for col in ['x','y','bbox_w','bbox_h']:\n",
    "        df_annotation[col] = df_annotation[col].astype(float)\n",
    "\n",
    "    # normalize values\n",
    "    df_annotation.loc[:,'x'] = df_annotation['x']/df_annotation['width']\n",
    "    df_annotation.loc[:,'y'] = df_annotation['y']/df_annotation['height']\n",
    "    df_annotation.loc[:,'bbox_w'] = df_annotation['bbox_w']/df_annotation['width']\n",
    "    df_annotation.loc[:,'bbox_h'] = df_annotation['bbox_h']/df_annotation['height']\n",
    "\n",
    "    if is_detector:\n",
    "        df_annotation['class'] = 0\n",
    "    \n",
    "    for image_name,df in tqdm(df_annotation.groupby('images'),desc='Saving yolo labels'):\n",
    "        txt_file = f'{Path(image_name).stem}.txt'\n",
    "        df[cols].to_csv(os.path.join(dest_path_labels,txt_file),sep=' ',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='train' # 'train' 'test', 'val\n",
    "root = Path(rf\"D:\\PhD\\Data per camp\\Extra training data\\general_dataset\\tiled_data\\{split}_tiled\")\n",
    "path_to_csv = root/\"gt.csv\"\n",
    "path_images = root/'images'\n",
    "path_to_labels = root/'labels'\n",
    "detection_mode=False # save label for wildlife detection only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(path_to_csv)\n",
    "# df_annotations.head(2)\n",
    "\n",
    "# update df_annotations\n",
    "df_annotations['width'] = 0.0\n",
    "df_annotations['height'] = 0.0\n",
    "\n",
    "\n",
    "for name in set(df_annotations.images):\n",
    "    width, height = Image.open(root/f\"images/{name}\").size\n",
    "    df_annotations.loc[df_annotations.images==name,'width'] = float(width)\n",
    "    df_annotations.loc[df_annotations.images==name,'height'] = float(height)\n",
    "\n",
    "df_annotations['x'] = 0.5*(df_annotations['x_min'] + df_annotations['x_max'])\n",
    "df_annotations['y'] = 0.5*(df_annotations['y_min'] + df_annotations['y_max'])\n",
    "df_annotations['bbox_h'] = df_annotations['y_max'] - df_annotations['y_min']\n",
    "df_annotations['bbox_w'] = df_annotations['x_max'] - df_annotations['x_min']\n",
    "\n",
    "df_annotations.rename(columns={'labels':'class'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_annotations.head(2)\n",
    "# df_annotations['class'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving yolo labels: 100%|██████████| 4511/4511 [00:02<00:00, 2155.82it/s]\n"
     ]
    }
   ],
   "source": [
    "save_df_as_yolo(df_annotations,path_to_labels,is_detector=detection_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WAID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasforming labels for detector training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14366it [00:53, 266.73it/s]\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Machine Learning\\Desktop\\workspace-wildAI\\datalabeling\\data\\WAID\\labels\"\n",
    "path = Path(path)\n",
    "\n",
    "for p in tqdm(path.glob(\"*/**/*.txt\")):\n",
    "    df = pd.read_csv(p,sep=\" \",header=None)\n",
    "    df.columns = [\"class\",'x','y','w','h']\n",
    "    df['class'] = 0\n",
    "    # un-comment to run\n",
    "    # df.to_csv(p, sep=\" \", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping labels to a reference mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
